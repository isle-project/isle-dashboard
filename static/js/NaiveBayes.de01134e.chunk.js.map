{"version":3,"file":"static/js/NaiveBayes.de01134e.chunk.js","mappings":";2SAaA,SAASA,EAAWC,GACnB,OAAOC,GAAAA,CAAOD,IAAOE,GAAAA,CAAmBF,GAGzC,SAASG,EAAoBH,GAC5B,OAAOI,EAAAA,EAAAA,aAAUJ,KAAQC,GAAAA,CAAOD,GAM1B,SAASK,EAAcL,EAAGM,EAAGC,EAAMC,GACzC,IAAIC,EAAS,GACb,MAAMC,EAAa,GACbC,EAAO,GACPC,GAAAA,CAASZ,KACdA,EAAI,CAAEA,IAEP,IAAM,IAAIa,EAAI,EAAGA,EAAIb,EAAEc,OAAQD,IAAM,CACpC,MAAME,EAASR,EAAMP,EAAGa,IACxB,GAAKG,GAAAA,CAAUR,EAAcR,EAAGa,IAC/BH,EAAWO,KAAMjB,EAAGa,QACd,CACN,MAAMK,GAAaC,EAAAA,EAAAA,GAA6BJ,EAAQf,EAAGa,IAC3D,IAAM,IAAIO,EAAI,EAAGA,EAAIF,EAAWJ,OAAQM,IACvCV,EAAWO,KAAO,GAAEjB,EAAGa,MAAOK,EAAYE,MAE3CT,EAAMX,EAAGa,IAAQK,GAGnB,MAAMG,EAAOd,EAAMP,EAAG,IAAMc,OAC5B,IAAM,IAAIQ,EAAI,EAAGA,EAAID,EAAMC,IAAM,CAChC,MAAMC,EAAM,GACZ,IAAM,IAAIV,EAAI,EAAGA,EAAIb,EAAEc,OAAQD,IAAM,CACpC,MAAME,EAASR,EAAMP,EAAGa,IACxB,GAAKG,GAAAA,CAAUR,EAAcR,EAAGa,IAC/BU,EAAIN,KAAMF,EAAQO,QACZ,CACN,MAAMJ,EAAaP,EAAMX,EAAGa,IACtBW,EAAMT,EAAQO,GACpB,IAAM,IAAIF,EAAI,EAAGA,EAAIF,EAAWJ,OAAQM,IACvCG,EAAIN,KAAQO,IAAQN,EAAYE,GAAQ,EAAI,IAI/CX,EAAOQ,KAAMM,GAEdd,EAASgB,GAAAA,CAAShB,GAElB,MAAO,CAAEA,OAAAA,EAAQC,WAAAA,EAAYgB,QADbnB,EAAMD,IAIhB,SAASqB,EAAqB3B,EAAGM,EAAGC,EAAMC,GAChD,IAAIC,EAAS,GACb,MAAMC,EAAa,GACbC,EAAO,GACPC,GAAAA,CAASZ,KACdA,EAAI,CAAEA,IAEP,IAAM,IAAIa,EAAI,EAAGA,EAAIb,EAAEc,OAAQD,IAAM,CACpC,MAAME,EAASR,EAAMP,EAAGa,IACxB,GAAKG,GAAAA,CAAUR,EAAcR,EAAGa,IAC/BH,EAAWO,KAAMjB,EAAGa,QACd,CACN,MAAMK,GAAaC,EAAAA,EAAAA,GAA6BJ,EAAQf,EAAGa,IAC3D,IAAM,IAAIO,EAAI,EAAGA,EAAIF,EAAWJ,OAAQM,IACvCV,EAAWO,KAAO,GAAEjB,EAAGa,MAAOK,EAAYE,MAE3CT,EAAMX,EAAGa,IAAQK,GAGnB,MAAMG,EAAOd,EAAMP,EAAG,IAAMc,OACtBY,EAAU,GAChB,IAAM,IAAIJ,EAAI,EAAGA,EAAID,EAAMC,IAAM,CAChC,MAAMC,EAAM,GACZ,IAAIK,GAAU,EACd,IAAM,IAAIf,EAAI,EAAGA,EAAIb,EAAEc,OAAQD,IAAM,CACpC,MAAME,EAASR,EAAMP,EAAGa,IACxB,GAAKG,GAAAA,CAAUR,EAAcR,EAAGa,IAC1BV,EAAoBY,EAAQO,IAChCC,EAAIN,KAAMF,EAAQO,IAElBM,GAAU,MAEL,CACN,MAAMV,EAAaP,EAAMX,EAAGa,IACtBW,EAAMT,EAAQO,GACpB,GAAKvB,EAAWyB,GACfI,GAAU,OAEV,IAAM,IAAIR,EAAI,EAAGA,EAAIF,EAAWJ,OAAQM,IACvCG,EAAIN,KAAQO,IAAQN,EAAYE,GAAQ,EAAI,IAK3CrB,EAAWQ,EAAMD,GAAKgB,MAC1BM,GAAU,GAELA,IACLnB,EAAOQ,KAAMM,GACbG,EAAQT,KAAMV,EAAMD,GAAKgB,KAI3B,OADAb,EAASgB,GAAAA,CAAShB,GACX,CAAEA,OAAAA,EAAQC,WAAAA,EAAYgB,QAAAA,yaC5F9B,SAASG,EAAa7B,EAAGM,GACxBwB,KAAKC,EAAI/B,EAAEgC,MAAO,GAClBF,KAAKG,EAAIjC,EAAEgC,MAAO,GAElBF,KAAKI,QAAUC,GAAAA,CAAM7B,EAAE8B,SACvBN,KAAKO,OAASP,KAAKI,QAAQpB,OAE3BgB,KAAKQ,YAAatC,EAAGM,GAGtBuB,EAAYU,UAAUC,MAAQC,EAAS,OAcvCZ,EAAYU,UAAUD,YAAc,SAAsBtC,EAAGM,GAC5DwB,KAAKY,MAAQ,GACb,MAAMV,EAAQ,CAAEF,KAAKG,EAAGH,KAAKO,QAC7BP,KAAKa,GAAKlB,GAAAA,CAAS,IAAImB,aAAcZ,EAAM,GAAGA,EAAM,IAAM,CAAE,MAASA,IACrEF,KAAKe,MAAQpB,GAAAA,CAAS,IAAImB,aAAcZ,EAAM,GAAGA,EAAM,IAAM,CAAE,MAASA,IACxE,IAAM,IAAIV,EAAI,EAAGA,EAAIQ,KAAKO,OAAQf,IAAM,CACvC,MAAMwB,EAAM,GACNC,EAAIjB,KAAKI,QAASZ,GACxB,IAAM,IAAIT,EAAI,EAAGA,EAAIiB,KAAKC,EAAGlB,IACvBP,EAAGO,KAAQkC,GACfD,EAAI7B,KAAMJ,GAGZ,MAAMmC,EAAKF,EAAIhC,OACfgB,KAAKY,MAAOK,GAAME,GAAAA,CAAID,EAAKlB,KAAKC,GAChC,IAAM,IAAIlB,EAAI,EAAGA,EAAIiB,KAAKG,EAAGpB,IAAM,CAClC,MAAMqC,EAAOJ,EAAIK,KAAK7B,GAAKtB,EAAEoD,IAAK9B,EAAGT,KAC/B8B,GAAKU,EAAAA,EAAAA,GAAMH,GACXL,GAAQS,EAAAA,EAAAA,GAAOJ,GACrBpB,KAAKa,GAAGY,IAAK1C,EAAGS,EAAGqB,GACnBb,KAAKe,MAAMU,IAAK1C,EAAGS,EAAGuB,MAYzBhB,EAAYU,UAAUiB,iBAAmB,SAA2BxD,EAAGsB,GACtE,MAAMyB,EAAIjB,KAAKI,QAASZ,GACxB,IAAImC,EAAM3B,KAAKY,MAAOK,GAEtB,IAAM,IAAIlC,EAAI,EAAGA,EAAIiB,KAAKG,EAAGpB,IAAM,CAClC,MAAMgC,EAAQf,KAAKe,MAAMO,IAAKvC,EAAGS,GAC3BoC,EAAKb,EAAMA,EACXF,EAAKb,KAAKa,GAAGS,IAAKvC,EAAGS,GAE3BmC,IADe,GAAMR,GAAAA,CAAI,EAAIU,IAAKD,GAAWE,GAAAA,CAAK5D,EAAGa,GAAM8B,EAAI,GAAMe,EAGtE,OAAOD,GASR5B,EAAYU,UAAUsB,WAAa,SAAqB7D,GACvD,MAAM8D,EAAWhC,KAAKI,QAAQpB,OACxBiD,EAAS,IAAIC,MAAOF,GAC1B,IAAM,IAAIxC,EAAI,EAAGA,EAAIwC,EAAUxC,IAC9ByC,EAAQzC,GAAMQ,KAAK0B,iBAAkBxD,EAAGsB,GAEzC,IAAI2C,EAAMF,EAAQ,GACdG,EAASpC,KAAKI,QAAS,GAC3B,IAAM,IAAIZ,EAAI,EAAGA,EAAIwC,EAAUxC,IAAM,CACpC,MAAME,EAAMuC,EAAQzC,GACfE,EAAMyC,IACVA,EAAMzC,EACN0C,EAASpC,KAAKI,QAASZ,IAGzB,OAAO4C,GASRrC,EAAYU,UAAU4B,QAAU,SAAkBnE,GACjD,MAAM8D,EAAWhC,KAAKI,QAAQpB,OAK9B,GAJKsD,GAAAA,CAAcpE,KAClBA,EAAIyB,GAAAA,CAASzB,IAGTqE,GAAAA,CAAcrE,GAAM,CACxB,MAAQsE,EAAMC,GAASvE,EAAEgC,MACnBwC,EAAM,IAAIR,MAAOM,GACvB,IAAM,IAAIhD,EAAI,EAAGA,EAAIgD,EAAMhD,IAAM,CAChC,MAAMyC,EAAS,IAAIC,MAAOF,GAC1B,IAAM,IAAIjD,EAAI,EAAGA,EAAIiD,EAAUjD,IAAM,CACpC,MAAM4D,EAAM,IAAIT,MAAOO,GACvB,IAAM,IAAInD,EAAI,EAAGA,EAAImD,EAAMnD,IAC1BqD,EAAKrD,GAAMpB,EAAEoD,IAAK9B,EAAGF,GAEtB2C,EAAQlD,GAAMiB,KAAK0B,iBAAkBiB,EAAK5D,GAE3C,IAAIoD,EAAMF,EAAQ,GACdG,EAASpC,KAAKI,QAAS,GAC3B,IAAM,IAAIrB,EAAI,EAAGA,EAAIiD,EAAUjD,IAAM,CACpC,MAAMW,EAAMuC,EAAQlD,GACfW,EAAMyC,IACVA,EAAMzC,EACN0C,EAASpC,KAAKI,QAASrB,IAGzB2D,EAAKlD,GAAM4C,EAEZ,OAAOM,EAGR,OAAO1C,KAAK+B,WAAY7D,IASzB6B,EAAYU,UAAUmC,aAAe,SAAuB1E,GAK3D,GAJKoE,GAAAA,CAAcpE,KAClBA,EAAIyB,GAAAA,CAASzB,IAGTqE,GAAAA,CAAcrE,GAAM,CACxB,MAAQsE,EAAMC,GAASvE,EAAEgC,MACnBwC,EAAM,IAAIR,MAAOM,GACvB,IAAM,IAAIhD,EAAI,EAAGA,EAAIgD,EAAMhD,IAAM,CAChC,IAAIyC,EAAS,IAAIC,MAAOlC,KAAKO,QAC7B,IAAM,IAAIxB,EAAI,EAAGA,EAAIiB,KAAKO,OAAQxB,IAAM,CACvC,MAAM4D,EAAM,IAAIT,MAAOO,GACvB,IAAM,IAAInD,EAAI,EAAGA,EAAImD,EAAMnD,IAC1BqD,EAAKrD,GAAMpB,EAAEoD,IAAK9B,EAAGF,GAEtB2C,EAAQlD,GAAMiB,KAAK0B,iBAAkBiB,EAAK5D,GAE3C,MAAM8D,GAAIV,EAAAA,EAAAA,GAAKF,GACf,IAAIa,EAAU,EACd,IAAM,IAAI/D,EAAI,EAAGA,EAAIkD,EAAOjD,OAAQD,IACnC+D,GAAWC,GAAAA,CAAKd,EAAQlD,GAAM8D,GAE/B,MAAMG,EAAQH,EAAI1B,GAAAA,CAAI2B,GACtBb,GAASgB,EAAAA,EAAAA,GAAUhB,EAAQe,GAC3BN,EAAKlD,GAAMyC,EAAOZ,KAAKnD,GAAK6E,GAAAA,CAAK7E,KAElC,OAAOwE,EAGR,MAAMT,EAAS,IAAIC,MAAOlC,KAAKO,QAC/B,IAAM,IAAIxB,EAAI,EAAGA,EAAIiB,KAAKO,OAAQxB,IACjCkD,EAAQlD,GAAMiB,KAAK0B,iBAAkBxD,EAAGa,GAEzC,MAAM8D,GAAIV,EAAAA,EAAAA,GAAKF,GACf,IAAIa,EAAU,EACd,IAAM,IAAI/D,EAAI,EAAGA,EAAIkD,EAAOjD,OAAQD,IACnC+D,GAAWC,GAAAA,CAAKd,EAAQlD,GAAM8D,GAE/B,MAAMG,EAAQH,EAAI1B,GAAAA,CAAI2B,GAEtB,OADAb,GAASgB,EAAAA,EAAAA,GAAUhB,EAAQe,GACpBf,EAAOZ,KAAKnD,GAAK6E,GAAAA,CAAK7E,MAM9B,QCvMA,MAAMgF,EAAQP,IACb,IAAIQ,EAAM,EACV,IAAM,IAAI3D,EAAI,EAAGA,EAAImD,EAAI3D,OAAQQ,IAChC2D,GAAOR,EAAKnD,GAEb,OAAO2D,GAeR,SAASC,EAAgBlF,EAAGM,EAAG6E,GAC9BrD,KAAKC,EAAI/B,EAAEgC,MAAO,GAClBF,KAAKG,EAAIjC,EAAEgC,MAAO,GAElBF,KAAKI,QAAUC,GAAAA,CAAM7B,EAAE8B,SACvBN,KAAKO,OAASP,KAAKI,QAAQpB,OAC3BgB,KAAKqD,MAAQA,EAEbrD,KAAKsD,eAAgBpF,EAAGM,GAGzB4E,EAAe3C,UAAUC,MAAQC,EAAS,OAc1CyC,EAAe3C,UAAU6C,eAAiB,SAAyBpF,EAAGM,GACrE,MAAMoC,EAAQ,GACRV,EAAQ,CAAEF,KAAKG,EAAGH,KAAKO,QACvBgD,EAAQ5D,GAAAA,CAAS,IAAImB,aAAcZ,EAAM,GAAGA,EAAM,IAAM,CAAE,MAASA,IACzE,IAAM,IAAIV,EAAI,EAAGA,EAAIQ,KAAKO,OAAQf,IAAM,CACvC,MAAMwB,EAAM,GACNwC,EAAS,IAAIC,WAAYzD,KAAKG,GAC9Bc,EAAIjB,KAAKI,QAASZ,GACxB,IAAM,IAAIT,EAAI,EAAGA,EAAIiB,KAAKC,EAAGlB,IACvBP,EAAGO,KAAQkC,GACfD,EAAI7B,KAAMJ,GAGZ,MAAMmC,EAAKF,EAAIhC,OACf4B,EAAOK,GAAME,GAAAA,CAAID,EAAKlB,KAAKC,GAC3B,IAAIyD,EAAa,EACjB,IAAM,IAAI3E,EAAI,EAAGA,EAAIiB,KAAKG,EAAGpB,IAAM,CAClC,MAAMqC,EAAOJ,EAAIK,KAAK7B,GAAKtB,EAAEoD,IAAK9B,EAAGT,KACrCyE,EAAQzE,GAAMmE,EAAK9B,GACnBsC,GAAcF,EAAQzE,GAEvB,IAAM,IAAIA,EAAI,EAAGA,EAAIiB,KAAKG,EAAGpB,IAAM,CAClC,MAAMW,EAAMyB,GAAAA,CAAIqC,EAAQzE,GAAMiB,KAAKqD,OAAUlC,GAAAA,CAAIuC,EAAa1D,KAAKG,EAAIH,KAAKqD,OAC5EE,EAAM9B,IAAK1C,EAAGS,EAAGE,IAGnBM,KAAKY,MAAQA,EACbZ,KAAKuD,MAAQA,GAWdH,EAAe3C,UAAUkD,iBAAmB,SAA2BzF,EAAGsB,EAAGT,GAC5E,MAAMkC,EAAIjB,KAAKI,QAASZ,GACxB,IAAImC,EAAM3B,KAAKY,MAAOK,GACtB,IAAMlC,EAAI,EAAGA,EAAIiB,KAAKG,EAAGpB,IAAM,CAE9B4C,GADYzD,EAAGa,GAAMb,EAAGa,GAAMiB,KAAKuD,MAAMjC,IAAKvC,EAAGS,GAAM,EAGxD,OAAOmC,GASRyB,EAAe3C,UAAUsB,WAAa,SAAqB7D,GAC1D,MAAM8D,EAAWhC,KAAKI,QAAQpB,OACxBiD,EAAS,IAAIC,MAAOF,GAC1B,IAAM,IAAIxC,EAAI,EAAGA,EAAIwC,EAAUxC,IAAM,CACpC,MAAMyB,EAAIjB,KAAKI,QAASZ,GACxByC,EAAQzC,GAAMQ,KAAKY,MAAOK,GAC1B,IAAM,IAAIlC,EAAI,EAAGA,EAAIiB,KAAKG,EAAGpB,IAAM,CAClC,MAAMW,EAAMxB,EAAGa,GAAMb,EAAGa,GAAMiB,KAAKuD,MAAMjC,IAAKvC,EAAGS,GAAM,EACvDyC,EAAQzC,IAAOE,GAGjB,IAAIyC,EAAMF,EAAQ,GACdG,EAASpC,KAAKI,QAAS,GAC3B,IAAM,IAAIZ,EAAI,EAAGA,EAAIwC,EAAUxC,IAAM,CACpC,MAAME,EAAMuC,EAAQzC,GACfE,EAAMyC,IACVA,EAAMzC,EACN0C,EAASpC,KAAKI,QAASZ,IAGzB,OAAO4C,GASRgB,EAAe3C,UAAU4B,QAAU,SAAkBnE,GACpD,MAAM8D,EAAWhC,KAAKI,QAAQpB,OAK9B,GAJKsD,GAAAA,CAAcpE,KAClBA,EAAIyB,GAAAA,CAASzB,IAGTqE,GAAAA,CAAcrE,GAAM,CACxB,MAAMwE,EAAM,GACNF,EAAOtE,EAAEgC,MAAO,GACtB,IAAM,IAAIV,EAAI,EAAGA,EAAIgD,EAAMhD,IAAM,CAChC,MAAMyC,EAAS,IAAIC,MAAOF,GAC1B,IAAM,IAAIjD,EAAI,EAAGA,EAAIiD,EAAUjD,IAAM,CACpC,MAAMkC,EAAIjB,KAAKI,QAASrB,GACxBkD,EAAQlD,GAAMiB,KAAKY,MAAOK,GAC1B,IAAM,IAAI3B,EAAI,EAAGA,EAAIU,KAAKG,EAAGb,IAAM,CAClC,MAAMI,EAAMxB,EAAEoD,IAAK9B,EAAGF,GAAMpB,EAAEoD,IAAK9B,EAAGF,GAAMU,KAAKuD,MAAMjC,IAAKhC,EAAGP,GAAM,EACrEkD,EAAQlD,IAAOW,GAGjB,IAAIyC,EAAMF,EAAQ,GACdG,EAASpC,KAAKI,QAAS,GAC3B,IAAM,IAAIrB,EAAI,EAAGA,EAAIiD,EAAUjD,IAAM,CACnC,MAAMW,EAAMuC,EAAQlD,GACfW,EAAMyC,IACVA,EAAMzC,EACN0C,EAASpC,KAAKI,QAASrB,IAG1B2D,EAAKlD,GAAM4C,EAEZ,OAAOM,EAGR,OAAO1C,KAAK+B,WAAY7D,IASzBkF,EAAe3C,UAAUmC,aAAe,SAAuB1E,GAK9D,GAJKoE,GAAAA,CAAcpE,KAClBA,EAAIyB,GAAAA,CAASzB,IAGTqE,GAAAA,CAAcrE,GAAM,CACxB,MAAMsE,EAAOtE,EAAEgC,MAAO,GAChBwC,EAAM,IAAIR,MAAOM,GACvB,IAAM,IAAIhD,EAAI,EAAGA,EAAIgD,EAAMhD,IAAM,CAChC,IAAIyC,EAAS,IAAIC,MAAOlC,KAAKO,QAC7B,IAAM,IAAIxB,EAAI,EAAGA,EAAIiB,KAAKO,OAAQxB,IAAM,CACvC,MAAMkC,EAAIjB,KAAKI,QAASrB,GACxBkD,EAAQlD,GAAMiB,KAAKY,MAAOK,GAC1B,IAAM,IAAI3B,EAAI,EAAGA,EAAIU,KAAKG,EAAGb,IAAM,CAClC,MAAMI,EAAMxB,EAAEoD,IAAK9B,EAAGF,GAAMpB,EAAEoD,IAAK9B,EAAGF,GAAMU,KAAKuD,MAAMjC,IAAKhC,EAAGP,GAAM,EACrEkD,EAAQlD,IAAOW,GAGjB,MAAMmD,GAAIV,EAAAA,EAAAA,GAAKF,GACf,IAAIa,EAAU,EACd,IAAM,IAAI/D,EAAI,EAAGA,EAAIkD,EAAOjD,OAAQD,IACnC+D,GAAWC,GAAAA,CAAKd,EAAQlD,GAAM8D,GAE/B,MAAMG,EAAQH,EAAI1B,GAAAA,CAAI2B,GACtBb,GAASgB,EAAAA,EAAAA,GAAUhB,EAAQe,GAC3BN,EAAKlD,GAAMyC,EAAOZ,KAAKnD,GAAK6E,GAAAA,CAAK7E,KAElC,OAAOwE,EAGR,IAAIT,EAAS,IAAIC,MAAOlC,KAAKO,QAC7B,IAAM,IAAIxB,EAAI,EAAGA,EAAIiB,KAAKO,OAAQxB,IAAM,CACvC,MAAMkC,EAAIjB,KAAKI,QAASrB,GACxBkD,EAAQlD,GAAMiB,KAAKY,MAAOK,GAC1B,IAAM,IAAI3B,EAAI,EAAGA,EAAIU,KAAKG,EAAGb,IAAM,CAClC,MAAMI,EAAMxB,EAAGoB,GAAMU,KAAKuD,MAAMjC,IAAKhC,EAAGP,GACxCkD,EAAQlD,IAAOW,GAGjB,MAAMmD,GAAIV,EAAAA,EAAAA,GAAKF,GACf,IAAIa,EAAU,EACd,IAAM,IAAI/D,EAAI,EAAGA,EAAIkD,EAAOjD,OAAQD,IACnC+D,GAAWC,GAAAA,CAAKd,EAAQlD,GAAM8D,GAE/B,MAAMG,EAAQH,EAAI1B,GAAAA,CAAI2B,GAEtB,OADAb,GAASgB,EAAAA,EAAAA,GAAUhB,EAAQe,GACpBf,EAAOZ,KAAKnD,GAAK6E,GAAAA,CAAK7E,2CCnN9B,IAAI0F,EAAU,EAKd,MAqEMC,EAAW,EAAG3F,EAAAA,EAAGM,EAAAA,EAAGC,KAAAA,EAAMC,aAAAA,EAAcoF,YAAAA,MAC7C,IACC,MAAMC,EAAUD,EAAcjE,EAAAA,EAAsBtB,EAAAA,GAC9C,OAAEI,EAAF,WAAUC,EAAV,QAAsBgB,GAAYmE,EAAS7F,EAAGM,EAAGC,EAAMC,GACvDsF,EC7CR,SAAqB9F,EAAGM,GACvB,GAAK8D,GAAAA,CAAcpE,GAClBA,EAAIyB,GAAAA,CAASzB,QACP,IAAMqE,GAAAA,CAAcrE,GAE1B,MAAM,IAAI+F,UADE,8FAAgG/F,EAAI,KAGjH,IAAMgG,GAAAA,CAAa1F,GAClB,MAAM,IAAIyF,UAAW,2EAA6EzF,EAAI,KAGvG,OADY,IAAIuB,EAAa7B,EAAGM,GDmChB2F,CAAUxF,EAAQiB,GACjC,MAAO,CACNoE,OAAAA,EACApF,WAAAA,GAEA,MAAQwF,GACT,MAAO,KAiBT,MAAMC,UAAmBC,EAAAA,UACxBC,YAAaC,aACZC,MAAOD,KA2BW,KAClBxE,KAAKwE,MAAME,UAAW1E,KAAK2E,MAAMX,OAAQJ,OA7BrB,oHAGpBA,GAAW,EACX,MAAM,EAAE1F,EAAF,EAAKM,EAAL,KAAQC,EAAR,aAAcC,EAAd,YAA4BoF,GAAgBU,EAClDxE,KAAK2E,MAAQ,IACTd,EAAS,CAAE3F,EAAAA,EAAGM,EAAAA,EAAGC,KAAAA,EAAMC,aAAAA,EAAcoF,YAAAA,OACrCU,GAI0B,gCAAEI,EAAWC,GAC3C,GACCD,EAAUnG,OAASoG,EAAUpG,MAC7BmG,EAAUlG,eAAiBmG,EAAUnG,cACrCkG,EAAU1G,IAAM2G,EAAU3G,GAC1B0G,EAAUpG,IAAMqG,EAAUrG,GAC1BoG,EAAUd,cAAgBe,EAAUf,YACnC,CACD,MAAM,EAAE5F,EAAF,EAAKM,EAAL,KAAQC,EAAR,aAAcC,EAAd,YAA4BoF,GAAgBc,EAClD,MAAO,IACHf,EAAS,CAAE3F,EAAAA,EAAGM,EAAAA,EAAGC,KAAAA,EAAMC,aAAAA,EAAcoF,YAAAA,OACrCc,GAGL,OAAO,KAORE,SACC,MAAM,OAAEd,EAAF,WAAUpF,GAAeoB,KAAK2E,OAC9B,EAAEI,GAAM/E,KAAKwE,MACnB,OAAMR,EAIL,uBAAKgB,MAAO,CAAEC,UAAW,OAAQC,MAAO,SACvC,wBAAMC,UAAU,SAAUJ,EAAE,2BAA4B,CAAEvG,EAAGwB,KAAKwE,MAAMhG,EAAG4G,QAASxB,KAzInE,EAAEhF,EAAYoF,EAAQtF,EAAcqG,IAEvD,2BACC,wBAAMI,UAAU,SAASJ,EAAE,iBAA3B,KACA,gBAAC,IAAD,CAAOM,UAAQ,EAACC,KAAK,MACpB,6BACC,0BACEtB,EAAO5D,QAAQiB,KAAK,CAAEnD,EAAGsB,IAAO,sBAAI+F,IAAK/F,GAAItB,OAGhD,6BACC,0BACE8F,EAAO5D,QAAQiB,KAAK,CAAEnD,EAAGsB,IAAO,sBAAI+F,IAAK/F,GAAIuD,GAAAA,CAAIiB,EAAOpD,MAAO1C,IAAKsH,QAAS,SAIjF,wBAAML,UAAU,SAASJ,EAAE,gBAA3B,KACCnG,EAAWyC,KAAK,CAAEoE,EAAMjG,IACnBN,GAAAA,CAAUR,EAAc+G,GACnB,gBAAC,IAAD,CAAOJ,UAAQ,EAACC,KAAK,KAAKC,IAAK/F,GACvC,6BACC,0BACC,0BAAKiG,GACJzB,EAAO5D,QAAQiB,KAAK,CAAEnD,EAAGsB,IAAO,sBAAI+F,IAAK/F,GAAItB,OAGhD,6BACC,0BACC,0BAAK6G,EAAE,SACNf,EAAO5D,QAAQiB,KAAK,CAAEqE,EAAG3G,IAClB,sBAAIwG,IAAM,GAAE/F,KAAKT,KAAMiF,EAAOnD,GAAGS,IAAK9B,EAAGT,GAAIyG,QAAS,OAG/D,0BACC,0BAAKT,EAAE,OACNf,EAAO5D,QAAQiB,KAAK,CAAEqE,EAAG3G,IAClB,sBAAIwG,IAAM,GAAE/F,KAAKT,KAAMiF,EAAOjD,MAAMO,IAAK9B,EAAGT,GAAIyG,QAAS,SAM5D,gBAAC,IAAD,CAAOH,UAAQ,EAACC,KAAK,KAAKC,IAAK/F,GACvC,6BACC,0BACC,0BAAKiG,GACJzB,EAAO5D,QAAQiB,KAAK,CAAEnD,EAAGsB,IAAO,sBAAI+F,IAAK/F,GAAItB,OAGhD,6BACC,0BACC,0BAAK6G,EAAE,QACNf,EAAO5D,QAAQiB,KAAK,CAAEqE,EAAG3G,IAClB,sBAAIwG,IAAM,GAAE/F,KAAKT,KAAMiF,EAAOnD,GAAGS,IAAK9B,EAAGT,GAAIyG,QAAS,OAG/D,0BACC,0BAAKT,EAAE,OACNf,EAAO5D,QAAQiB,KAAK,CAAEqE,EAAG3G,IAClB,sBAAIwG,IAAM,GAAE/F,KAAKT,MAAO,EAAEiF,EAAOnD,GAAGS,IAAK9B,EAAGT,IAAKyG,QAAS,YA+EpEG,CAAc/G,EAAYoF,EAAQhE,KAAKwE,MAAM9F,aAAcqG,GAC3D/E,KAAKwE,MAAME,UAAY,gBAAC,IAAD,CAASkB,QAASb,EAAE,iCAC3C,gBAACc,EAAA,EAAD,CAAQC,QAAQ,YAAYR,KAAK,KAAKS,QAAS/F,KAAKgG,kBAAoBjB,EAAE,0BAC9D,MARP,gBAACkB,EAAA,EAAD,CAAOH,QAAQ,UAAUf,EAAE,wBAiBrCV,EAAW6B,aAAe,CACzBpC,aAAa,EACbY,UAAW,MAGZL,EAAW8B,UAAY,CACtB1H,KAAM2H,IAAAA,OAAAA,WACN5H,EAAG4H,IAAAA,UAAoB,CACtBA,IAAAA,OACAA,IAAAA,WAAsBC,EAAAA,KACpBC,WACHpI,EAAGkI,IAAAA,UAAoB,CACtBA,IAAAA,QAAmBA,IAAAA,UAAoB,CAAEA,IAAAA,OAAkBA,IAAAA,WAAsBC,EAAAA,MACjFD,IAAAA,OACAA,IAAAA,WAAsBC,EAAAA,KACpBC,WACH5H,aAAc0H,IAAAA,QAAmBA,IAAAA,QAAmBE,WACpDxC,YAAasC,IAAAA,KACb1B,UAAW0B,IAAAA,MAMZ,OAAeG,EAAAA,EAAAA,GAAiB,SAAhC,EAA4CC,EAAAA,EAAAA,GAAenC,yDElK3D,UAtBA,SAAgBnG,EAAGM,GAClB,IAAM0F,GAAAA,CAAahG,GAClB,MAAM,IAAI+F,UAAW,oFAAsF/F,EAAI,KAEhH,IAAMgG,GAAAA,CAAa1F,GAClB,MAAM,IAAIyF,UAAW,2FAA6FzF,EAAI,KAEvH,MAAMiI,EAAOzG,KAAKqC,QAASnE,GACrB+B,EAAIzB,EAAEQ,OACZ,IAAI0H,EAAW,EACf,IAAM,IAAIlH,EAAI,EAAGA,EAAIS,EAAGT,IAClBiH,EAAMjH,KAAQhB,EAAGgB,KACrBkH,GAAY,GAId,OADAA,GAAYzG,EACLyG,4DCiBR,IAhCA,SAAmB/D,EAAKzE,GACvB,MAAMyI,EAAQzC,GAAAA,CAAahG,GAC3B,IAAMgG,GAAAA,CAAavB,GAClB,MAAM,IAAIsB,UAAW,0DAA4DtB,EAAM,MAExF,IAAMgE,KAAUrI,EAAAA,EAAAA,aAAUJ,GACzB,MAAM,IAAI+F,UAAW,gGAAkG/F,EAAI,MAE5H,MAAM0I,EAAMjE,EAAI3D,OACVmE,EAAM,IAAIjB,MAAO0E,GAGvB,GAAKD,EAAQ,CACZ,GAAKC,IAAQ1I,EAAEc,OACd,MAAM,IAAI6H,MAAO,kGAElB,IAAM,IAAIrH,EAAI,EAAGA,EAAIoH,EAAKpH,IACzB2D,EAAK3D,GAAMmD,EAAKnD,GAAMtB,EAAGsB,QAK1B,IAAM,IAAIA,EAAI,EAAGA,EAAIoH,EAAKpH,IACzB2D,EAAK3D,GAAMmD,EAAKnD,GAAMtB,EAGxB,OAAOiF,0BCJR,IAAIb,EAAe,EAAQ,OAG3BwE,EAAOC,QAAUzE,yBCrBjB,IAwBIA,EAxBW,EAAQ,MAwBJ0E,CAtBL,EAAQ,QAwBtBF,EAAOC,QAAUzE","sources":["../node_modules/@isle-project/components/models/naive-bayes/design_matrix.js","../node_modules/@isle-project/components/models/naive-bayes/gaussian.js","../node_modules/@isle-project/components/models/naive-bayes/multinomial.js","../node_modules/@isle-project/components/models/naive-bayes/main.js","../node_modules/@isle-project/components/models/naive-bayes/naive_bayes.js","../node_modules/@isle-project/components/models/naive-bayes/score.js","../node_modules/@isle-project/utils/subtract/index.js","../node_modules/@stdlib/assert/is-array-array/lib/index.js","../node_modules/@stdlib/assert/is-array-array/lib/main.js"],"sourcesContent":["// MODULES //\n\nimport contains from '@stdlib/assert/contains';\nimport ndarray from '@stdlib/ndarray/array';\nimport { isPrimitive as isNumber } from '@stdlib/assert/is-number';\nimport isUndefinedOrNull from '@stdlib/assert/is-undefined-or-null';\nimport isnan from '@stdlib/assert/is-nan';\nimport isArray from '@stdlib/assert/is-array';\nimport extractCategoriesFromValues from '@isle-project/utils/extract-categories-from-values';\n\n\n// FUNCTIONS //\n\nfunction isMissing( x ) {\n\treturn isnan( x ) || isUndefinedOrNull( x );\n}\n\nfunction isNonMissingNumber( x ) {\n\treturn isNumber( x ) && !isnan( x );\n}\n\n\n// MAIN //\n\nexport function designMatrix( x, y, data, quantitative ) {\n\tlet matrix = [];\n\tconst predictors = [];\n\tconst hash = {};\n\tif ( !isArray( x ) ) {\n\t\tx = [ x ];\n\t}\n\tfor ( let j = 0; j < x.length; j++ ) {\n\t\tconst values = data[ x[ j ] ];\n\t\tif ( contains( quantitative, x[ j ] ) ) {\n\t\t\tpredictors.push( x[ j ] );\n\t\t} else {\n\t\t\tconst categories = extractCategoriesFromValues( values, x[ j ] );\n\t\t\tfor ( let k = 0; k < categories.length; k++ ) {\n\t\t\t\tpredictors.push( `${x[ j ]}_${categories[ k ]}` );\n\t\t\t}\n\t\t\thash[ x[ j ] ] = categories;\n\t\t}\n\t}\n\tconst nobs = data[ x[ 0 ] ].length;\n\tfor ( let i = 0; i < nobs; i++ ) {\n\t\tconst row = [];\n\t\tfor ( let j = 0; j < x.length; j++ ) {\n\t\t\tconst values = data[ x[ j ] ];\n\t\t\tif ( contains( quantitative, x[ j ] ) ) {\n\t\t\t\trow.push( values[ i ] );\n\t\t\t} else {\n\t\t\t\tconst categories = hash[ x[ j ] ];\n\t\t\t\tconst val = values[ i ];\n\t\t\t\tfor ( let k = 0; k < categories.length; k++ ) {\n\t\t\t\t\trow.push( ( val === categories[ k ] ) ? 1 : 0 );\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tmatrix.push( row );\n\t}\n\tmatrix = ndarray( matrix );\n\tconst yvalues = data[ y ];\n\treturn { matrix, predictors, yvalues };\n}\n\nexport function designMatrixMissing( x, y, data, quantitative ) {\n\tlet matrix = [];\n\tconst predictors = [];\n\tconst hash = {};\n\tif ( !isArray( x ) ) {\n\t\tx = [ x ];\n\t}\n\tfor ( let j = 0; j < x.length; j++ ) {\n\t\tconst values = data[ x[ j ] ];\n\t\tif ( contains( quantitative, x[ j ] ) ) {\n\t\t\tpredictors.push( x[ j ] );\n\t\t} else {\n\t\t\tconst categories = extractCategoriesFromValues( values, x[ j ] );\n\t\t\tfor ( let k = 0; k < categories.length; k++ ) {\n\t\t\t\tpredictors.push( `${x[ j ]}_${categories[ k ]}` );\n\t\t\t}\n\t\t\thash[ x[ j ] ] = categories;\n\t\t}\n\t}\n\tconst nobs = data[ x[ 0 ] ].length;\n\tconst yvalues = [];\n\tfor ( let i = 0; i < nobs; i++ ) {\n\t\tconst row = [];\n\t\tlet missing = false;\n\t\tfor ( let j = 0; j < x.length; j++ ) {\n\t\t\tconst values = data[ x[ j ] ];\n\t\t\tif ( contains( quantitative, x[ j ] ) ) {\n\t\t\t\tif ( isNonMissingNumber( values[ i ] ) ) {\n\t\t\t\t\trow.push( values[ i ] );\n\t\t\t\t} else {\n\t\t\t\t\tmissing = true;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tconst categories = hash[ x[ j ] ];\n\t\t\t\tconst val = values[ i ];\n\t\t\t\tif ( isMissing( val ) ) {\n\t\t\t\t\tmissing = true;\n\t\t\t\t} else {\n\t\t\t\t\tfor ( let k = 0; k < categories.length; k++ ) {\n\t\t\t\t\t\trow.push( ( val === categories[ k ] ) ? 1 : 0 );\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif ( isMissing( data[ y ][ i ] ) ) {\n\t\t\tmissing = true;\n\t\t}\n\t\tif ( !missing ) {\n\t\t\tmatrix.push( row );\n\t\t\tyvalues.push( data[ y ][ i ] );\n\t\t}\n\t}\n\tmatrix = ndarray( matrix );\n\treturn { matrix, predictors, yvalues };\n}\n","// MODULES //\n\nimport uniq from 'uniq';\nimport ndarray from '@stdlib/ndarray/array';\nimport isArrayArray from '@stdlib/assert/is-array-array';\nimport isMatrixLike from '@stdlib/assert/is-matrix-like';\nimport exp from '@stdlib/math/base/special/exp';\nimport ln from '@stdlib/math/base/special/ln';\nimport pow from '@stdlib/math/base/special/pow';\nimport PI from '@stdlib/constants/float64/pi';\nimport mean from '@isle-project/utils/statistic/mean';\nimport stdev from '@isle-project/utils/statistic/stdev';\nimport max from '@isle-project/utils/statistic/max';\nimport subtract from '@isle-project/utils/subtract';\n\n\n// MAIN //\n\n/**\n* Naive Bayes fitting object constructor for normal distribution.\n*\n* @constructor\n* @param {Matrix} x - design matrix\n* @param {Array} y - vector of class memberships\n* @returns {GaussianFit} GaussianFit instance\n*/\nfunction GaussianFit( x, y ) {\n\tthis.n = x.shape[ 0 ];\n\tthis.p = x.shape[ 1 ];\n\n\tthis.classes = uniq( y.slice() );\n\tthis.nclass = this.classes.length;\n\n\tthis.fitGaussian( x, y );\n}\n\nGaussianFit.prototype.score = require( './score.js' );\n\n\n/**\n* Fit the data under the assumption that p(x_i|c) follows a normal distribution.\n*\n* ## Notes\n*\n* -   Assigns prior and conditional probabilities of BayesFit instance.\n*\n* @param {Matrix} x - design matrix\n* @param {Array} y - vector of class memberships\n* @returns {void}\n*/\nGaussianFit.prototype.fitGaussian = function fitGaussian( x, y ) {\n\tthis.prior = {};\n\tconst shape = [ this.p, this.nclass ];\n\tthis.mu = ndarray( new Float64Array( shape[0]*shape[1] ), { 'shape': shape } );\n\tthis.sigma = ndarray( new Float64Array( shape[0]*shape[1] ), { 'shape': shape } );\n\tfor ( let i = 0; i < this.nclass; i++ ) {\n\t\tconst ids = [];\n\t\tconst c = this.classes[ i ];\n\t\tfor ( let j = 0; j < this.n; j++ ) {\n\t\t\tif ( y[ j ] === c ) {\n\t\t\t\tids.push( j );\n\t\t\t}\n\t\t}\n\t\tconst nc = ids.length;\n\t\tthis.prior[ c ] = ln( nc / this.n );\n\t\tfor ( let j = 0; j < this.p; j++ ) {\n\t\t\tconst vals = ids.map( i => x.get( i, j ) );\n\t\t\tconst mu = mean( vals );\n\t\t\tconst sigma = stdev( vals );\n\t\t\tthis.mu.set( j, i, mu );\n\t\t\tthis.sigma.set( j, i, sigma );\n\t\t}\n\t}\n};\n\n/**\n* Calculate p(X=x,C=i), i.e. the joint probability of observation x and class i.\n*\n* @param {Array} x - new observation\n* @param {number} i - class indicator\n* @returns {number} log probability\n*/\nGaussianFit.prototype.calcGaussianProb = function calcGaussianProb( x, i ) {\n\tconst c = this.classes[ i ];\n\tlet res = this.prior[ c ];\n\n\tfor ( let j = 0; j < this.p; j++ ) {\n\t\tconst sigma = this.sigma.get( j, i );\n\t\tconst s2 = sigma*sigma;\n\t\tconst mu = this.mu.get( j, i );\n\t\tconst val = ( -0.5 * ln( 2 * PI * s2 ) ) - ( pow( x[ j ] - mu, 2 ) / s2 );\n\t\tres += val;\n\t}\n\treturn res;\n};\n\n/**\n* Predict class membership for one new observation.\n*\n* @param {Array} x - new observation\n* @returns {(number|string)} predicted class membership\n*/\nGaussianFit.prototype.predictOne = function predictOne( x ) {\n\tconst nClasses = this.classes.length;\n\tconst logLik = new Array( nClasses );\n\tfor ( let i = 0; i < nClasses; i++ ) {\n\t\tlogLik[ i ] = this.calcGaussianProb( x, i );\n\t}\n\tlet max = logLik[ 0 ];\n\tlet argmax = this.classes[ 0 ];\n\tfor ( let i = 0; i < nClasses; i++ ) {\n\t\tconst val = logLik[ i ];\n\t\tif ( val > max ) {\n\t\t\tmax = val;\n\t\t\targmax = this.classes[ i ];\n\t\t}\n\t}\n\treturn argmax;\n};\n\n/**\n* Predict class membership for new observation(s).\n*\n* @param {(Matrix|Array)} x - new observation(s)\n* @returns {Array} array of predicted class memberships\n*/\nGaussianFit.prototype.predict = function predict( x ) {\n\tconst nClasses = this.classes.length;\n\tif ( isArrayArray( x ) ) {\n\t\tx = ndarray( x );\n\t}\n\t// Case A: Predictions for multiple observations:\n\tif ( isMatrixLike( x ) ) {\n\t\tconst [ nrow, ncol ] = x.shape;\n\t\tconst ret = new Array( nrow );\n\t\tfor ( let i = 0; i < nrow; i++ ) {\n\t\t\tconst logLik = new Array( nClasses );\n\t\t\tfor ( let j = 0; j < nClasses; j++ ) {\n\t\t\t\tconst arr = new Array( ncol );\n\t\t\t\tfor ( let k = 0; k < ncol; k++ ) {\n\t\t\t\t\tarr[ k ] = x.get( i, k );\n\t\t\t\t}\n\t\t\t\tlogLik[ j ] = this.calcGaussianProb( arr, j );\n\t\t\t}\n\t\t\tlet max = logLik[ 0 ];\n\t\t\tlet argmax = this.classes[ 0 ];\n\t\t\tfor ( let j = 0; j < nClasses; j++ ) {\n\t\t\t\tconst val = logLik[ j ];\n\t\t\t\tif ( val > max ) {\n\t\t\t\t\tmax = val;\n\t\t\t\t\targmax = this.classes[ j ];\n\t\t\t\t}\n\t\t\t}\n\t\t\tret[ i ] = argmax;\n\t\t}\n\t\treturn ret;\n\t}\n\t// Case B: Only one new observation:\n\treturn this.predictOne( x );\n};\n\n/**\n* Calculates class membership probabilities.\n*\n* @param {(Matrix|Array)} x - design matrix\n* @returns {Array} class probabilities\n*/\nGaussianFit.prototype.predictProbs = function predictProbs( x ) {\n\tif ( isArrayArray( x ) ) {\n\t\tx = ndarray( x );\n\t}\n\t// Case A: Predictions for multiple observations:\n\tif ( isMatrixLike( x ) ) {\n\t\tconst [ nrow, ncol ] = x.shape;\n\t\tconst ret = new Array( nrow );\n\t\tfor ( let i = 0; i < nrow; i++ ) {\n\t\t\tlet logLik = new Array( this.nclass );\n\t\t\tfor ( let j = 0; j < this.nclass; j++ ) {\n\t\t\t\tconst arr = new Array( ncol );\n\t\t\t\tfor ( let k = 0; k < ncol; k++ ) {\n\t\t\t\t\tarr[ k ] = x.get( i, k );\n\t\t\t\t}\n\t\t\t\tlogLik[ j ] = this.calcGaussianProb( arr, j );\n\t\t\t}\n\t\t\tconst a = max( logLik );\n\t\t\tlet summand = 0;\n\t\t\tfor ( let j = 0; j < logLik.length; j++ ) {\n\t\t\t\tsummand += exp( logLik[ j ] - a );\n\t\t\t}\n\t\t\tconst denom = a + ln( summand );\n\t\t\tlogLik = subtract( logLik, denom );\n\t\t\tret[ i ] = logLik.map( x => exp( x ) );\n\t\t}\n\t\treturn ret;\n\t}\n\t// Case B: Create prediction for a single observation:\n\tconst logLik = new Array( this.nclass );\n\tfor ( let j = 0; j < this.nclass; j++ ) {\n\t\tlogLik[ j ] = this.calcGaussianProb( x, j );\n\t}\n\tconst a = max( logLik );\n\tlet summand = 0;\n\tfor ( let j = 0; j < logLik.length; j++ ) {\n\t\tsummand += exp( logLik[ j ] - a );\n\t}\n\tconst denom = a + ln( summand );\n\tlogLik = subtract( logLik, denom );\n\treturn logLik.map( x => exp( x ) );\n};\n\n\n// EXPORTS //\n\nexport default GaussianFit;\n","// MODULES //\n\nimport uniq from 'uniq';\nimport ndarray from '@stdlib/ndarray/array';\nimport max from '@isle-project/utils/statistic/max';\nimport subtract from '@isle-project/utils/subtract';\nimport exp from '@stdlib/math/base/special/exp';\nimport isArrayArray from '@stdlib/assert/is-array-array';\nimport isMatrixLike from '@stdlib/assert/is-matrix-like';\nimport ln from '@stdlib/math/base/special/ln';\n\n\n// FUNCTIONS //\n\nconst sum = ( arr ) => {\n\tlet out = 0;\n\tfor ( let i = 0; i < arr.length; i++ ) {\n\t\tout += arr[ i ];\n\t}\n\treturn out;\n};\n\n\n// MAIN //\n\n/**\n* Naive Bayes fitting object constructor for multinomial distribution.\n*\n* @constructor\n* @param {Matrix} x - design matrix\n* @param {Array} y - vector of class memberships\n* @param {number} alpha - Laplace smoothing parameter\n* @returns {MultinomialFit} MultinomialFit instance\n*/\nfunction MultinomialFit( x, y, alpha ) {\n\tthis.n = x.shape[ 0 ];\n\tthis.p = x.shape[ 1 ];\n\n\tthis.classes = uniq( y.slice() );\n\tthis.nclass = this.classes.length;\n\tthis.alpha = alpha;\n\n\tthis.fitMultinomial( x, y );\n}\n\nMultinomialFit.prototype.score = require( './score.js' );\n\n\n/**\n* Fit the data under the assumption that p(x_i|c) follows a multinomial distribution.\n*\n* ## Notes\n*\n* -   Assigns prior and conditional probabilities of BayesFit instance.\n*\n* @param {Matrix} x - design matrix\n* @param {Array} y - vector of class memberships\n* @returns {Void}\n*/\nMultinomialFit.prototype.fitMultinomial = function fitMultinomial( x, y ) {\n\tconst prior = {};\n\tconst shape = [ this.p, this.nclass ];\n\tconst cprob = ndarray( new Float64Array( shape[0]*shape[1] ), { 'shape': shape } );\n\tfor ( let i = 0; i < this.nclass; i++ ) {\n\t\tconst ids = [];\n\t\tconst counts = new Int32Array( this.p );\n\t\tconst c = this.classes[ i ];\n\t\tfor ( let j = 0; j < this.n; j++ ) {\n\t\t\tif ( y[ j ] === c ) {\n\t\t\t\tids.push( j );\n\t\t\t}\n\t\t}\n\t\tconst nc = ids.length;\n\t\tprior[ c ] = ln( nc / this.n );\n\t\tlet totalCount = 0;\n\t\tfor ( let j = 0; j < this.p; j++ ) {\n\t\t\tconst vals = ids.map( i => x.get( i, j ) );\n\t\t\tcounts[ j ] = sum( vals );\n\t\t\ttotalCount += counts[ j ];\n\t\t}\n\t\tfor ( let j = 0; j < this.p; j++ ) {\n\t\t\tconst val = ln( counts[ j ] + this.alpha ) - ln( totalCount + this.p * this.alpha );\n\t\t\tcprob.set( j, i, val );\n\t\t}\n\t}\n\tthis.prior = prior;\n\tthis.cprob = cprob;\n};\n\n/**\n* Calculates multinomial probability.\n*\n* @param {Array} x - new observation\n* @param {number} i - class indicator\n* @param {number} j - variable indicator\n* @returns {number} probability\n*/\nMultinomialFit.prototype.calcMultinomProb = function calcMultinomProb( x, i, j ) {\n\tconst c = this.classes[ i ];\n\tlet res = this.prior[ c ];\n\tfor ( j = 0; j < this.p; j++ ) {\n\t\tconst val = x[ j ] ? x[ j ] * this.cprob.get( j, i ) : 0;\n\t\tres += val;\n\t}\n\treturn res;\n};\n\n/**\n* Predict class membership for one new observation.\n*\n* @param {Array} x - new observation\n* @returns {(number|string)} predicted class membership\n*/\nMultinomialFit.prototype.predictOne = function predictOne( x ) {\n\tconst nClasses = this.classes.length;\n\tconst logLik = new Array( nClasses );\n\tfor ( let i = 0; i < nClasses; i++ ) {\n\t\tconst c = this.classes[ i ];\n\t\tlogLik[ i ] = this.prior[ c ];\n\t\tfor ( let j = 0; j < this.p; j++ ) {\n\t\t\tconst val = x[ j ] ? x[ j ] * this.cprob.get( j, i ) : 0;\n\t\t\tlogLik[ i ] += val;\n\t\t}\n\t}\n\tlet max = logLik[ 0 ];\n\tlet argmax = this.classes[ 0 ];\n\tfor ( let i = 0; i < nClasses; i++ ) {\n\t\tconst val = logLik[ i ];\n\t\tif ( val > max ) {\n\t\t\tmax = val;\n\t\t\targmax = this.classes[ i ];\n\t\t}\n\t}\n\treturn argmax;\n};\n\n/**\n* Predict class membership for new observation(s).\n*\n* @param {(Matrix|Array)} x - new observation(s)\n* @returns {Array} array of predicted class memberships\n*/\nMultinomialFit.prototype.predict = function predict( x ) {\n\tconst nClasses = this.classes.length;\n\tif ( isArrayArray( x ) ) {\n\t\tx = ndarray( x );\n\t}\n\t// Case A: Predictions for multiple observations:\n\tif ( isMatrixLike( x ) ) {\n\t\tconst ret = [];\n\t\tconst nrow = x.shape[ 0 ];\n\t\tfor ( let i = 0; i < nrow; i++ ) {\n\t\t\tconst logLik = new Array( nClasses );\n\t\t\tfor ( let j = 0; j < nClasses; j++ ) {\n\t\t\t\tconst c = this.classes[ j ];\n\t\t\t\tlogLik[ j ] = this.prior[ c ];\n\t\t\t\tfor ( let k = 0; k < this.p; k++ ) {\n\t\t\t\t\tconst val = x.get( i, k ) ? x.get( i, k ) * this.cprob.get( k, j ) : 0;\n\t\t\t\t\tlogLik[ j ] += val;\n\t\t\t\t}\n\t\t\t}\n\t\t\tlet max = logLik[ 0 ];\n\t\t\tlet argmax = this.classes[ 0 ];\n\t\t\tfor ( let j = 0; j < nClasses; j++ ) {\n\t\t\t\t\tconst val = logLik[ j ];\n\t\t\t\t\tif ( val > max ) {\n\t\t\t\t\t\tmax = val;\n\t\t\t\t\t\targmax = this.classes[ j ];\n\t\t\t\t\t}\n\t\t\t}\n\t\t\tret[ i ] = argmax;\n\t\t}\n\t\treturn ret;\n\t}\n\t// Case B: Only one new observation:\n\treturn this.predictOne( x );\n};\n\n/**\n* Calculates class membership probabilities.\n*\n* @param {(Matrix|Array)} x - design matrix\n* @returns {Array} class probabilities\n*/\nMultinomialFit.prototype.predictProbs = function predictProbs( x ) {\n\tif ( isArrayArray( x ) ) {\n\t\tx = ndarray( x );\n\t}\n\t// Case A: Predictions for multiple observations:\n\tif ( isMatrixLike( x ) ) {\n\t\tconst nrow = x.shape[ 0 ];\n\t\tconst ret = new Array( nrow );\n\t\tfor ( let i = 0; i < nrow; i++ ) {\n\t\t\tlet logLik = new Array( this.nclass );\n\t\t\tfor ( let j = 0; j < this.nclass; j++ ) {\n\t\t\t\tconst c = this.classes[ j ];\n\t\t\t\tlogLik[ j ] = this.prior[ c ];\n\t\t\t\tfor ( let k = 0; k < this.p; k++ ) {\n\t\t\t\t\tconst val = x.get( i, k ) ? x.get( i, k ) * this.cprob.get( k, j ) : 0;\n\t\t\t\t\tlogLik[ j ] += val;\n\t\t\t\t}\n\t\t\t}\n\t\t\tconst a = max( logLik );\n\t\t\tlet summand = 0;\n\t\t\tfor ( let j = 0; j < logLik.length; j++ ) {\n\t\t\t\tsummand += exp( logLik[ j ] - a );\n\t\t\t}\n\t\t\tconst denom = a + ln( summand );\n\t\t\tlogLik = subtract( logLik, denom );\n\t\t\tret[ i ] = logLik.map( x => exp( x ) );\n\t\t}\n\t\treturn ret;\n\t}\n\t// Case B: Create prediction for a single observation:\n\tlet logLik = new Array( this.nclass );\n\tfor ( let j = 0; j < this.nclass; j++ ) {\n\t\tconst c = this.classes[ j ];\n\t\tlogLik[ j ] = this.prior[ c ];\n\t\tfor ( let k = 0; k < this.p; k++ ) {\n\t\t\tconst val = x[ k ] * this.cprob.get( k, j );\n\t\t\tlogLik[ j ] += val;\n\t\t}\n\t}\n\tconst a = max( logLik );\n\tlet summand = 0;\n\tfor ( let j = 0; j < logLik.length; j++ ) {\n\t\tsummand += exp( logLik[ j ] - a );\n\t}\n\tconst denom = a + ln( summand );\n\tlogLik = subtract( logLik, denom );\n\treturn logLik.map( x => exp( x ) );\n};\n\n\n// EXPORTS //\n\nexport default MultinomialFit;\n","// MODULES //\n\nimport React, { Component } from 'react';\nimport PropTypes from 'prop-types';\nimport { withTranslation } from 'react-i18next';\nimport Alert from 'react-bootstrap/Alert';\nimport Button from 'react-bootstrap/Button';\nimport Table from '@isle-project/components/table';\nimport contains from '@stdlib/assert/contains';\nimport exp from '@stdlib/math/base/special/exp';\nimport Tooltip from '@isle-project/components/tooltip';\nimport { gaussian } from './naive_bayes.js';\nimport { designMatrix, designMatrixMissing } from './design_matrix.js';\nimport { withPropCheck } from '@isle-project/utils/prop-check';\nimport { Factor } from '@isle-project/utils/factor-variable';\n\n\n// VARIABLES //\n\nlet COUNTER = 0;\n\n\n// FUNCTIONS //\n\nconst summaryTable = ( predictors, result, quantitative, t ) => {\n\treturn (\n\t\t<div>\n\t\t\t<span className=\"title\">{t('apriori-probs')}:</span>\n\t\t\t<Table bordered size=\"sm\">\n\t\t\t\t<thead>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t{result.classes.map( ( x, i ) => <th key={i}>{x}</th>)}\n\t\t\t\t\t</tr>\n\t\t\t\t</thead>\n\t\t\t\t<tbody>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t{result.classes.map( ( x, i ) => <th key={i}>{exp(result.prior[ x ]).toFixed( 3 )}</th>)}\n\t\t\t\t\t</tr>\n\t\t\t\t</tbody>\n\t\t\t</Table>\n\t\t\t<span className=\"title\">{t('conditionals')}:</span>\n\t\t\t{predictors.map( ( pred, i ) => {\n\t\t\t\tif ( contains( quantitative, pred ) ) {\n\t\t\t\t\treturn ( <Table bordered size=\"sm\" key={i} >\n\t\t\t\t\t\t<thead>\n\t\t\t\t\t\t\t<tr>\n\t\t\t\t\t\t\t\t<th>{pred}</th>\n\t\t\t\t\t\t\t\t{result.classes.map( ( x, i ) => <th key={i}>{x}</th>)}\n\t\t\t\t\t\t\t</tr>\n\t\t\t\t\t\t</thead>\n\t\t\t\t\t\t<tbody>\n\t\t\t\t\t\t\t<tr>\n\t\t\t\t\t\t\t\t<th>{t('mean')}</th>\n\t\t\t\t\t\t\t\t{result.classes.map( ( _, j ) => {\n\t\t\t\t\t\t\t\t\treturn <td key={`${i}-${j}`}>{result.mu.get( i, j ).toFixed( 6 )}</td>;\n\t\t\t\t\t\t\t\t})}\n\t\t\t\t\t\t\t</tr>\n\t\t\t\t\t\t\t<tr>\n\t\t\t\t\t\t\t\t<th>{t('sd')}</th>\n\t\t\t\t\t\t\t\t{result.classes.map( ( _, j ) => {\n\t\t\t\t\t\t\t\t\treturn <td key={`${i}-${j}`}>{result.sigma.get( i, j ).toFixed( 6 )}</td>;\n\t\t\t\t\t\t\t\t})}\n\t\t\t\t\t\t\t</tr>\n\t\t\t\t\t\t</tbody>\n\t\t\t\t\t</Table> );\n\t\t\t\t}\n\t\t\t\treturn ( <Table bordered size=\"sm\" key={i} >\n\t\t\t\t\t<thead>\n\t\t\t\t\t\t<tr>\n\t\t\t\t\t\t\t<th>{pred}</th>\n\t\t\t\t\t\t\t{result.classes.map( ( x, i ) => <th key={i}>{x}</th>)}\n\t\t\t\t\t\t</tr>\n\t\t\t\t\t</thead>\n\t\t\t\t\t<tbody>\n\t\t\t\t\t\t<tr>\n\t\t\t\t\t\t\t<th>{t('yes')}</th>\n\t\t\t\t\t\t\t{result.classes.map( ( _, j ) => {\n\t\t\t\t\t\t\t\treturn <td key={`${i}-${j}`}>{result.mu.get( i, j ).toFixed( 3 )}</td>;\n\t\t\t\t\t\t\t})}\n\t\t\t\t\t\t</tr>\n\t\t\t\t\t\t<tr>\n\t\t\t\t\t\t\t<th>{t('no')}</th>\n\t\t\t\t\t\t\t{result.classes.map( ( _, j ) => {\n\t\t\t\t\t\t\t\treturn <td key={`${i}-${j}`}>{(1-result.mu.get( i, j )).toFixed( 3 )}</td>;\n\t\t\t\t\t\t\t})}\n\t\t\t\t\t\t</tr>\n\t\t\t\t\t</tbody>\n\t\t\t\t</Table> );\n\t\t\t})}\n\t\t</div>\n\t);\n};\n\nconst fitModel = ({ x, y, data, quantitative, omitMissing }) => {\n\ttry {\n\t\tconst designM = omitMissing ? designMatrixMissing : designMatrix;\n\t\tconst { matrix, predictors, yvalues } = designM( x, y, data, quantitative );\n\t\tconst result = gaussian( matrix, yvalues );\n\t\treturn {\n\t\t\tresult,\n\t\t\tpredictors\n\t\t};\n\t} catch ( error ) {\n\t\treturn {};\n\t}\n};\n\n\n// MAIN //\n\n/**\n* Naive Bayes assuming that the predictors given the class membership follow a normal distribution.\n*\n* @property {Object} data - object of value arrays\n* @property {(string|Factor)} y - outcome variable\n* @property {(string|Factor|Array<(string|Factor)>)} x - one or more predictor variables\n* @property {Array<string>} quantitative - array of variables in `data` that are `quantitative`\n* @property {boolean} omitMissing - controls whether to omit missing values\n* @property {Function} onPredict - callback invoked with predictions and residuals after model fitting\n*/\nclass NaiveBayes extends Component {\n\tconstructor( props ) {\n\t\tsuper( props );\n\n\t\tCOUNTER += 1;\n\t\tconst { x, y, data, quantitative, omitMissing } = props;\n\t\tthis.state = {\n\t\t\t...fitModel({ x, y, data, quantitative, omitMissing }),\n\t\t\t...props\n\t\t};\n\t}\n\n\tstatic getDerivedStateFromProps( nextProps, prevState ) {\n\t\tif (\n\t\t\tnextProps.data !== prevState.data ||\n\t\t\tnextProps.quantitative !== prevState.quantitative ||\n\t\t\tnextProps.x !== prevState.x ||\n\t\t\tnextProps.y !== prevState.y ||\n\t\t\tnextProps.omitMissing !== prevState.omitMissing\n\t\t) {\n\t\t\tconst { x, y, data, quantitative, omitMissing } = nextProps;\n\t\t\treturn {\n\t\t\t\t...fitModel({ x, y, data, quantitative, omitMissing }),\n\t\t\t\t...nextProps\n\t\t\t};\n\t\t}\n\t\treturn null;\n\t}\n\n\thandlePrediction = () => {\n\t\tthis.props.onPredict( this.state.result, COUNTER );\n\t}\n\n\trender() {\n\t\tconst { result, predictors } = this.state;\n\t\tconst { t } = this.props;\n\t\tif ( !result ) {\n\t\t\treturn <Alert variant=\"danger\">{t('missing-attributes')}</Alert>;\n\t\t}\n\t\treturn (\n\t\t\t<div style={{ overflowX: 'auto', width: '100%' }}>\n\t\t\t\t<span className=\"title\" >{t('naive-bayes-for-response', { y: this.props.y, counter: COUNTER })}</span>\n\t\t\t\t{summaryTable( predictors, result, this.props.quantitative, t )}\n\t\t\t\t{this.props.onPredict ? <Tooltip tooltip={t('use-model-to-predict-tooltip')} >\n\t\t\t\t\t<Button variant=\"secondary\" size=\"sm\" onClick={this.handlePrediction} >{t('use-model-to-predict')}</Button>\n\t\t\t\t</Tooltip> : null}\n\t\t\t</div>\n\t\t);\n\t}\n}\n\n\n// PROPERTIES //\n\nNaiveBayes.defaultProps = {\n\tomitMissing: false,\n\tonPredict: null\n};\n\nNaiveBayes.propTypes = {\n\tdata: PropTypes.object.isRequired,\n\ty: PropTypes.oneOfType([\n\t\tPropTypes.string,\n\t\tPropTypes.instanceOf( Factor )\n\t]).isRequired,\n\tx: PropTypes.oneOfType([\n\t\tPropTypes.arrayOf( PropTypes.oneOfType([ PropTypes.string, PropTypes.instanceOf( Factor ) ]) ),\n\t\tPropTypes.string,\n\t\tPropTypes.instanceOf( Factor )\n\t]).isRequired,\n\tquantitative: PropTypes.arrayOf( PropTypes.string ).isRequired,\n\tomitMissing: PropTypes.bool,\n\tonPredict: PropTypes.func\n};\n\n\n// EXPORTS //\n\nexport default withTranslation( 'models' )( withPropCheck( NaiveBayes ) );\n","// MODULES //\n\nimport ndarray from '@stdlib/ndarray/array';\nimport hasOwnProperty from '@stdlib/assert/has-own-property';\nimport isArrayArray from '@stdlib/assert/is-array-array';\nimport isArrayLike from '@stdlib/assert/is-array-like';\nimport isMatrixLike from '@stdlib/assert/is-matrix-like';\nimport { isPrimitive as isNumber } from '@stdlib/assert/is-number';\nimport GaussianFit from './gaussian.js';\nimport MultinomialFit from './multinomial.js';\n\n\n// MAIN //\n\n/**\n* Fits a multinomial naive Bayes model.\n*\n* @param {(Matrix|Array)} x - design matrix\n* @param {Array} y - vector of class memberships\n* @param {Object} [opts] - function options\n* @param {number} [opts.alpha] - Laplace smoothing parameter\n* @returns {MultinomialFit} MultinomialFit instance\n*/\nfunction multinomNB( x, y, opts ) {\n\tif ( isArrayArray( x ) ) {\n\t\tx = ndarray( x );\n\t} else if ( !isMatrixLike( x ) ) {\n\t\tconst msg = 'invalid input argument. The first argument must be a matrix or an array-of-arrays. Value: `' + x + '`';\n\t\tthrow new TypeError( msg );\n\t}\n\tif ( !isArrayLike( y ) ) {\n\t\tthrow new TypeError( 'invalid input argument. The second argument must be array-like. Value: `' + y + '`' );\n\t}\n\tif ( arguments > 2 ) {\n\t\tif ( hasOwnProperty( opts, 'alpha' ) ) {\n\t\t\tif ( !isNumber( opts.alpha ) ) {\n\t\t\t\tthrow new TypeError( 'invalid option. Laplace smoothing option must be a number primitive. Option: `' + opts.alpha + '`.' );\n\t\t\t}\n\t\t}\n\t}\n\tconst alpha = opts.alpha || 1;\n\tconst fit = new MultinomialFit( x, y, alpha );\n\treturn fit;\n}\n\n/**\n* Fits a Gaussian naive Bayes model.\n*\n* @param {(Matrix|Array)} x - design matrix\n* @param {Array} y - vector of class memberships\n* @returns {GaussianFit} model fit\n*/\nfunction gaussianNB( x, y ) {\n\tif ( isArrayArray( x ) ) {\n\t\tx = ndarray( x );\n\t} else if ( !isMatrixLike( x ) ) {\n\t\tconst msg = 'invalid input argument. The first argument must be a matrix or an array-of-arrays. Value: `' + x + '`';\n\t\tthrow new TypeError( msg );\n\t}\n\tif ( !isArrayLike( y ) ) {\n\t\tthrow new TypeError( 'invalid input argument. The second argument must be array-like. Value: `' + y + '`' );\n\t}\n\tconst fit = new GaussianFit( x, y );\n\treturn fit;\n}\n\n\n// EXPORTS //\n\nexport { multinomNB as multinomial, gaussianNB as gaussian };\n","// MODULES //\n\nimport isArrayLike from '@stdlib/assert/is-array-like';\n\n\n// MAIN //\n\n/**\n* Calculates the mean accuracy of the given test data and labels.\n*\n* @param {(Matrix|Array)} x - design matrix\n* @param {Array} y - vector of class memberships\n* @returns {number} mean accuracy\n*/\nfunction score( x, y ) {\n\tif ( !isArrayLike( x ) ) {\n\t\tthrow new TypeError( 'invalid argument. First argument must be a matrix or array of test data. Value: `' + x + '`' );\n\t}\n\tif ( !isArrayLike( y ) ) {\n\t\tthrow new TypeError( 'invalid argument. Second argument must be an array of labels for the test data. Value: `' + y + '`' );\n\t}\n\tconst yhat = this.predict( x ); // eslint-disable-line @babel/no-invalid-this\n\tconst n = y.length;\n\tlet accuracy = 0;\n\tfor ( let i = 0; i < n; i++ ) {\n\t\tif ( yhat[ i ] === y[ i ] ) {\n\t\t\taccuracy += 1;\n\t\t}\n\t}\n\taccuracy /= n;\n\treturn accuracy;\n}\n\n\n// EXPORTS //\n\nexport default score;\n","// MODULES //\n\nimport isArrayLike from '@stdlib/assert/is-array-like';\nimport { isPrimitive as isNumber } from '@stdlib/assert/is-number';\n\n\n// MAIN //\n\n/**\n* Computes an element-wise subtraction.\n*\n* @param {NumberArray} arr - input array\n* @param {(NumberArray|number)} x - either an array of equal length or a scalar\n* @returns {NumberArray} output array\n*/\nfunction subtract( arr, x ) {\n\tconst isArr = isArrayLike( x );\n\tif ( !isArrayLike( arr ) ) {\n\t\tthrow new TypeError( 'invalid input argument. Must provide an array. Value: `' + arr + '`.' );\n\t}\n\tif ( !isArr && !isNumber( x ) ) {\n\t\tthrow new TypeError( 'invalid input argument. Second argument must either be an array or number primitive. Value: `' + x + '`.' );\n\t}\n\tconst len = arr.length;\n\tconst out = new Array( len );\n\n\t// Case 1: x is an array\n\tif ( isArr ) {\n\t\tif ( len !== x.length ) {\n\t\t\tthrow new Error( 'invalid input argument. Array to be added must have a length equal to that of the input array.' );\n\t\t}\n\t\tfor ( let i = 0; i < len; i++ ) {\n\t\t\tout[ i ] = arr[ i ] - x[ i ];\n\t\t}\n\t}\n\t// Case 2: scalar\n\telse {\n\t\tfor ( let i = 0; i < len; i++ ) {\n\t\t\tout[ i ] = arr[ i ] - x;\n\t\t}\n\t}\n\treturn out;\n}\n\n\n// EXPORTS //\n\nexport default subtract;\n","/**\n* @license Apache-2.0\n*\n* Copyright (c) 2018 The Stdlib Authors.\n*\n* Licensed under the Apache License, Version 2.0 (the \"License\");\n* you may not use this file except in compliance with the License.\n* You may obtain a copy of the License at\n*\n*    http://www.apache.org/licenses/LICENSE-2.0\n*\n* Unless required by applicable law or agreed to in writing, software\n* distributed under the License is distributed on an \"AS IS\" BASIS,\n* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n* See the License for the specific language governing permissions and\n* limitations under the License.\n*/\n'use strict';\n/**\n* Test if a value is an array of arrays.\n*\n* @module @stdlib/assert/is-array-array\n*\n* @example\n* var isArrayArray = require( '@stdlib/assert/is-array-array' );\n*\n* var bool = isArrayArray( [ [], [] ] );\n* // returns true\n*\n* bool = isArrayArray( [ {}, {} ] );\n* // returns false\n*\n* bool = isArrayArray( [] );\n* // returns false\n*/\n// MODULES //\n\nvar isArrayArray = require('./main.js'); // EXPORTS //\n\n\nmodule.exports = isArrayArray;","/**\n* @license Apache-2.0\n*\n* Copyright (c) 2018 The Stdlib Authors.\n*\n* Licensed under the Apache License, Version 2.0 (the \"License\");\n* you may not use this file except in compliance with the License.\n* You may obtain a copy of the License at\n*\n*    http://www.apache.org/licenses/LICENSE-2.0\n*\n* Unless required by applicable law or agreed to in writing, software\n* distributed under the License is distributed on an \"AS IS\" BASIS,\n* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n* See the License for the specific language governing permissions and\n* limitations under the License.\n*/\n'use strict'; // MODULES //\n\nvar arrayfun = require('./../../tools/array-function');\n\nvar isArray = require('./../../is-array'); // MAIN //\n\n/**\n* Tests if a value is an array of arrays.\n*\n* @name isArrayArray\n* @type {Function}\n* @param {*} value - value to test\n* @returns {boolean} boolean indicating whether a value is an array of arrays\n*\n* @example\n* var bool = isArrayArray( [ [], [] ] );\n* // returns true\n*\n* bool = isArrayArray( [ {}, {} ] );\n* // returns false\n*\n* bool = isArrayArray( [] );\n* // returns false\n*/\n\n\nvar isArrayArray = arrayfun(isArray); // EXPORTS //\n\nmodule.exports = isArrayArray;"],"names":["isMissing","x","isnan","isUndefinedOrNull","isNonMissingNumber","isNumber","designMatrix","y","data","quantitative","matrix","predictors","hash","isArray","j","length","values","contains","push","categories","extractCategoriesFromValues","k","nobs","i","row","val","ndarray","yvalues","designMatrixMissing","missing","GaussianFit","this","n","shape","p","classes","uniq","slice","nclass","fitGaussian","prototype","score","require","prior","mu","Float64Array","sigma","ids","c","nc","ln","vals","map","get","mean","stdev","set","calcGaussianProb","res","s2","PI","pow","predictOne","nClasses","logLik","Array","max","argmax","predict","isArrayArray","isMatrixLike","nrow","ncol","ret","arr","predictProbs","a","summand","exp","denom","subtract","sum","out","MultinomialFit","alpha","fitMultinomial","cprob","counts","Int32Array","totalCount","calcMultinomProb","COUNTER","fitModel","omitMissing","designM","result","TypeError","isArrayLike","gaussian","error","NaiveBayes","Component","constructor","props","super","onPredict","state","nextProps","prevState","render","t","style","overflowX","width","className","counter","bordered","size","key","toFixed","pred","_","summaryTable","tooltip","Button","variant","onClick","handlePrediction","Alert","defaultProps","propTypes","PropTypes","Factor","isRequired","withTranslation","withPropCheck","yhat","accuracy","isArr","len","Error","module","exports","arrayfun"],"sourceRoot":""}