{"version":3,"file":"static/js/NaiveBayes.010c6c46.chunk.js","mappings":";2SAaA,SAASA,EAAWC,GACnB,OAAOC,GAAAA,CAAOD,IAAOE,GAAAA,CAAmBF,GAGzC,SAASG,EAAoBH,GAC5B,OAAOI,EAAAA,EAAAA,aAAUJ,KAAQC,GAAAA,CAAOD,GAM1B,SAASK,EAAcL,EAAGM,EAAGC,EAAMC,GACzC,IAAIC,EAAS,GACPC,EAAa,GACbC,EAAO,GACPC,GAAAA,CAASZ,KACdA,EAAI,CAAEA,IAEP,IAAM,IAAIa,EAAI,EAAGA,EAAIb,EAAEc,OAAQD,IAAM,CACpC,IAAME,EAASR,EAAMP,EAAGa,IACxB,GAAKG,GAAAA,CAAUR,EAAcR,EAAGa,IAC/BH,EAAWO,KAAMjB,EAAGa,QACd,CAEN,IADA,IAAMK,GAAaC,EAAAA,EAAAA,GAA6BJ,EAAQf,EAAGa,IACjDO,EAAI,EAAGA,EAAIF,EAAWJ,OAAQM,IACvCV,EAAWO,KAAX,UAAoBjB,EAAGa,GAAvB,YAA8BK,EAAYE,KAE3CT,EAAMX,EAAGa,IAAQK,GAInB,IADA,IAAMG,EAAOd,EAAMP,EAAG,IAAMc,OAClBQ,EAAI,EAAGA,EAAID,EAAMC,IAAM,CAEhC,IADA,IAAMC,EAAM,GACFV,EAAI,EAAGA,EAAIb,EAAEc,OAAQD,IAAM,CACpC,IAAME,EAASR,EAAMP,EAAGa,IACxB,GAAKG,GAAAA,CAAUR,EAAcR,EAAGa,IAC/BU,EAAIN,KAAMF,EAAQO,SAIlB,IAFA,IAAMJ,EAAaP,EAAMX,EAAGa,IACtBW,EAAMT,EAAQO,GACVF,EAAI,EAAGA,EAAIF,EAAWJ,OAAQM,IACvCG,EAAIN,KAAQO,IAAQN,EAAYE,GAAQ,EAAI,GAI/CX,EAAOQ,KAAMM,GAId,MAAO,CAAEd,OAFTA,EAASgB,GAAAA,CAAShB,GAEDC,WAAAA,EAAYgB,QADbnB,EAAMD,IAIhB,SAASqB,EAAqB3B,EAAGM,EAAGC,EAAMC,GAChD,IAAIC,EAAS,GACPC,EAAa,GACbC,EAAO,GACPC,GAAAA,CAASZ,KACdA,EAAI,CAAEA,IAEP,IAAM,IAAIa,EAAI,EAAGA,EAAIb,EAAEc,OAAQD,IAAM,CACpC,IAAME,EAASR,EAAMP,EAAGa,IACxB,GAAKG,GAAAA,CAAUR,EAAcR,EAAGa,IAC/BH,EAAWO,KAAMjB,EAAGa,QACd,CAEN,IADA,IAAMK,GAAaC,EAAAA,EAAAA,GAA6BJ,EAAQf,EAAGa,IACjDO,EAAI,EAAGA,EAAIF,EAAWJ,OAAQM,IACvCV,EAAWO,KAAX,UAAoBjB,EAAGa,GAAvB,YAA8BK,EAAYE,KAE3CT,EAAMX,EAAGa,IAAQK,GAKnB,IAFA,IAAMG,EAAOd,EAAMP,EAAG,IAAMc,OACtBY,EAAU,GACNJ,EAAI,EAAGA,EAAID,EAAMC,IAAM,CAGhC,IAFA,IAAMC,EAAM,GACRK,GAAU,EACJf,EAAI,EAAGA,EAAIb,EAAEc,OAAQD,IAAM,CACpC,IAAME,EAASR,EAAMP,EAAGa,IACxB,GAAKG,GAAAA,CAAUR,EAAcR,EAAGa,IAC1BV,EAAoBY,EAAQO,IAChCC,EAAIN,KAAMF,EAAQO,IAElBM,GAAU,MAEL,CACN,IAAMV,EAAaP,EAAMX,EAAGa,IACtBW,EAAMT,EAAQO,GACpB,GAAKvB,EAAWyB,GACfI,GAAU,OAEV,IAAM,IAAIR,EAAI,EAAGA,EAAIF,EAAWJ,OAAQM,IACvCG,EAAIN,KAAQO,IAAQN,EAAYE,GAAQ,EAAI,IAK3CrB,EAAWQ,EAAMD,GAAKgB,MAC1BM,GAAU,GAELA,IACLnB,EAAOQ,KAAMM,GACbG,EAAQT,KAAMV,EAAMD,GAAKgB,KAI3B,MAAO,CAAEb,OADTA,EAASgB,GAAAA,CAAShB,GACDC,WAAAA,EAAYgB,QAAAA,ofC5F9B,SAASG,EAAa7B,EAAGM,GACxBwB,KAAKC,EAAI/B,EAAEgC,MAAO,GAClBF,KAAKG,EAAIjC,EAAEgC,MAAO,GAElBF,KAAKI,QAAUC,GAAAA,CAAM7B,EAAE8B,SACvBN,KAAKO,OAASP,KAAKI,QAAQpB,OAE3BgB,KAAKQ,YAAatC,EAAGM,GAGtBuB,EAAYU,UAAUC,MAAQC,EAAS,OAcvCZ,EAAYU,UAAUD,YAAc,SAAsBtC,EAAGM,GAAK,IAAD,OAChEwB,KAAKY,MAAQ,GACb,IAAMV,EAAQ,CAAEF,KAAKG,EAAGH,KAAKO,QAC7BP,KAAKa,GAAKlB,GAAAA,CAAS,IAAImB,aAAcZ,EAAM,GAAGA,EAAM,IAAM,CAAE,MAASA,IACrEF,KAAKe,MAAQpB,GAAAA,CAAS,IAAImB,aAAcZ,EAAM,GAAGA,EAAM,IAAM,CAAE,MAASA,IACxE,IAAM,IAAIV,EAAI,EAAGA,EAAIQ,KAAKO,OAAQf,IAAM,CAGvC,IAFA,IAAMwB,EAAM,GACNC,EAAIjB,KAAKI,QAASZ,GACdT,EAAI,EAAGA,EAAIiB,KAAKC,EAAGlB,IACvBP,EAAGO,KAAQkC,GACfD,EAAI7B,KAAMJ,GAGZ,IAAMmC,EAAKF,EAAIhC,OACfgB,KAAKY,MAAOK,GAAME,GAAAA,CAAID,EAAKlB,KAAKC,GAChC,IAVuC,eAU7BlB,GACT,IAAMqC,EAAOJ,EAAIK,KAAK,SAAA7B,GAAC,OAAItB,EAAEoD,IAAK9B,EAAGT,MAC/B8B,GAAKU,EAAAA,EAAAA,GAAMH,GACXL,GAAQS,EAAAA,EAAAA,GAAOJ,GACrB,EAAKP,GAAGY,IAAK1C,EAAGS,EAAGqB,GACnB,EAAKE,MAAMU,IAAK1C,EAAGS,EAAGuB,IALbhC,EAAI,EAAGA,EAAIiB,KAAKG,EAAGpB,IAAO,EAA1BA,KAiBZgB,EAAYU,UAAUiB,iBAAmB,SAA2BxD,EAAGsB,GAItE,IAHA,IAAMyB,EAAIjB,KAAKI,QAASZ,GACpBmC,EAAM3B,KAAKY,MAAOK,GAEZlC,EAAI,EAAGA,EAAIiB,KAAKG,EAAGpB,IAAM,CAClC,IAAMgC,EAAQf,KAAKe,MAAMO,IAAKvC,EAAGS,GAC3BoC,EAAKb,EAAMA,EACXF,EAAKb,KAAKa,GAAGS,IAAKvC,EAAGS,GAE3BmC,IADe,GAAMR,GAAAA,CAAI,EAAIU,IAAKD,GAAWE,GAAAA,CAAK5D,EAAGa,GAAM8B,EAAI,GAAMe,EAGtE,OAAOD,GASR5B,EAAYU,UAAUsB,WAAa,SAAqB7D,GAGvD,IAFA,IAAM8D,EAAWhC,KAAKI,QAAQpB,OACxBiD,EAAS,IAAIC,MAAOF,GAChBxC,EAAI,EAAGA,EAAIwC,EAAUxC,IAC9ByC,EAAQzC,GAAMQ,KAAK0B,iBAAkBxD,EAAGsB,GAIzC,IAFA,IAAI2C,EAAMF,EAAQ,GACdG,EAASpC,KAAKI,QAAS,GACjBZ,EAAI,EAAGA,EAAIwC,EAAUxC,IAAM,CACpC,IAAME,EAAMuC,EAAQzC,GACfE,EAAMyC,IACVA,EAAMzC,EACN0C,EAASpC,KAAKI,QAASZ,IAGzB,OAAO4C,GASRrC,EAAYU,UAAU4B,QAAU,SAAkBnE,GACjD,IAAM8D,EAAWhC,KAAKI,QAAQpB,OAK9B,GAJKsD,GAAAA,CAAcpE,KAClBA,EAAIyB,GAAAA,CAASzB,IAGTqE,GAAAA,CAAcrE,GAAM,CAGxB,IAFA,cAAuBA,EAAEgC,MAAzB,GAAQsC,EAAR,KAAcC,EAAd,KACMC,EAAM,IAAIR,MAAOM,GACbhD,EAAI,EAAGA,EAAIgD,EAAMhD,IAAM,CAEhC,IADA,IAAMyC,EAAS,IAAIC,MAAOF,GAChBjD,EAAI,EAAGA,EAAIiD,EAAUjD,IAAM,CAEpC,IADA,IAAM4D,EAAM,IAAIT,MAAOO,GACbnD,EAAI,EAAGA,EAAImD,EAAMnD,IAC1BqD,EAAKrD,GAAMpB,EAAEoD,IAAK9B,EAAGF,GAEtB2C,EAAQlD,GAAMiB,KAAK0B,iBAAkBiB,EAAK5D,GAI3C,IAFA,IAAIoD,EAAMF,EAAQ,GACdG,EAASpC,KAAKI,QAAS,GACjBrB,EAAI,EAAGA,EAAIiD,EAAUjD,IAAM,CACpC,IAAMW,EAAMuC,EAAQlD,GACfW,EAAMyC,IACVA,EAAMzC,EACN0C,EAASpC,KAAKI,QAASrB,IAGzB2D,EAAKlD,GAAM4C,EAEZ,OAAOM,EAGR,OAAO1C,KAAK+B,WAAY7D,IASzB6B,EAAYU,UAAUmC,aAAe,SAAuB1E,GAK3D,GAJKoE,GAAAA,CAAcpE,KAClBA,EAAIyB,GAAAA,CAASzB,IAGTqE,GAAAA,CAAcrE,GAAM,CAGxB,IAFA,cAAuBA,EAAEgC,MAAzB,GAAQsC,EAAR,KAAcC,EAAd,KACMC,EAAM,IAAIR,MAAOM,GACbhD,EAAI,EAAGA,EAAIgD,EAAMhD,IAAM,CAEhC,IADA,IAAIyC,EAAS,IAAIC,MAAOlC,KAAKO,QACnBxB,EAAI,EAAGA,EAAIiB,KAAKO,OAAQxB,IAAM,CAEvC,IADA,IAAM4D,EAAM,IAAIT,MAAOO,GACbnD,EAAI,EAAGA,EAAImD,EAAMnD,IAC1BqD,EAAKrD,GAAMpB,EAAEoD,IAAK9B,EAAGF,GAEtB2C,EAAQlD,GAAMiB,KAAK0B,iBAAkBiB,EAAK5D,GAI3C,IAFA,IAAM8D,GAAIV,EAAAA,EAAAA,GAAKF,GACXa,EAAU,EACJ/D,EAAI,EAAGA,EAAIkD,EAAOjD,OAAQD,IACnC+D,GAAWC,GAAAA,CAAKd,EAAQlD,GAAM8D,GAE/B,IAAMG,EAAQH,EAAI1B,GAAAA,CAAI2B,GACtBb,GAASgB,EAAAA,EAAAA,GAAUhB,EAAQe,GAC3BN,EAAKlD,GAAMyC,EAAOZ,KAAK,SAAAnD,GAAC,OAAI6E,GAAAA,CAAK7E,MAElC,OAAOwE,EAIR,IADA,IAAMT,EAAS,IAAIC,MAAOlC,KAAKO,QACrBxB,EAAI,EAAGA,EAAIiB,KAAKO,OAAQxB,IACjCkD,EAAQlD,GAAMiB,KAAK0B,iBAAkBxD,EAAGa,GAIzC,IAFA,IAAM8D,GAAIV,EAAAA,EAAAA,GAAKF,GACXa,EAAU,EACJ/D,EAAI,EAAGA,EAAIkD,EAAOjD,OAAQD,IACnC+D,GAAWC,GAAAA,CAAKd,EAAQlD,GAAM8D,GAE/B,IAAMG,EAAQH,EAAI1B,GAAAA,CAAI2B,GAEtB,OADSG,EAAAA,EAAAA,GAAUhB,EAAQe,IAA3B,iBACOf,EAAOZ,KAAK,SAAAnD,GAAC,OAAI6E,GAAAA,CAAK7E,OAM9B,QCvMMgF,EAAM,SAAEP,GAEb,IADA,IAAIQ,EAAM,EACA3D,EAAI,EAAGA,EAAImD,EAAI3D,OAAQQ,IAChC2D,GAAOR,EAAKnD,GAEb,OAAO2D,GAeR,SAASC,EAAgBlF,EAAGM,EAAG6E,GAC9BrD,KAAKC,EAAI/B,EAAEgC,MAAO,GAClBF,KAAKG,EAAIjC,EAAEgC,MAAO,GAElBF,KAAKI,QAAUC,GAAAA,CAAM7B,EAAE8B,SACvBN,KAAKO,OAASP,KAAKI,QAAQpB,OAC3BgB,KAAKqD,MAAQA,EAEbrD,KAAKsD,eAAgBpF,EAAGM,GAGzB4E,EAAe3C,UAAUC,MAAQC,EAAS,OAc1CyC,EAAe3C,UAAU6C,eAAiB,SAAyBpF,EAAGM,GAIrE,IAHA,IAAMoC,EAAQ,GACRV,EAAQ,CAAEF,KAAKG,EAAGH,KAAKO,QACvBgD,EAAQ5D,GAAAA,CAAS,IAAImB,aAAcZ,EAAM,GAAGA,EAAM,IAAM,CAAE,MAASA,IAC/DV,EAAI,EAAGA,EAAIQ,KAAKO,OAAQf,IAAM,CAIvC,IAHA,IAAMwB,EAAM,GACNwC,EAAS,IAAIC,WAAYzD,KAAKG,GAC9Bc,EAAIjB,KAAKI,QAASZ,GACdT,EAAI,EAAGA,EAAIiB,KAAKC,EAAGlB,IACvBP,EAAGO,KAAQkC,GACfD,EAAI7B,KAAMJ,GAGZ,IAAMmC,EAAKF,EAAIhC,OACf4B,EAAOK,GAAME,GAAAA,CAAID,EAAKlB,KAAKC,GAE3B,IADA,IAAIyD,EAAa,EAXsB,WAY7B3E,GACT,IAAMqC,EAAOJ,EAAIK,KAAK,SAAA7B,GAAC,OAAItB,EAAEoD,IAAK9B,EAAGT,MACrCyE,EAAQzE,GAAMmE,EAAK9B,GACnBsC,GAAcF,EAAQzE,IAHbA,EAAI,EAAGA,EAAIiB,KAAKG,EAAGpB,IAAO,EAA1BA,GAKV,IAAM,IAAIA,EAAI,EAAGA,EAAIiB,KAAKG,EAAGpB,IAAM,CAClC,IAAMW,EAAMyB,GAAAA,CAAIqC,EAAQzE,GAAMiB,KAAKqD,OAAUlC,GAAAA,CAAIuC,EAAa1D,KAAKG,EAAIH,KAAKqD,OAC5EE,EAAM9B,IAAK1C,EAAGS,EAAGE,IAGnBM,KAAKY,MAAQA,EACbZ,KAAKuD,MAAQA,GAWdH,EAAe3C,UAAUkD,iBAAmB,SAA2BzF,EAAGsB,EAAGT,GAC5E,IAAMkC,EAAIjB,KAAKI,QAASZ,GACpBmC,EAAM3B,KAAKY,MAAOK,GACtB,IAAMlC,EAAI,EAAGA,EAAIiB,KAAKG,EAAGpB,IAAM,CAE9B4C,GADYzD,EAAGa,GAAMb,EAAGa,GAAMiB,KAAKuD,MAAMjC,IAAKvC,EAAGS,GAAM,EAGxD,OAAOmC,GASRyB,EAAe3C,UAAUsB,WAAa,SAAqB7D,GAG1D,IAFA,IAAM8D,EAAWhC,KAAKI,QAAQpB,OACxBiD,EAAS,IAAIC,MAAOF,GAChBxC,EAAI,EAAGA,EAAIwC,EAAUxC,IAAM,CACpC,IAAMyB,EAAIjB,KAAKI,QAASZ,GACxByC,EAAQzC,GAAMQ,KAAKY,MAAOK,GAC1B,IAAM,IAAIlC,EAAI,EAAGA,EAAIiB,KAAKG,EAAGpB,IAAM,CAClC,IAAMW,EAAMxB,EAAGa,GAAMb,EAAGa,GAAMiB,KAAKuD,MAAMjC,IAAKvC,EAAGS,GAAM,EACvDyC,EAAQzC,IAAOE,GAKjB,IAFA,IAAIyC,EAAMF,EAAQ,GACdG,EAASpC,KAAKI,QAAS,GACjBZ,EAAI,EAAGA,EAAIwC,EAAUxC,IAAM,CACpC,IAAME,EAAMuC,EAAQzC,GACfE,EAAMyC,IACVA,EAAMzC,EACN0C,EAASpC,KAAKI,QAASZ,IAGzB,OAAO4C,GASRgB,EAAe3C,UAAU4B,QAAU,SAAkBnE,GACpD,IAAM8D,EAAWhC,KAAKI,QAAQpB,OAK9B,GAJKsD,GAAAA,CAAcpE,KAClBA,EAAIyB,GAAAA,CAASzB,IAGTqE,GAAAA,CAAcrE,GAAM,CAGxB,IAFA,IAAMwE,EAAM,GACNF,EAAOtE,EAAEgC,MAAO,GACZV,EAAI,EAAGA,EAAIgD,EAAMhD,IAAM,CAEhC,IADA,IAAMyC,EAAS,IAAIC,MAAOF,GAChBjD,EAAI,EAAGA,EAAIiD,EAAUjD,IAAM,CACpC,IAAMkC,EAAIjB,KAAKI,QAASrB,GACxBkD,EAAQlD,GAAMiB,KAAKY,MAAOK,GAC1B,IAAM,IAAI3B,EAAI,EAAGA,EAAIU,KAAKG,EAAGb,IAAM,CAClC,IAAMI,EAAMxB,EAAEoD,IAAK9B,EAAGF,GAAMpB,EAAEoD,IAAK9B,EAAGF,GAAMU,KAAKuD,MAAMjC,IAAKhC,EAAGP,GAAM,EACrEkD,EAAQlD,IAAOW,GAKjB,IAFA,IAAIyC,EAAMF,EAAQ,GACdG,EAASpC,KAAKI,QAAS,GACjBrB,EAAI,EAAGA,EAAIiD,EAAUjD,IAAM,CACnC,IAAMW,EAAMuC,EAAQlD,GACfW,EAAMyC,IACVA,EAAMzC,EACN0C,EAASpC,KAAKI,QAASrB,IAG1B2D,EAAKlD,GAAM4C,EAEZ,OAAOM,EAGR,OAAO1C,KAAK+B,WAAY7D,IASzBkF,EAAe3C,UAAUmC,aAAe,SAAuB1E,GAK9D,GAJKoE,GAAAA,CAAcpE,KAClBA,EAAIyB,GAAAA,CAASzB,IAGTqE,GAAAA,CAAcrE,GAAM,CAGxB,IAFA,IAAMsE,EAAOtE,EAAEgC,MAAO,GAChBwC,EAAM,IAAIR,MAAOM,GACbhD,EAAI,EAAGA,EAAIgD,EAAMhD,IAAM,CAEhC,IADA,IAAIyC,EAAS,IAAIC,MAAOlC,KAAKO,QACnBxB,EAAI,EAAGA,EAAIiB,KAAKO,OAAQxB,IAAM,CACvC,IAAMkC,EAAIjB,KAAKI,QAASrB,GACxBkD,EAAQlD,GAAMiB,KAAKY,MAAOK,GAC1B,IAAM,IAAI3B,EAAI,EAAGA,EAAIU,KAAKG,EAAGb,IAAM,CAClC,IAAMI,EAAMxB,EAAEoD,IAAK9B,EAAGF,GAAMpB,EAAEoD,IAAK9B,EAAGF,GAAMU,KAAKuD,MAAMjC,IAAKhC,EAAGP,GAAM,EACrEkD,EAAQlD,IAAOW,GAKjB,IAFA,IAAMmD,GAAIV,EAAAA,EAAAA,GAAKF,GACXa,EAAU,EACJ/D,EAAI,EAAGA,EAAIkD,EAAOjD,OAAQD,IACnC+D,GAAWC,GAAAA,CAAKd,EAAQlD,GAAM8D,GAE/B,IAAMG,EAAQH,EAAI1B,GAAAA,CAAI2B,GACtBb,GAASgB,EAAAA,EAAAA,GAAUhB,EAAQe,GAC3BN,EAAKlD,GAAMyC,EAAOZ,KAAK,SAAAnD,GAAC,OAAI6E,GAAAA,CAAK7E,MAElC,OAAOwE,EAIR,IADA,IAAIT,EAAS,IAAIC,MAAOlC,KAAKO,QACnBxB,EAAI,EAAGA,EAAIiB,KAAKO,OAAQxB,IAAM,CACvC,IAAMkC,EAAIjB,KAAKI,QAASrB,GACxBkD,EAAQlD,GAAMiB,KAAKY,MAAOK,GAC1B,IAAM,IAAI3B,EAAI,EAAGA,EAAIU,KAAKG,EAAGb,IAAM,CAClC,IAAMI,EAAMxB,EAAGoB,GAAMU,KAAKuD,MAAMjC,IAAKhC,EAAGP,GACxCkD,EAAQlD,IAAOW,GAKjB,IAFA,IAAMmD,GAAIV,EAAAA,EAAAA,GAAKF,GACXa,EAAU,EACJ/D,EAAI,EAAGA,EAAIkD,EAAOjD,OAAQD,IACnC+D,GAAWC,GAAAA,CAAKd,EAAQlD,GAAM8D,GAE/B,IAAMG,EAAQH,EAAI1B,GAAAA,CAAI2B,GAEtB,OADAb,GAASgB,EAAAA,EAAAA,GAAUhB,EAAQe,IACb3B,KAAK,SAAAnD,GAAC,OAAI6E,GAAAA,CAAK7E,iCCnN1B0F,YAAU,GA0ERC,EAAW,SAAC,GAA+C,IAA7C3F,EAA4C,EAA5CA,EAAGM,EAAyC,EAAzCA,EAAGC,EAAsC,EAAtCA,KAAMC,EAAgC,EAAhCA,aAAcoF,EAAkB,EAAlBA,YAC7C,IACC,IACA,GADgBA,EAAcjE,EAAAA,EAAsBtB,EAAAA,GACHL,EAAGM,EAAGC,EAAMC,GAArDC,EAAR,EAAQA,OAAQC,EAAhB,EAAgBA,WACVmF,EC7CR,SAAqB7F,EAAGM,GACvB,GAAK8D,GAAAA,CAAcpE,GAClBA,EAAIyB,GAAAA,CAASzB,QACP,IAAMqE,GAAAA,CAAcrE,GAE1B,MAAM,IAAI8F,UADE,8FAAgG9F,EAAI,KAGjH,IAAM+F,GAAAA,CAAazF,GAClB,MAAM,IAAIwF,UAAW,2EAA6ExF,EAAI,KAGvG,OADY,IAAIuB,EAAa7B,EAAGM,GDmChB0F,CAAUvF,EADzB,EAA4BiB,SAE5B,MAAO,CACNmE,OAAAA,EACAnF,WAAAA,GAEA,MAAQuF,GACT,MAAO,KAiBHC,EAAAA,SAAAA,IAAAA,EAAAA,EAAAA,GAAAA,EAAAA,GAAAA,IAAAA,GAAAA,EAAAA,EAAAA,GAAAA,GACL,WAAaC,GAAS,IAAD,kBACpB,cAAOA,IADa,sCA4BF,WAClB,EAAKA,MAAMC,UAAW,EAAKC,MAAMR,OAAQH,MA1BzCA,GAAW,EACX,IAAQ1F,EAA0CmG,EAA1CnG,EAAGM,EAAuC6F,EAAvC7F,EAAGC,EAAoC4F,EAApC5F,KAAMC,EAA8B2F,EAA9B3F,aAAcoF,EAAgBO,EAAhBP,YAJd,OAKpB,EAAKS,OAAL,kBACIV,EAAS,CAAE3F,EAAAA,EAAGM,EAAAA,EAAGC,KAAAA,EAAMC,aAAAA,EAAcoF,YAAAA,KACrCO,GAPgB,EA0BpB,OAjBA,8BAuBD,WACC,MAA+BrE,KAAKuE,MAA5BR,EAAR,EAAQA,OAAQnF,EAAhB,EAAgBA,WACR4F,EAAMxE,KAAKqE,MAAXG,EACR,OAAMT,EAIL,uBAAKU,MAAO,CAAEC,UAAW,OAAQC,MAAO,SACvC,wBAAMC,UAAU,SAAUJ,EAAE,2BAA4B,CAAEhG,EAAGwB,KAAKqE,MAAM7F,EAAGqG,QAASjB,KAzInE,SAAEhF,EAAYmF,EAAQrF,EAAc8F,GACxD,OACC,2BACC,wBAAMI,UAAU,SAASJ,EAAE,iBAA3B,KACA,gBAAC,IAAD,CAAOM,UAAQ,EAACC,KAAK,MACpB,6BACC,0BACEhB,EAAO3D,QAAQiB,KAAK,SAAEnD,EAAGsB,GAAL,OAAY,sBAAIwF,IAAKxF,GAAItB,QAGhD,6BACC,0BACE6F,EAAO3D,QAAQiB,KAAK,SAAEnD,EAAGsB,GAAL,OAAY,sBAAIwF,IAAKxF,GAAIuD,GAAAA,CAAIgB,EAAOnD,MAAO1C,IAAK+G,QAAS,UAIjF,wBAAML,UAAU,SAASJ,EAAE,gBAA3B,KACC5F,EAAWyC,KAAK,SAAE6D,EAAM1F,GACxB,OAAKN,GAAAA,CAAUR,EAAcwG,GACnB,gBAAC,IAAD,CAAOJ,UAAQ,EAACC,KAAK,KAAKC,IAAKxF,GACvC,6BACC,0BACC,0BAAK0F,GACJnB,EAAO3D,QAAQiB,KAAK,SAAEnD,EAAGsB,GAAL,OAAY,sBAAIwF,IAAKxF,GAAItB,QAGhD,6BACC,0BACC,0BAAKsG,EAAE,SACNT,EAAO3D,QAAQiB,KAAK,SAAE8D,EAAGpG,GACzB,OAAO,sBAAIiG,IAAG,UAAKxF,EAAL,YAAUT,IAAMgF,EAAOlD,GAAGS,IAAK9B,EAAGT,GAAIkG,QAAS,QAG/D,0BACC,0BAAKT,EAAE,OACNT,EAAO3D,QAAQiB,KAAK,SAAE8D,EAAGpG,GACzB,OAAO,sBAAIiG,IAAG,UAAKxF,EAAL,YAAUT,IAAMgF,EAAOhD,MAAMO,IAAK9B,EAAGT,GAAIkG,QAAS,UAM5D,gBAAC,IAAD,CAAOH,UAAQ,EAACC,KAAK,KAAKC,IAAKxF,GACvC,6BACC,0BACC,0BAAK0F,GACJnB,EAAO3D,QAAQiB,KAAK,SAAEnD,EAAGsB,GAAL,OAAY,sBAAIwF,IAAKxF,GAAItB,QAGhD,6BACC,0BACC,0BAAKsG,EAAE,QACNT,EAAO3D,QAAQiB,KAAK,SAAE8D,EAAGpG,GACzB,OAAO,sBAAIiG,IAAG,UAAKxF,EAAL,YAAUT,IAAMgF,EAAOlD,GAAGS,IAAK9B,EAAGT,GAAIkG,QAAS,QAG/D,0BACC,0BAAKT,EAAE,OACNT,EAAO3D,QAAQiB,KAAK,SAAE8D,EAAGpG,GACzB,OAAO,sBAAIiG,IAAG,UAAKxF,EAAL,YAAUT,KAAO,EAAEgF,EAAOlD,GAAGS,IAAK9B,EAAGT,IAAKkG,QAAS,cA+EpEG,CAAcxG,EAAYmF,EAAQ/D,KAAKqE,MAAM3F,aAAc8F,GAC3DxE,KAAKqE,MAAMC,UAAY,gBAAC,IAAD,CAASe,QAASb,EAAE,iCAC3C,gBAACc,EAAA,EAAD,CAAQC,QAAQ,YAAYR,KAAK,KAAKS,QAASxF,KAAKyF,kBAAoBjB,EAAE,0BAC9D,MARP,gBAACkB,EAAA,EAAD,CAAOH,QAAQ,UAAUf,EAAE,0BAWnC,uCApCD,SAAiCmB,EAAWC,GAC3C,GACCD,EAAUlH,OAASmH,EAAUnH,MAC7BkH,EAAUjH,eAAiBkH,EAAUlH,cACrCiH,EAAUzH,IAAM0H,EAAU1H,GAC1ByH,EAAUnH,IAAMoH,EAAUpH,GAC1BmH,EAAU7B,cAAgB8B,EAAU9B,YACnC,CACD,IAAQ5F,EAA0CyH,EAA1CzH,EAAGM,EAAuCmH,EAAvCnH,EAAGC,EAAoCkH,EAApClH,KAAMC,EAA8BiH,EAA9BjH,aAAcoF,EAAgB6B,EAAhB7B,YAClC,OAAO,kBACHD,EAAS,CAAE3F,EAAAA,EAAGM,EAAAA,EAAGC,KAAAA,EAAMC,aAAAA,EAAcoF,YAAAA,KACrC6B,GAGL,OAAO,SACP,EA3BIvB,CAAmByB,EAAAA,WAsDzBzB,EAAW0B,aAAe,CACzBhC,aAAa,EACbQ,UAAW,MAsBZ,OAAeyB,EAAAA,EAAAA,GAAiB,SAAhC,EAA4CC,EAAAA,EAAAA,GAAe5B,wDElK3D,UAtBA,SAAgBlG,EAAGM,GAClB,IAAMyF,GAAAA,CAAa/F,GAClB,MAAM,IAAI8F,UAAW,oFAAsF9F,EAAI,KAEhH,IAAM+F,GAAAA,CAAazF,GAClB,MAAM,IAAIwF,UAAW,2FAA6FxF,EAAI,KAKvH,IAHA,IAAMyH,EAAOjG,KAAKqC,QAASnE,GACrB+B,EAAIzB,EAAEQ,OACRkH,EAAW,EACL1G,EAAI,EAAGA,EAAIS,EAAGT,IAClByG,EAAMzG,KAAQhB,EAAGgB,KACrB0G,GAAY,GAId,OADAA,GAAYjG,2DCkBb,IAhCA,SAAmB0C,EAAKzE,GACvB,IAAMiI,EAAQlC,GAAAA,CAAa/F,GAC3B,IAAM+F,GAAAA,CAAatB,GAClB,MAAM,IAAIqB,UAAW,0DAA4DrB,EAAM,MAExF,IAAMwD,KAAU7H,EAAAA,EAAAA,aAAUJ,GACzB,MAAM,IAAI8F,UAAW,gGAAkG9F,EAAI,MAE5H,IAAMkI,EAAMzD,EAAI3D,OACVmE,EAAM,IAAIjB,MAAOkE,GAGvB,GAAKD,EAAQ,CACZ,GAAKC,IAAQlI,EAAEc,OACd,MAAM,IAAIqH,MAAO,kGAElB,IAAM,IAAI7G,EAAI,EAAGA,EAAI4G,EAAK5G,IACzB2D,EAAK3D,GAAMmD,EAAKnD,GAAMtB,EAAGsB,QAK1B,IAAM,IAAIA,EAAI,EAAGA,EAAI4G,EAAK5G,IACzB2D,EAAK3D,GAAMmD,EAAKnD,GAAMtB,EAGxB,OAAOiF,0BCJR,IAAIb,EAAe,EAAQ,OAG3BgE,EAAOC,QAAUjE,yBCrBjB,IAwBIA,EAxBW,EAAQ,MAwBJkE,CAtBL,EAAQ,QAwBtBF,EAAOC,QAAUjE,yBC7CF,SAASmE,EAAeC,GACrC,MAAM,IAAI1C,UAAU,IAAO0C,EAAO","sources":["../node_modules/@isle-project/components/models/naive-bayes/design_matrix.js","../node_modules/@isle-project/components/models/naive-bayes/gaussian.js","../node_modules/@isle-project/components/models/naive-bayes/multinomial.js","../node_modules/@isle-project/components/models/naive-bayes/main.js","../node_modules/@isle-project/components/models/naive-bayes/naive_bayes.js","../node_modules/@isle-project/components/models/naive-bayes/score.js","../node_modules/@isle-project/utils/subtract/index.js","../node_modules/@stdlib/assert/is-array-array/lib/index.js","../node_modules/@stdlib/assert/is-array-array/lib/main.js","../javascript/esm|/home/philipp/git/cmu-isle/isle-dashboard/node_modules/@babel/runtime/helpers/esm/readOnlyError.js"],"sourcesContent":["// MODULES //\n\nimport contains from '@stdlib/assert/contains';\nimport ndarray from '@stdlib/ndarray/array';\nimport { isPrimitive as isNumber } from '@stdlib/assert/is-number';\nimport isUndefinedOrNull from '@stdlib/assert/is-undefined-or-null';\nimport isnan from '@stdlib/assert/is-nan';\nimport isArray from '@stdlib/assert/is-array';\nimport extractCategoriesFromValues from '@isle-project/utils/extract-categories-from-values';\n\n\n// FUNCTIONS //\n\nfunction isMissing( x ) {\n\treturn isnan( x ) || isUndefinedOrNull( x );\n}\n\nfunction isNonMissingNumber( x ) {\n\treturn isNumber( x ) && !isnan( x );\n}\n\n\n// MAIN //\n\nexport function designMatrix( x, y, data, quantitative ) {\n\tlet matrix = [];\n\tconst predictors = [];\n\tconst hash = {};\n\tif ( !isArray( x ) ) {\n\t\tx = [ x ];\n\t}\n\tfor ( let j = 0; j < x.length; j++ ) {\n\t\tconst values = data[ x[ j ] ];\n\t\tif ( contains( quantitative, x[ j ] ) ) {\n\t\t\tpredictors.push( x[ j ] );\n\t\t} else {\n\t\t\tconst categories = extractCategoriesFromValues( values, x[ j ] );\n\t\t\tfor ( let k = 0; k < categories.length; k++ ) {\n\t\t\t\tpredictors.push( `${x[ j ]}_${categories[ k ]}` );\n\t\t\t}\n\t\t\thash[ x[ j ] ] = categories;\n\t\t}\n\t}\n\tconst nobs = data[ x[ 0 ] ].length;\n\tfor ( let i = 0; i < nobs; i++ ) {\n\t\tconst row = [];\n\t\tfor ( let j = 0; j < x.length; j++ ) {\n\t\t\tconst values = data[ x[ j ] ];\n\t\t\tif ( contains( quantitative, x[ j ] ) ) {\n\t\t\t\trow.push( values[ i ] );\n\t\t\t} else {\n\t\t\t\tconst categories = hash[ x[ j ] ];\n\t\t\t\tconst val = values[ i ];\n\t\t\t\tfor ( let k = 0; k < categories.length; k++ ) {\n\t\t\t\t\trow.push( ( val === categories[ k ] ) ? 1 : 0 );\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tmatrix.push( row );\n\t}\n\tmatrix = ndarray( matrix );\n\tconst yvalues = data[ y ];\n\treturn { matrix, predictors, yvalues };\n}\n\nexport function designMatrixMissing( x, y, data, quantitative ) {\n\tlet matrix = [];\n\tconst predictors = [];\n\tconst hash = {};\n\tif ( !isArray( x ) ) {\n\t\tx = [ x ];\n\t}\n\tfor ( let j = 0; j < x.length; j++ ) {\n\t\tconst values = data[ x[ j ] ];\n\t\tif ( contains( quantitative, x[ j ] ) ) {\n\t\t\tpredictors.push( x[ j ] );\n\t\t} else {\n\t\t\tconst categories = extractCategoriesFromValues( values, x[ j ] );\n\t\t\tfor ( let k = 0; k < categories.length; k++ ) {\n\t\t\t\tpredictors.push( `${x[ j ]}_${categories[ k ]}` );\n\t\t\t}\n\t\t\thash[ x[ j ] ] = categories;\n\t\t}\n\t}\n\tconst nobs = data[ x[ 0 ] ].length;\n\tconst yvalues = [];\n\tfor ( let i = 0; i < nobs; i++ ) {\n\t\tconst row = [];\n\t\tlet missing = false;\n\t\tfor ( let j = 0; j < x.length; j++ ) {\n\t\t\tconst values = data[ x[ j ] ];\n\t\t\tif ( contains( quantitative, x[ j ] ) ) {\n\t\t\t\tif ( isNonMissingNumber( values[ i ] ) ) {\n\t\t\t\t\trow.push( values[ i ] );\n\t\t\t\t} else {\n\t\t\t\t\tmissing = true;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tconst categories = hash[ x[ j ] ];\n\t\t\t\tconst val = values[ i ];\n\t\t\t\tif ( isMissing( val ) ) {\n\t\t\t\t\tmissing = true;\n\t\t\t\t} else {\n\t\t\t\t\tfor ( let k = 0; k < categories.length; k++ ) {\n\t\t\t\t\t\trow.push( ( val === categories[ k ] ) ? 1 : 0 );\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif ( isMissing( data[ y ][ i ] ) ) {\n\t\t\tmissing = true;\n\t\t}\n\t\tif ( !missing ) {\n\t\t\tmatrix.push( row );\n\t\t\tyvalues.push( data[ y ][ i ] );\n\t\t}\n\t}\n\tmatrix = ndarray( matrix );\n\treturn { matrix, predictors, yvalues };\n}\n","// MODULES //\n\nimport uniq from 'uniq';\nimport ndarray from '@stdlib/ndarray/array';\nimport isArrayArray from '@stdlib/assert/is-array-array';\nimport isMatrixLike from '@stdlib/assert/is-matrix-like';\nimport exp from '@stdlib/math/base/special/exp';\nimport ln from '@stdlib/math/base/special/ln';\nimport pow from '@stdlib/math/base/special/pow';\nimport PI from '@stdlib/constants/float64/pi';\nimport mean from '@isle-project/utils/statistic/mean';\nimport stdev from '@isle-project/utils/statistic/stdev';\nimport max from '@isle-project/utils/statistic/max';\nimport subtract from '@isle-project/utils/subtract';\n\n\n// MAIN //\n\n/**\n* Naive Bayes fitting object constructor for normal distribution.\n*\n* @constructor\n* @param {Matrix} x - design matrix\n* @param {Array} y - vector of class memberships\n* @returns {GaussianFit} GaussianFit instance\n*/\nfunction GaussianFit( x, y ) {\n\tthis.n = x.shape[ 0 ];\n\tthis.p = x.shape[ 1 ];\n\n\tthis.classes = uniq( y.slice() );\n\tthis.nclass = this.classes.length;\n\n\tthis.fitGaussian( x, y );\n}\n\nGaussianFit.prototype.score = require( './score.js' );\n\n\n/**\n* Fit the data under the assumption that p(x_i|c) follows a normal distribution.\n*\n* ## Notes\n*\n* -   Assigns prior and conditional probabilities of BayesFit instance.\n*\n* @param {Matrix} x - design matrix\n* @param {Array} y - vector of class memberships\n* @returns {void}\n*/\nGaussianFit.prototype.fitGaussian = function fitGaussian( x, y ) {\n\tthis.prior = {};\n\tconst shape = [ this.p, this.nclass ];\n\tthis.mu = ndarray( new Float64Array( shape[0]*shape[1] ), { 'shape': shape } );\n\tthis.sigma = ndarray( new Float64Array( shape[0]*shape[1] ), { 'shape': shape } );\n\tfor ( let i = 0; i < this.nclass; i++ ) {\n\t\tconst ids = [];\n\t\tconst c = this.classes[ i ];\n\t\tfor ( let j = 0; j < this.n; j++ ) {\n\t\t\tif ( y[ j ] === c ) {\n\t\t\t\tids.push( j );\n\t\t\t}\n\t\t}\n\t\tconst nc = ids.length;\n\t\tthis.prior[ c ] = ln( nc / this.n );\n\t\tfor ( let j = 0; j < this.p; j++ ) {\n\t\t\tconst vals = ids.map( i => x.get( i, j ) );\n\t\t\tconst mu = mean( vals );\n\t\t\tconst sigma = stdev( vals );\n\t\t\tthis.mu.set( j, i, mu );\n\t\t\tthis.sigma.set( j, i, sigma );\n\t\t}\n\t}\n};\n\n/**\n* Calculate p(X=x,C=i), i.e. the joint probability of observation x and class i.\n*\n* @param {Array} x - new observation\n* @param {number} i - class indicator\n* @returns {number} log probability\n*/\nGaussianFit.prototype.calcGaussianProb = function calcGaussianProb( x, i ) {\n\tconst c = this.classes[ i ];\n\tlet res = this.prior[ c ];\n\n\tfor ( let j = 0; j < this.p; j++ ) {\n\t\tconst sigma = this.sigma.get( j, i );\n\t\tconst s2 = sigma*sigma;\n\t\tconst mu = this.mu.get( j, i );\n\t\tconst val = ( -0.5 * ln( 2 * PI * s2 ) ) - ( pow( x[ j ] - mu, 2 ) / s2 );\n\t\tres += val;\n\t}\n\treturn res;\n};\n\n/**\n* Predict class membership for one new observation.\n*\n* @param {Array} x - new observation\n* @returns {(number|string)} predicted class membership\n*/\nGaussianFit.prototype.predictOne = function predictOne( x ) {\n\tconst nClasses = this.classes.length;\n\tconst logLik = new Array( nClasses );\n\tfor ( let i = 0; i < nClasses; i++ ) {\n\t\tlogLik[ i ] = this.calcGaussianProb( x, i );\n\t}\n\tlet max = logLik[ 0 ];\n\tlet argmax = this.classes[ 0 ];\n\tfor ( let i = 0; i < nClasses; i++ ) {\n\t\tconst val = logLik[ i ];\n\t\tif ( val > max ) {\n\t\t\tmax = val;\n\t\t\targmax = this.classes[ i ];\n\t\t}\n\t}\n\treturn argmax;\n};\n\n/**\n* Predict class membership for new observation(s).\n*\n* @param {(Matrix|Array)} x - new observation(s)\n* @returns {Array} array of predicted class memberships\n*/\nGaussianFit.prototype.predict = function predict( x ) {\n\tconst nClasses = this.classes.length;\n\tif ( isArrayArray( x ) ) {\n\t\tx = ndarray( x );\n\t}\n\t// Case A: Predictions for multiple observations:\n\tif ( isMatrixLike( x ) ) {\n\t\tconst [ nrow, ncol ] = x.shape;\n\t\tconst ret = new Array( nrow );\n\t\tfor ( let i = 0; i < nrow; i++ ) {\n\t\t\tconst logLik = new Array( nClasses );\n\t\t\tfor ( let j = 0; j < nClasses; j++ ) {\n\t\t\t\tconst arr = new Array( ncol );\n\t\t\t\tfor ( let k = 0; k < ncol; k++ ) {\n\t\t\t\t\tarr[ k ] = x.get( i, k );\n\t\t\t\t}\n\t\t\t\tlogLik[ j ] = this.calcGaussianProb( arr, j );\n\t\t\t}\n\t\t\tlet max = logLik[ 0 ];\n\t\t\tlet argmax = this.classes[ 0 ];\n\t\t\tfor ( let j = 0; j < nClasses; j++ ) {\n\t\t\t\tconst val = logLik[ j ];\n\t\t\t\tif ( val > max ) {\n\t\t\t\t\tmax = val;\n\t\t\t\t\targmax = this.classes[ j ];\n\t\t\t\t}\n\t\t\t}\n\t\t\tret[ i ] = argmax;\n\t\t}\n\t\treturn ret;\n\t}\n\t// Case B: Only one new observation:\n\treturn this.predictOne( x );\n};\n\n/**\n* Calculates class membership probabilities.\n*\n* @param {(Matrix|Array)} x - design matrix\n* @returns {Array} class probabilities\n*/\nGaussianFit.prototype.predictProbs = function predictProbs( x ) {\n\tif ( isArrayArray( x ) ) {\n\t\tx = ndarray( x );\n\t}\n\t// Case A: Predictions for multiple observations:\n\tif ( isMatrixLike( x ) ) {\n\t\tconst [ nrow, ncol ] = x.shape;\n\t\tconst ret = new Array( nrow );\n\t\tfor ( let i = 0; i < nrow; i++ ) {\n\t\t\tlet logLik = new Array( this.nclass );\n\t\t\tfor ( let j = 0; j < this.nclass; j++ ) {\n\t\t\t\tconst arr = new Array( ncol );\n\t\t\t\tfor ( let k = 0; k < ncol; k++ ) {\n\t\t\t\t\tarr[ k ] = x.get( i, k );\n\t\t\t\t}\n\t\t\t\tlogLik[ j ] = this.calcGaussianProb( arr, j );\n\t\t\t}\n\t\t\tconst a = max( logLik );\n\t\t\tlet summand = 0;\n\t\t\tfor ( let j = 0; j < logLik.length; j++ ) {\n\t\t\t\tsummand += exp( logLik[ j ] - a );\n\t\t\t}\n\t\t\tconst denom = a + ln( summand );\n\t\t\tlogLik = subtract( logLik, denom );\n\t\t\tret[ i ] = logLik.map( x => exp( x ) );\n\t\t}\n\t\treturn ret;\n\t}\n\t// Case B: Create prediction for a single observation:\n\tconst logLik = new Array( this.nclass );\n\tfor ( let j = 0; j < this.nclass; j++ ) {\n\t\tlogLik[ j ] = this.calcGaussianProb( x, j );\n\t}\n\tconst a = max( logLik );\n\tlet summand = 0;\n\tfor ( let j = 0; j < logLik.length; j++ ) {\n\t\tsummand += exp( logLik[ j ] - a );\n\t}\n\tconst denom = a + ln( summand );\n\tlogLik = subtract( logLik, denom );\n\treturn logLik.map( x => exp( x ) );\n};\n\n\n// EXPORTS //\n\nexport default GaussianFit;\n","// MODULES //\n\nimport uniq from 'uniq';\nimport ndarray from '@stdlib/ndarray/array';\nimport max from '@isle-project/utils/statistic/max';\nimport subtract from '@isle-project/utils/subtract';\nimport exp from '@stdlib/math/base/special/exp';\nimport isArrayArray from '@stdlib/assert/is-array-array';\nimport isMatrixLike from '@stdlib/assert/is-matrix-like';\nimport ln from '@stdlib/math/base/special/ln';\n\n\n// FUNCTIONS //\n\nconst sum = ( arr ) => {\n\tlet out = 0;\n\tfor ( let i = 0; i < arr.length; i++ ) {\n\t\tout += arr[ i ];\n\t}\n\treturn out;\n};\n\n\n// MAIN //\n\n/**\n* Naive Bayes fitting object constructor for multinomial distribution.\n*\n* @constructor\n* @param {Matrix} x - design matrix\n* @param {Array} y - vector of class memberships\n* @param {number} alpha - Laplace smoothing parameter\n* @returns {MultinomialFit} MultinomialFit instance\n*/\nfunction MultinomialFit( x, y, alpha ) {\n\tthis.n = x.shape[ 0 ];\n\tthis.p = x.shape[ 1 ];\n\n\tthis.classes = uniq( y.slice() );\n\tthis.nclass = this.classes.length;\n\tthis.alpha = alpha;\n\n\tthis.fitMultinomial( x, y );\n}\n\nMultinomialFit.prototype.score = require( './score.js' );\n\n\n/**\n* Fit the data under the assumption that p(x_i|c) follows a multinomial distribution.\n*\n* ## Notes\n*\n* -   Assigns prior and conditional probabilities of BayesFit instance.\n*\n* @param {Matrix} x - design matrix\n* @param {Array} y - vector of class memberships\n* @returns {Void}\n*/\nMultinomialFit.prototype.fitMultinomial = function fitMultinomial( x, y ) {\n\tconst prior = {};\n\tconst shape = [ this.p, this.nclass ];\n\tconst cprob = ndarray( new Float64Array( shape[0]*shape[1] ), { 'shape': shape } );\n\tfor ( let i = 0; i < this.nclass; i++ ) {\n\t\tconst ids = [];\n\t\tconst counts = new Int32Array( this.p );\n\t\tconst c = this.classes[ i ];\n\t\tfor ( let j = 0; j < this.n; j++ ) {\n\t\t\tif ( y[ j ] === c ) {\n\t\t\t\tids.push( j );\n\t\t\t}\n\t\t}\n\t\tconst nc = ids.length;\n\t\tprior[ c ] = ln( nc / this.n );\n\t\tlet totalCount = 0;\n\t\tfor ( let j = 0; j < this.p; j++ ) {\n\t\t\tconst vals = ids.map( i => x.get( i, j ) );\n\t\t\tcounts[ j ] = sum( vals );\n\t\t\ttotalCount += counts[ j ];\n\t\t}\n\t\tfor ( let j = 0; j < this.p; j++ ) {\n\t\t\tconst val = ln( counts[ j ] + this.alpha ) - ln( totalCount + this.p * this.alpha );\n\t\t\tcprob.set( j, i, val );\n\t\t}\n\t}\n\tthis.prior = prior;\n\tthis.cprob = cprob;\n};\n\n/**\n* Calculates multinomial probability.\n*\n* @param {Array} x - new observation\n* @param {number} i - class indicator\n* @param {number} j - variable indicator\n* @returns {number} probability\n*/\nMultinomialFit.prototype.calcMultinomProb = function calcMultinomProb( x, i, j ) {\n\tconst c = this.classes[ i ];\n\tlet res = this.prior[ c ];\n\tfor ( j = 0; j < this.p; j++ ) {\n\t\tconst val = x[ j ] ? x[ j ] * this.cprob.get( j, i ) : 0;\n\t\tres += val;\n\t}\n\treturn res;\n};\n\n/**\n* Predict class membership for one new observation.\n*\n* @param {Array} x - new observation\n* @returns {(number|string)} predicted class membership\n*/\nMultinomialFit.prototype.predictOne = function predictOne( x ) {\n\tconst nClasses = this.classes.length;\n\tconst logLik = new Array( nClasses );\n\tfor ( let i = 0; i < nClasses; i++ ) {\n\t\tconst c = this.classes[ i ];\n\t\tlogLik[ i ] = this.prior[ c ];\n\t\tfor ( let j = 0; j < this.p; j++ ) {\n\t\t\tconst val = x[ j ] ? x[ j ] * this.cprob.get( j, i ) : 0;\n\t\t\tlogLik[ i ] += val;\n\t\t}\n\t}\n\tlet max = logLik[ 0 ];\n\tlet argmax = this.classes[ 0 ];\n\tfor ( let i = 0; i < nClasses; i++ ) {\n\t\tconst val = logLik[ i ];\n\t\tif ( val > max ) {\n\t\t\tmax = val;\n\t\t\targmax = this.classes[ i ];\n\t\t}\n\t}\n\treturn argmax;\n};\n\n/**\n* Predict class membership for new observation(s).\n*\n* @param {(Matrix|Array)} x - new observation(s)\n* @returns {Array} array of predicted class memberships\n*/\nMultinomialFit.prototype.predict = function predict( x ) {\n\tconst nClasses = this.classes.length;\n\tif ( isArrayArray( x ) ) {\n\t\tx = ndarray( x );\n\t}\n\t// Case A: Predictions for multiple observations:\n\tif ( isMatrixLike( x ) ) {\n\t\tconst ret = [];\n\t\tconst nrow = x.shape[ 0 ];\n\t\tfor ( let i = 0; i < nrow; i++ ) {\n\t\t\tconst logLik = new Array( nClasses );\n\t\t\tfor ( let j = 0; j < nClasses; j++ ) {\n\t\t\t\tconst c = this.classes[ j ];\n\t\t\t\tlogLik[ j ] = this.prior[ c ];\n\t\t\t\tfor ( let k = 0; k < this.p; k++ ) {\n\t\t\t\t\tconst val = x.get( i, k ) ? x.get( i, k ) * this.cprob.get( k, j ) : 0;\n\t\t\t\t\tlogLik[ j ] += val;\n\t\t\t\t}\n\t\t\t}\n\t\t\tlet max = logLik[ 0 ];\n\t\t\tlet argmax = this.classes[ 0 ];\n\t\t\tfor ( let j = 0; j < nClasses; j++ ) {\n\t\t\t\t\tconst val = logLik[ j ];\n\t\t\t\t\tif ( val > max ) {\n\t\t\t\t\t\tmax = val;\n\t\t\t\t\t\targmax = this.classes[ j ];\n\t\t\t\t\t}\n\t\t\t}\n\t\t\tret[ i ] = argmax;\n\t\t}\n\t\treturn ret;\n\t}\n\t// Case B: Only one new observation:\n\treturn this.predictOne( x );\n};\n\n/**\n* Calculates class membership probabilities.\n*\n* @param {(Matrix|Array)} x - design matrix\n* @returns {Array} class probabilities\n*/\nMultinomialFit.prototype.predictProbs = function predictProbs( x ) {\n\tif ( isArrayArray( x ) ) {\n\t\tx = ndarray( x );\n\t}\n\t// Case A: Predictions for multiple observations:\n\tif ( isMatrixLike( x ) ) {\n\t\tconst nrow = x.shape[ 0 ];\n\t\tconst ret = new Array( nrow );\n\t\tfor ( let i = 0; i < nrow; i++ ) {\n\t\t\tlet logLik = new Array( this.nclass );\n\t\t\tfor ( let j = 0; j < this.nclass; j++ ) {\n\t\t\t\tconst c = this.classes[ j ];\n\t\t\t\tlogLik[ j ] = this.prior[ c ];\n\t\t\t\tfor ( let k = 0; k < this.p; k++ ) {\n\t\t\t\t\tconst val = x.get( i, k ) ? x.get( i, k ) * this.cprob.get( k, j ) : 0;\n\t\t\t\t\tlogLik[ j ] += val;\n\t\t\t\t}\n\t\t\t}\n\t\t\tconst a = max( logLik );\n\t\t\tlet summand = 0;\n\t\t\tfor ( let j = 0; j < logLik.length; j++ ) {\n\t\t\t\tsummand += exp( logLik[ j ] - a );\n\t\t\t}\n\t\t\tconst denom = a + ln( summand );\n\t\t\tlogLik = subtract( logLik, denom );\n\t\t\tret[ i ] = logLik.map( x => exp( x ) );\n\t\t}\n\t\treturn ret;\n\t}\n\t// Case B: Create prediction for a single observation:\n\tlet logLik = new Array( this.nclass );\n\tfor ( let j = 0; j < this.nclass; j++ ) {\n\t\tconst c = this.classes[ j ];\n\t\tlogLik[ j ] = this.prior[ c ];\n\t\tfor ( let k = 0; k < this.p; k++ ) {\n\t\t\tconst val = x[ k ] * this.cprob.get( k, j );\n\t\t\tlogLik[ j ] += val;\n\t\t}\n\t}\n\tconst a = max( logLik );\n\tlet summand = 0;\n\tfor ( let j = 0; j < logLik.length; j++ ) {\n\t\tsummand += exp( logLik[ j ] - a );\n\t}\n\tconst denom = a + ln( summand );\n\tlogLik = subtract( logLik, denom );\n\treturn logLik.map( x => exp( x ) );\n};\n\n\n// EXPORTS //\n\nexport default MultinomialFit;\n","// MODULES //\n\nimport React, { Component } from 'react';\nimport PropTypes from 'prop-types';\nimport { withTranslation } from 'react-i18next';\nimport Alert from 'react-bootstrap/Alert';\nimport Button from 'react-bootstrap/Button';\nimport Table from '@isle-project/components/table';\nimport contains from '@stdlib/assert/contains';\nimport exp from '@stdlib/math/base/special/exp';\nimport Tooltip from '@isle-project/components/tooltip';\nimport { gaussian } from './naive_bayes.js';\nimport { designMatrix, designMatrixMissing } from './design_matrix.js';\nimport { withPropCheck } from '@isle-project/utils/prop-check';\nimport { Factor } from '@isle-project/utils/factor-variable';\n\n\n// VARIABLES //\n\nlet COUNTER = 0;\n\n\n// FUNCTIONS //\n\nconst summaryTable = ( predictors, result, quantitative, t ) => {\n\treturn (\n\t\t<div>\n\t\t\t<span className=\"title\">{t('apriori-probs')}:</span>\n\t\t\t<Table bordered size=\"sm\">\n\t\t\t\t<thead>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t{result.classes.map( ( x, i ) => <th key={i}>{x}</th>)}\n\t\t\t\t\t</tr>\n\t\t\t\t</thead>\n\t\t\t\t<tbody>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t{result.classes.map( ( x, i ) => <th key={i}>{exp(result.prior[ x ]).toFixed( 3 )}</th>)}\n\t\t\t\t\t</tr>\n\t\t\t\t</tbody>\n\t\t\t</Table>\n\t\t\t<span className=\"title\">{t('conditionals')}:</span>\n\t\t\t{predictors.map( ( pred, i ) => {\n\t\t\t\tif ( contains( quantitative, pred ) ) {\n\t\t\t\t\treturn ( <Table bordered size=\"sm\" key={i} >\n\t\t\t\t\t\t<thead>\n\t\t\t\t\t\t\t<tr>\n\t\t\t\t\t\t\t\t<th>{pred}</th>\n\t\t\t\t\t\t\t\t{result.classes.map( ( x, i ) => <th key={i}>{x}</th>)}\n\t\t\t\t\t\t\t</tr>\n\t\t\t\t\t\t</thead>\n\t\t\t\t\t\t<tbody>\n\t\t\t\t\t\t\t<tr>\n\t\t\t\t\t\t\t\t<th>{t('mean')}</th>\n\t\t\t\t\t\t\t\t{result.classes.map( ( _, j ) => {\n\t\t\t\t\t\t\t\t\treturn <td key={`${i}-${j}`}>{result.mu.get( i, j ).toFixed( 6 )}</td>;\n\t\t\t\t\t\t\t\t})}\n\t\t\t\t\t\t\t</tr>\n\t\t\t\t\t\t\t<tr>\n\t\t\t\t\t\t\t\t<th>{t('sd')}</th>\n\t\t\t\t\t\t\t\t{result.classes.map( ( _, j ) => {\n\t\t\t\t\t\t\t\t\treturn <td key={`${i}-${j}`}>{result.sigma.get( i, j ).toFixed( 6 )}</td>;\n\t\t\t\t\t\t\t\t})}\n\t\t\t\t\t\t\t</tr>\n\t\t\t\t\t\t</tbody>\n\t\t\t\t\t</Table> );\n\t\t\t\t}\n\t\t\t\treturn ( <Table bordered size=\"sm\" key={i} >\n\t\t\t\t\t<thead>\n\t\t\t\t\t\t<tr>\n\t\t\t\t\t\t\t<th>{pred}</th>\n\t\t\t\t\t\t\t{result.classes.map( ( x, i ) => <th key={i}>{x}</th>)}\n\t\t\t\t\t\t</tr>\n\t\t\t\t\t</thead>\n\t\t\t\t\t<tbody>\n\t\t\t\t\t\t<tr>\n\t\t\t\t\t\t\t<th>{t('yes')}</th>\n\t\t\t\t\t\t\t{result.classes.map( ( _, j ) => {\n\t\t\t\t\t\t\t\treturn <td key={`${i}-${j}`}>{result.mu.get( i, j ).toFixed( 3 )}</td>;\n\t\t\t\t\t\t\t})}\n\t\t\t\t\t\t</tr>\n\t\t\t\t\t\t<tr>\n\t\t\t\t\t\t\t<th>{t('no')}</th>\n\t\t\t\t\t\t\t{result.classes.map( ( _, j ) => {\n\t\t\t\t\t\t\t\treturn <td key={`${i}-${j}`}>{(1-result.mu.get( i, j )).toFixed( 3 )}</td>;\n\t\t\t\t\t\t\t})}\n\t\t\t\t\t\t</tr>\n\t\t\t\t\t</tbody>\n\t\t\t\t</Table> );\n\t\t\t})}\n\t\t</div>\n\t);\n};\n\nconst fitModel = ({ x, y, data, quantitative, omitMissing }) => {\n\ttry {\n\t\tconst designM = omitMissing ? designMatrixMissing : designMatrix;\n\t\tconst { matrix, predictors, yvalues } = designM( x, y, data, quantitative );\n\t\tconst result = gaussian( matrix, yvalues );\n\t\treturn {\n\t\t\tresult,\n\t\t\tpredictors\n\t\t};\n\t} catch ( error ) {\n\t\treturn {};\n\t}\n};\n\n\n// MAIN //\n\n/**\n* Naive Bayes assuming that the predictors given the class membership follow a normal distribution.\n*\n* @property {Object} data - object of value arrays\n* @property {(string|Factor)} y - outcome variable\n* @property {(string|Factor|Array<(string|Factor)>)} x - one or more predictor variables\n* @property {Array<string>} quantitative - array of variables in `data` that are `quantitative`\n* @property {boolean} omitMissing - controls whether to omit missing values\n* @property {Function} onPredict - callback invoked with predictions and residuals after model fitting\n*/\nclass NaiveBayes extends Component {\n\tconstructor( props ) {\n\t\tsuper( props );\n\n\t\tCOUNTER += 1;\n\t\tconst { x, y, data, quantitative, omitMissing } = props;\n\t\tthis.state = {\n\t\t\t...fitModel({ x, y, data, quantitative, omitMissing }),\n\t\t\t...props\n\t\t};\n\t}\n\n\tstatic getDerivedStateFromProps( nextProps, prevState ) {\n\t\tif (\n\t\t\tnextProps.data !== prevState.data ||\n\t\t\tnextProps.quantitative !== prevState.quantitative ||\n\t\t\tnextProps.x !== prevState.x ||\n\t\t\tnextProps.y !== prevState.y ||\n\t\t\tnextProps.omitMissing !== prevState.omitMissing\n\t\t) {\n\t\t\tconst { x, y, data, quantitative, omitMissing } = nextProps;\n\t\t\treturn {\n\t\t\t\t...fitModel({ x, y, data, quantitative, omitMissing }),\n\t\t\t\t...nextProps\n\t\t\t};\n\t\t}\n\t\treturn null;\n\t}\n\n\thandlePrediction = () => {\n\t\tthis.props.onPredict( this.state.result, COUNTER );\n\t}\n\n\trender() {\n\t\tconst { result, predictors } = this.state;\n\t\tconst { t } = this.props;\n\t\tif ( !result ) {\n\t\t\treturn <Alert variant=\"danger\">{t('missing-attributes')}</Alert>;\n\t\t}\n\t\treturn (\n\t\t\t<div style={{ overflowX: 'auto', width: '100%' }}>\n\t\t\t\t<span className=\"title\" >{t('naive-bayes-for-response', { y: this.props.y, counter: COUNTER })}</span>\n\t\t\t\t{summaryTable( predictors, result, this.props.quantitative, t )}\n\t\t\t\t{this.props.onPredict ? <Tooltip tooltip={t('use-model-to-predict-tooltip')} >\n\t\t\t\t\t<Button variant=\"secondary\" size=\"sm\" onClick={this.handlePrediction} >{t('use-model-to-predict')}</Button>\n\t\t\t\t</Tooltip> : null}\n\t\t\t</div>\n\t\t);\n\t}\n}\n\n\n// PROPERTIES //\n\nNaiveBayes.defaultProps = {\n\tomitMissing: false,\n\tonPredict: null\n};\n\nNaiveBayes.propTypes = {\n\tdata: PropTypes.object.isRequired,\n\ty: PropTypes.oneOfType([\n\t\tPropTypes.string,\n\t\tPropTypes.instanceOf( Factor )\n\t]).isRequired,\n\tx: PropTypes.oneOfType([\n\t\tPropTypes.arrayOf( PropTypes.oneOfType([ PropTypes.string, PropTypes.instanceOf( Factor ) ]) ),\n\t\tPropTypes.string,\n\t\tPropTypes.instanceOf( Factor )\n\t]).isRequired,\n\tquantitative: PropTypes.arrayOf( PropTypes.string ).isRequired,\n\tomitMissing: PropTypes.bool,\n\tonPredict: PropTypes.func\n};\n\n\n// EXPORTS //\n\nexport default withTranslation( 'models' )( withPropCheck( NaiveBayes ) );\n","// MODULES //\n\nimport ndarray from '@stdlib/ndarray/array';\nimport hasOwnProperty from '@stdlib/assert/has-own-property';\nimport isArrayArray from '@stdlib/assert/is-array-array';\nimport isArrayLike from '@stdlib/assert/is-array-like';\nimport isMatrixLike from '@stdlib/assert/is-matrix-like';\nimport { isPrimitive as isNumber } from '@stdlib/assert/is-number';\nimport GaussianFit from './gaussian.js';\nimport MultinomialFit from './multinomial.js';\n\n\n// MAIN //\n\n/**\n* Fits a multinomial naive Bayes model.\n*\n* @param {(Matrix|Array)} x - design matrix\n* @param {Array} y - vector of class memberships\n* @param {Object} [opts] - function options\n* @param {number} [opts.alpha] - Laplace smoothing parameter\n* @returns {MultinomialFit} MultinomialFit instance\n*/\nfunction multinomNB( x, y, opts ) {\n\tif ( isArrayArray( x ) ) {\n\t\tx = ndarray( x );\n\t} else if ( !isMatrixLike( x ) ) {\n\t\tconst msg = 'invalid input argument. The first argument must be a matrix or an array-of-arrays. Value: `' + x + '`';\n\t\tthrow new TypeError( msg );\n\t}\n\tif ( !isArrayLike( y ) ) {\n\t\tthrow new TypeError( 'invalid input argument. The second argument must be array-like. Value: `' + y + '`' );\n\t}\n\tif ( arguments > 2 ) {\n\t\tif ( hasOwnProperty( opts, 'alpha' ) ) {\n\t\t\tif ( !isNumber( opts.alpha ) ) {\n\t\t\t\tthrow new TypeError( 'invalid option. Laplace smoothing option must be a number primitive. Option: `' + opts.alpha + '`.' );\n\t\t\t}\n\t\t}\n\t}\n\tconst alpha = opts.alpha || 1;\n\tconst fit = new MultinomialFit( x, y, alpha );\n\treturn fit;\n}\n\n/**\n* Fits a Gaussian naive Bayes model.\n*\n* @param {(Matrix|Array)} x - design matrix\n* @param {Array} y - vector of class memberships\n* @returns {GaussianFit} model fit\n*/\nfunction gaussianNB( x, y ) {\n\tif ( isArrayArray( x ) ) {\n\t\tx = ndarray( x );\n\t} else if ( !isMatrixLike( x ) ) {\n\t\tconst msg = 'invalid input argument. The first argument must be a matrix or an array-of-arrays. Value: `' + x + '`';\n\t\tthrow new TypeError( msg );\n\t}\n\tif ( !isArrayLike( y ) ) {\n\t\tthrow new TypeError( 'invalid input argument. The second argument must be array-like. Value: `' + y + '`' );\n\t}\n\tconst fit = new GaussianFit( x, y );\n\treturn fit;\n}\n\n\n// EXPORTS //\n\nexport { multinomNB as multinomial, gaussianNB as gaussian };\n","// MODULES //\n\nimport isArrayLike from '@stdlib/assert/is-array-like';\n\n\n// MAIN //\n\n/**\n* Calculates the mean accuracy of the given test data and labels.\n*\n* @param {(Matrix|Array)} x - design matrix\n* @param {Array} y - vector of class memberships\n* @returns {number} mean accuracy\n*/\nfunction score( x, y ) {\n\tif ( !isArrayLike( x ) ) {\n\t\tthrow new TypeError( 'invalid argument. First argument must be a matrix or array of test data. Value: `' + x + '`' );\n\t}\n\tif ( !isArrayLike( y ) ) {\n\t\tthrow new TypeError( 'invalid argument. Second argument must be an array of labels for the test data. Value: `' + y + '`' );\n\t}\n\tconst yhat = this.predict( x ); // eslint-disable-line @babel/no-invalid-this\n\tconst n = y.length;\n\tlet accuracy = 0;\n\tfor ( let i = 0; i < n; i++ ) {\n\t\tif ( yhat[ i ] === y[ i ] ) {\n\t\t\taccuracy += 1;\n\t\t}\n\t}\n\taccuracy /= n;\n\treturn accuracy;\n}\n\n\n// EXPORTS //\n\nexport default score;\n","// MODULES //\n\nimport isArrayLike from '@stdlib/assert/is-array-like';\nimport { isPrimitive as isNumber } from '@stdlib/assert/is-number';\n\n\n// MAIN //\n\n/**\n* Computes an element-wise subtraction.\n*\n* @param {NumberArray} arr - input array\n* @param {(NumberArray|number)} x - either an array of equal length or a scalar\n* @returns {NumberArray} output array\n*/\nfunction subtract( arr, x ) {\n\tconst isArr = isArrayLike( x );\n\tif ( !isArrayLike( arr ) ) {\n\t\tthrow new TypeError( 'invalid input argument. Must provide an array. Value: `' + arr + '`.' );\n\t}\n\tif ( !isArr && !isNumber( x ) ) {\n\t\tthrow new TypeError( 'invalid input argument. Second argument must either be an array or number primitive. Value: `' + x + '`.' );\n\t}\n\tconst len = arr.length;\n\tconst out = new Array( len );\n\n\t// Case 1: x is an array\n\tif ( isArr ) {\n\t\tif ( len !== x.length ) {\n\t\t\tthrow new Error( 'invalid input argument. Array to be added must have a length equal to that of the input array.' );\n\t\t}\n\t\tfor ( let i = 0; i < len; i++ ) {\n\t\t\tout[ i ] = arr[ i ] - x[ i ];\n\t\t}\n\t}\n\t// Case 2: scalar\n\telse {\n\t\tfor ( let i = 0; i < len; i++ ) {\n\t\t\tout[ i ] = arr[ i ] - x;\n\t\t}\n\t}\n\treturn out;\n}\n\n\n// EXPORTS //\n\nexport default subtract;\n","/**\n* @license Apache-2.0\n*\n* Copyright (c) 2018 The Stdlib Authors.\n*\n* Licensed under the Apache License, Version 2.0 (the \"License\");\n* you may not use this file except in compliance with the License.\n* You may obtain a copy of the License at\n*\n*    http://www.apache.org/licenses/LICENSE-2.0\n*\n* Unless required by applicable law or agreed to in writing, software\n* distributed under the License is distributed on an \"AS IS\" BASIS,\n* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n* See the License for the specific language governing permissions and\n* limitations under the License.\n*/\n'use strict';\n/**\n* Test if a value is an array of arrays.\n*\n* @module @stdlib/assert/is-array-array\n*\n* @example\n* var isArrayArray = require( '@stdlib/assert/is-array-array' );\n*\n* var bool = isArrayArray( [ [], [] ] );\n* // returns true\n*\n* bool = isArrayArray( [ {}, {} ] );\n* // returns false\n*\n* bool = isArrayArray( [] );\n* // returns false\n*/\n// MODULES //\n\nvar isArrayArray = require('./main.js'); // EXPORTS //\n\n\nmodule.exports = isArrayArray;","/**\n* @license Apache-2.0\n*\n* Copyright (c) 2018 The Stdlib Authors.\n*\n* Licensed under the Apache License, Version 2.0 (the \"License\");\n* you may not use this file except in compliance with the License.\n* You may obtain a copy of the License at\n*\n*    http://www.apache.org/licenses/LICENSE-2.0\n*\n* Unless required by applicable law or agreed to in writing, software\n* distributed under the License is distributed on an \"AS IS\" BASIS,\n* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n* See the License for the specific language governing permissions and\n* limitations under the License.\n*/\n'use strict'; // MODULES //\n\nvar arrayfun = require('./../../tools/array-function');\n\nvar isArray = require('./../../is-array'); // MAIN //\n\n/**\n* Tests if a value is an array of arrays.\n*\n* @name isArrayArray\n* @type {Function}\n* @param {*} value - value to test\n* @returns {boolean} boolean indicating whether a value is an array of arrays\n*\n* @example\n* var bool = isArrayArray( [ [], [] ] );\n* // returns true\n*\n* bool = isArrayArray( [ {}, {} ] );\n* // returns false\n*\n* bool = isArrayArray( [] );\n* // returns false\n*/\n\n\nvar isArrayArray = arrayfun(isArray); // EXPORTS //\n\nmodule.exports = isArrayArray;","export default function _readOnlyError(name) {\n  throw new TypeError(\"\\\"\" + name + \"\\\" is read-only\");\n}"],"names":["isMissing","x","isnan","isUndefinedOrNull","isNonMissingNumber","isNumber","designMatrix","y","data","quantitative","matrix","predictors","hash","isArray","j","length","values","contains","push","categories","extractCategoriesFromValues","k","nobs","i","row","val","ndarray","yvalues","designMatrixMissing","missing","GaussianFit","this","n","shape","p","classes","uniq","slice","nclass","fitGaussian","prototype","score","require","prior","mu","Float64Array","sigma","ids","c","nc","ln","vals","map","get","mean","stdev","set","calcGaussianProb","res","s2","PI","pow","predictOne","nClasses","logLik","Array","max","argmax","predict","isArrayArray","isMatrixLike","nrow","ncol","ret","arr","predictProbs","a","summand","exp","denom","subtract","sum","out","MultinomialFit","alpha","fitMultinomial","cprob","counts","Int32Array","totalCount","calcMultinomProb","COUNTER","fitModel","omitMissing","result","TypeError","isArrayLike","gaussian","error","NaiveBayes","props","onPredict","state","t","style","overflowX","width","className","counter","bordered","size","key","toFixed","pred","_","summaryTable","tooltip","Button","variant","onClick","handlePrediction","Alert","nextProps","prevState","Component","defaultProps","withTranslation","withPropCheck","yhat","accuracy","isArr","len","Error","module","exports","arrayfun","_readOnlyError","name"],"sourceRoot":""}