{"version":3,"sources":["../node_modules/@stdlib/assert/is-array-array/lib/index.js","../node_modules/@stdlib/assert/is-array-array/lib/main.js","../node_modules/@isle-project/components/models/naive-bayes/gaussian.js","../node_modules/@isle-project/components/models/naive-bayes/multinomial.js","../node_modules/@isle-project/components/models/naive-bayes/naive_bayes.js","../node_modules/@isle-project/components/models/naive-bayes/design_matrix.js","../node_modules/@isle-project/components/models/naive-bayes/main.js","../node_modules/@isle-project/components/models/naive-bayes/score.js"],"names":[],"mappings":"oKAwCA,GAAI,eAAe,oBAAS,OAK5B,OAAO,QAAU,e,oECvBjB,GAAI,UAAW,oBAAS,OACpB,QAAU,oBAAS,OAuBnB,cAAe,SAAU,SAK7B,OAAO,QAAU,e,uqDCzBjB,qBAAsB,EAAG,EAAI,CAC5B,KAAK,EAAI,EAAE,MAAO,GAClB,KAAK,EAAI,EAAE,MAAO,GAElB,KAAK,QAAU,eAAM,EAAE,SACvB,KAAK,OAAS,KAAK,QAAQ,OAE3B,KAAK,YAAa,EAAG,GAGtB,YAAY,UAAU,MAAQ,oBAAS,OAcvC,YAAY,UAAU,YAAc,SAAsB,EAAG,EAAI,CAChE,KAAK,MAAQ,GACb,KAAM,OAAQ,CAAE,KAAK,EAAG,KAAK,QAC7B,KAAK,GAAK,oBAAS,GAAI,cAAc,MAAM,GAAG,MAAM,IAAM,CAAE,QAC5D,KAAK,MAAQ,oBAAS,GAAI,cAAc,MAAM,GAAG,MAAM,IAAM,CAAE,QAC/D,OAAU,GAAI,EAAG,EAAI,KAAK,OAAQ,IAAM,CACvC,KAAM,KAAM,GACN,EAAI,KAAK,QAAS,GACxB,OAAU,GAAI,EAAG,EAAI,KAAK,EAAG,IACvB,EAAG,KAAQ,GACf,IAAI,KAAM,GAGZ,KAAM,IAAK,IAAI,OACf,KAAK,MAAO,GAAM,iBAAI,GAAK,KAAK,GAChC,OAAU,GAAI,EAAG,EAAI,KAAK,EAAG,IAAM,CAClC,KAAM,MAAO,IAAI,IAAK,IAAK,EAAE,IAAK,GAAG,IAC/B,GAAK,WAAM,MACX,MAAQ,YAAO,MACrB,KAAK,GAAG,IAAK,EAAG,EAAG,IACnB,KAAK,MAAM,IAAK,EAAG,EAAG,UAYzB,YAAY,UAAU,iBAAmB,SAA2B,EAAG,EAAI,CAC1E,KAAM,GAAI,KAAK,QAAS,GACxB,GAAI,KAAM,KAAK,MAAO,GAEtB,OAAU,GAAI,EAAG,EAAI,KAAK,EAAG,IAAM,CAClC,KAAM,OAAQ,KAAK,MAAM,IAAK,EAAG,GAC3B,GAAK,MAAM,MACX,GAAK,KAAK,GAAG,IAAK,EAAG,GAE3B,KADc,IAAO,iBAAI,EAAI,iBAAK,IAAW,kBAAK,EAAG,GAAM,GAAI,GAAM,GAGtE,MAAO,MASR,YAAY,UAAU,WAAa,SAAqB,EAAI,CAC3D,KAAM,UAAW,KAAK,QAAQ,OACxB,OAAS,GAAI,OAAO,UAC1B,OAAU,GAAI,EAAG,EAAI,SAAU,IAC9B,OAAQ,GAAM,KAAK,iBAAkB,EAAG,GAEzC,GAAI,MAAM,OAAQ,GACd,OAAS,KAAK,QAAS,GAC3B,OAAU,GAAI,EAAG,EAAI,SAAU,IAAM,CACpC,KAAM,KAAM,OAAQ,GACf,IAAM,MACV,MAAM,IACN,OAAS,KAAK,QAAS,IAGzB,MAAO,SASR,YAAY,UAAU,QAAU,SAAkB,EAAI,CACrD,KAAM,UAAW,KAAK,QAAQ,OAK9B,GAJK,6BAAc,IAClB,GAAI,oBAAS,IAGT,6BAAc,GAAM,CACxB,KAAM,CAAE,KAAM,MAAS,EAAE,MACnB,IAAM,GAAI,OAAO,MACvB,OAAU,GAAI,EAAG,EAAI,KAAM,IAAM,CAChC,KAAM,QAAS,GAAI,OAAO,UAC1B,OAAU,GAAI,EAAG,EAAI,SAAU,IAAM,CACpC,KAAM,KAAM,GAAI,OAAO,MACvB,OAAU,GAAI,EAAG,EAAI,KAAM,IAC1B,IAAK,GAAM,EAAE,IAAK,EAAG,GAEtB,OAAQ,GAAM,KAAK,iBAAkB,IAAK,GAE3C,GAAI,MAAM,OAAQ,GACd,OAAS,KAAK,QAAS,GAC3B,OAAU,GAAI,EAAG,EAAI,SAAU,IAAM,CACpC,KAAM,KAAM,OAAQ,GACf,IAAM,MACV,MAAM,IACN,OAAS,KAAK,QAAS,IAGzB,IAAK,GAAM,OAEZ,MAAO,KAGR,MAAO,MAAK,WAAY,IASzB,YAAY,UAAU,aAAe,SAAuB,EAAI,CAK/D,GAJK,6BAAc,IAClB,GAAI,oBAAS,IAGT,6BAAc,GAAM,CACxB,KAAM,CAAE,KAAM,MAAS,EAAE,MACnB,IAAM,GAAI,OAAO,MACvB,OAAU,GAAI,EAAG,EAAI,KAAM,IAAM,CAChC,GAAI,SAAS,GAAI,OAAO,KAAK,QAC7B,OAAU,GAAI,EAAG,EAAI,KAAK,OAAQ,IAAM,CACvC,KAAM,KAAM,GAAI,OAAO,MACvB,OAAU,GAAI,EAAG,EAAI,KAAM,IAC1B,IAAK,GAAM,EAAE,IAAK,EAAG,GAEtB,QAAQ,GAAM,KAAK,iBAAkB,IAAK,GAE3C,KAAM,IAAI,UAAK,SACf,GAAI,UAAU,EACd,OAAU,GAAI,EAAG,EAAI,QAAO,OAAQ,IACnC,UAAW,kBAAK,QAAQ,GAAM,IAE/B,KAAM,QAAQ,GAAI,iBAAI,UACtB,QAAS,eAAU,QAAQ,QAC3B,IAAK,GAAM,QAAO,IAAK,IAAK,kBAAK,KAElC,MAAO,KAGR,KAAM,QAAS,GAAI,OAAO,KAAK,QAC/B,OAAU,GAAI,EAAG,EAAI,KAAK,OAAQ,IACjC,OAAQ,GAAM,KAAK,iBAAkB,EAAG,GAEzC,KAAM,GAAI,UAAK,QACf,GAAI,SAAU,EACd,OAAU,GAAI,EAAG,EAAI,OAAO,OAAQ,IACnC,SAAW,kBAAK,OAAQ,GAAM,GAE/B,KAAM,OAAQ,EAAI,iBAAI,SACtB,cAAS,eAAU,OAAQ,OACpB,OAAO,IAAK,IAAK,kBAAK,MAM9B,aAAe,Y,+BC7Lf,oCAAyB,EAAG,EAAG,MAAQ,CACtC,KAAK,EAAI,EAAE,MAAO,GAClB,KAAK,EAAI,EAAE,MAAO,GAElB,KAAK,QAAU,eAAM,EAAE,SACvB,KAAK,OAAS,KAAK,QAAQ,OAC3B,KAAK,MAAQ,MAEb,KAAK,eAAgB,EAAG,GAGzB,2BAAe,UAAU,MAAQ,oBAAS,OAc1C,2BAAe,UAAU,eAAiB,SAAyB,EAAG,EAAI,CACzE,KAAM,OAAQ,GACR,MAAQ,CAAE,KAAK,EAAG,KAAK,QACvB,MAAQ,oBAAS,GAAI,cAAc,MAAM,GAAG,MAAM,IAAM,CAAE,QAChE,OAAU,GAAI,EAAG,EAAI,KAAK,OAAQ,IAAM,CACvC,KAAM,KAAM,GACN,OAAS,GAAI,YAAY,KAAK,GAC9B,EAAI,KAAK,QAAS,GACxB,OAAU,GAAI,EAAG,EAAI,KAAK,EAAG,IACvB,EAAG,KAAQ,GACf,IAAI,KAAM,GAGZ,KAAM,IAAK,IAAI,OACf,MAAO,GAAM,iBAAI,GAAK,KAAK,GAC3B,GAAI,YAAa,EACjB,OAAU,GAAI,EAAG,EAAI,KAAK,EAAG,IAAM,CAClC,KAAM,MAAO,IAAI,IAAK,IAAK,EAAE,IAAK,GAAG,IACrC,OAAQ,GAAM,UAAK,MACnB,YAAc,OAAQ,GAEvB,OAAU,GAAI,EAAG,EAAI,KAAK,EAAG,IAAM,CAClC,KAAM,KAAM,iBAAI,OAAQ,GAAM,KAAK,OAAU,iBAAI,WAAa,KAAK,EAAI,KAAK,OAC5E,MAAM,IAAK,EAAG,EAAG,MAGnB,KAAK,MAAQ,MACb,KAAK,MAAQ,OAWd,2BAAe,UAAU,iBAAmB,SAA2B,EAAG,EAAG,EAAI,CAChF,KAAM,GAAI,KAAK,QAAS,GACxB,GAAI,KAAM,KAAK,MAAO,GACtB,IAAM,EAAI,EAAG,EAAI,KAAK,EAAG,IAExB,KADY,EAAG,GAAM,EAAG,GAAM,KAAK,MAAM,IAAK,EAAG,GAAM,EAGxD,MAAO,MASR,2BAAe,UAAU,WAAa,SAAqB,EAAI,CAC9D,KAAM,UAAW,KAAK,QAAQ,OACxB,OAAS,GAAI,OAAO,UAC1B,OAAU,GAAI,EAAG,EAAI,SAAU,IAAM,CACpC,KAAM,GAAI,KAAK,QAAS,GACxB,OAAQ,GAAM,KAAK,MAAO,GAC1B,OAAU,GAAI,EAAG,EAAI,KAAK,EAAG,IAAM,CAClC,KAAM,KAAM,EAAG,GAAM,EAAG,GAAM,KAAK,MAAM,IAAK,EAAG,GAAM,EACvD,OAAQ,IAAO,KAGjB,GAAI,MAAM,OAAQ,GACd,OAAS,KAAK,QAAS,GAC3B,OAAU,GAAI,EAAG,EAAI,SAAU,IAAM,CACpC,KAAM,KAAM,OAAQ,GACf,IAAM,MACV,MAAM,IACN,OAAS,KAAK,QAAS,IAGzB,MAAO,SASR,2BAAe,UAAU,QAAU,SAAkB,EAAI,CACxD,KAAM,UAAW,KAAK,QAAQ,OAK9B,GAJK,6BAAc,IAClB,GAAI,oBAAS,IAGT,6BAAc,GAAM,CACxB,KAAM,KAAM,GACN,KAAO,EAAE,MAAO,GACtB,OAAU,GAAI,EAAG,EAAI,KAAM,IAAM,CAChC,KAAM,QAAS,GAAI,OAAO,UAC1B,OAAU,GAAI,EAAG,EAAI,SAAU,IAAM,CACpC,KAAM,GAAI,KAAK,QAAS,GACxB,OAAQ,GAAM,KAAK,MAAO,GAC1B,OAAU,GAAI,EAAG,EAAI,KAAK,EAAG,IAAM,CAClC,KAAM,KAAM,EAAE,IAAK,EAAG,GAAM,EAAE,IAAK,EAAG,GAAM,KAAK,MAAM,IAAK,EAAG,GAAM,EACrE,OAAQ,IAAO,KAGjB,GAAI,MAAM,OAAQ,GACd,OAAS,KAAK,QAAS,GAC3B,OAAU,GAAI,EAAG,EAAI,SAAU,IAAM,CACnC,KAAM,KAAM,OAAQ,GACf,IAAM,MACV,MAAM,IACN,OAAS,KAAK,QAAS,IAG1B,IAAK,GAAM,OAEZ,MAAO,KAGR,MAAO,MAAK,WAAY,IASzB,2BAAe,UAAU,aAAe,SAAuB,EAAI,CAKlE,GAJK,6BAAc,IAClB,GAAI,oBAAS,IAGT,6BAAc,GAAM,CACxB,KAAM,MAAO,EAAE,MAAO,GAChB,IAAM,GAAI,OAAO,MACvB,OAAU,GAAI,EAAG,EAAI,KAAM,IAAM,CAChC,GAAI,SAAS,GAAI,OAAO,KAAK,QAC7B,OAAU,GAAI,EAAG,EAAI,KAAK,OAAQ,IAAM,CACvC,KAAM,GAAI,KAAK,QAAS,GACxB,QAAQ,GAAM,KAAK,MAAO,GAC1B,OAAU,GAAI,EAAG,EAAI,KAAK,EAAG,IAAM,CAClC,KAAM,KAAM,EAAE,IAAK,EAAG,GAAM,EAAE,IAAK,EAAG,GAAM,KAAK,MAAM,IAAK,EAAG,GAAM,EACrE,QAAQ,IAAO,KAGjB,KAAM,IAAI,UAAK,SACf,GAAI,UAAU,EACd,OAAU,GAAI,EAAG,EAAI,QAAO,OAAQ,IACnC,UAAW,kBAAK,QAAQ,GAAM,IAE/B,KAAM,QAAQ,GAAI,iBAAI,UACtB,QAAS,eAAU,QAAQ,QAC3B,IAAK,GAAM,QAAO,IAAK,IAAK,kBAAK,KAElC,MAAO,KAGR,GAAI,QAAS,GAAI,OAAO,KAAK,QAC7B,OAAU,GAAI,EAAG,EAAI,KAAK,OAAQ,IAAM,CACvC,KAAM,GAAI,KAAK,QAAS,GACxB,OAAQ,GAAM,KAAK,MAAO,GAC1B,OAAU,GAAI,EAAG,EAAI,KAAK,EAAG,IAAM,CAClC,KAAM,KAAM,EAAG,GAAM,KAAK,MAAM,IAAK,EAAG,GACxC,OAAQ,IAAO,KAGjB,KAAM,GAAI,UAAK,QACf,GAAI,SAAU,EACd,OAAU,GAAI,EAAG,EAAI,OAAO,OAAQ,IACnC,SAAW,kBAAK,OAAQ,GAAM,GAE/B,KAAM,OAAQ,EAAI,iBAAI,SACtB,cAAS,eAAU,OAAQ,OACpB,OAAO,IAAK,IAAK,kBAAK,MAM9B,gBAAe,KC3Mf,oBAAqB,EAAG,EAAG,KAAO,CACjC,GAAK,aAAc,GAClB,EAAI,QAAS,WACF,CAAC,aAAc,GAAM,CAChC,KAAM,KAAM,8FAAgG,EAAI,IAChH,KAAM,IAAI,WAAW,KAEtB,GAAK,CAAC,YAAa,GAClB,KAAM,IAAI,WAAW,2EAA6E,EAAI,KAEvG,GAAK,UAAY,GACX,eAAgB,KAAM,UACrB,CAAC,SAAU,KAAK,OACpB,KAAM,IAAI,WAAW,iFAAmF,KAAK,MAAQ,MAIxH,KAAM,OAAQ,KAAK,OAAS,EAE5B,MADY,IAAI,gBAAgB,EAAG,EAAG,OAWvC,oBAAqB,EAAG,EAAI,CAC3B,GAAK,6BAAc,GAClB,EAAI,oBAAS,WACF,CAAC,6BAAc,GAAM,CAChC,KAAM,KAAM,8FAAgG,EAAI,IAChH,KAAM,IAAI,WAAW,KAEtB,GAAK,CAAC,4BAAa,GAClB,KAAM,IAAI,WAAW,2EAA6E,EAAI,KAGvG,MADY,IAAI,UAAa,EAAG,G,sPClD1B,sBAAuB,EAAG,EAAG,KAAM,aAAe,CACxD,GAAI,QAAS,GACb,KAAM,YAAa,GACb,KAAO,GACP,uBAAS,IACd,GAAI,CAAE,IAEP,OAAU,GAAI,EAAG,EAAI,EAAE,OAAQ,IAAM,CACpC,KAAM,QAAS,KAAM,EAAG,IACxB,GAAK,cAAU,aAAc,EAAG,IAC/B,WAAW,KAAM,EAAG,QACd,CACN,KAAM,YAAa,qCAA6B,OAAQ,EAAG,IAC3D,OAAU,GAAI,EAAG,EAAI,WAAW,OAAQ,IACvC,WAAW,KAAM,GAAG,EAAG,MAAO,WAAY,MAE3C,KAAM,EAAG,IAAQ,YAGnB,KAAM,MAAO,KAAM,EAAG,IAAM,OAC5B,OAAU,GAAI,EAAG,EAAI,KAAM,IAAM,CAChC,KAAM,KAAM,GACZ,OAAU,GAAI,EAAG,EAAI,EAAE,OAAQ,IAAM,CACpC,KAAM,QAAS,KAAM,EAAG,IACxB,GAAK,cAAU,aAAc,EAAG,IAC/B,IAAI,KAAM,OAAQ,QACZ,CACN,KAAM,YAAa,KAAM,EAAG,IACtB,IAAM,OAAQ,GACpB,OAAU,GAAI,EAAG,EAAI,WAAW,OAAQ,IACvC,IAAI,KAAQ,MAAQ,WAAY,GAAQ,EAAI,IAI/C,OAAO,KAAM,KAEd,OAAS,oBAAS,QAClB,KAAM,SAAU,KAAM,GACtB,MAAO,CAAE,OAAQ,WAAY,SAGvB,6BAA8B,EAAG,EAAG,KAAM,aAAe,CAC/D,GAAI,QAAS,GACb,KAAM,YAAa,GACb,KAAO,GACP,uBAAS,IACd,GAAI,CAAE,IAEP,OAAU,GAAI,EAAG,EAAI,EAAE,OAAQ,IAAM,CACpC,KAAM,QAAS,KAAM,EAAG,IACxB,GAAK,cAAU,aAAc,EAAG,IAC/B,WAAW,KAAM,EAAG,QACd,CACN,KAAM,YAAa,qCAA6B,OAAQ,EAAG,IAC3D,OAAU,GAAI,EAAG,EAAI,WAAW,OAAQ,IACvC,WAAW,KAAM,GAAG,EAAG,MAAO,WAAY,MAE3C,KAAM,EAAG,IAAQ,YAGnB,KAAM,MAAO,KAAM,EAAG,IAAM,OACtB,QAAU,GAChB,OAAU,GAAI,EAAG,EAAI,KAAM,IAAM,CAChC,KAAM,KAAM,GACZ,GAAI,SAAU,GACd,OAAU,GAAI,EAAG,EAAI,EAAE,OAAQ,IAAM,CACpC,KAAM,QAAS,KAAM,EAAG,IACxB,GAAK,cAAU,aAAc,EAAG,IAC1B,4BAAoB,OAAQ,IAChC,IAAI,KAAM,OAAQ,IAElB,QAAU,OAEL,CACN,KAAM,YAAa,KAAM,EAAG,IACtB,IAAM,OAAQ,GACpB,GAAK,iBAAW,KACf,QAAU,OAEV,QAAU,GAAI,EAAG,EAAI,WAAW,OAAQ,IACvC,IAAI,KAAQ,MAAQ,WAAY,GAAQ,EAAI,IAK3C,iBAAW,KAAM,GAAK,KAC1B,SAAU,IAEL,SACL,QAAO,KAAM,KACb,QAAQ,KAAM,KAAM,GAAK,KAG3B,cAAS,oBAAS,QACX,CAAE,OAAQ,WAAY,S,utBCvF9B,GAAI,SAAU,EAKd,KAAM,cAAe,CAAE,WAAY,OAAQ,aAAc,IAEvD,oBAAC,MAAD,KACC,oBAAC,OAAD,CAAM,UAAU,SAAS,EAAE,iBAAiB,KAC5C,oBAAC,QAAD,CAAO,SAAQ,GAAC,KAAK,MACpB,oBAAC,QAAD,KACC,oBAAC,KAAD,KACE,OAAO,QAAQ,IAAK,CAAE,EAAG,IAAO,oBAAC,KAAD,CAAI,IAAK,GAAI,MAGhD,oBAAC,QAAD,KACC,oBAAC,KAAD,KACE,OAAO,QAAQ,IAAK,CAAE,EAAG,IAAO,oBAAC,KAAD,CAAI,IAAK,GAAI,kBAAI,OAAO,MAAO,IAAK,QAAS,QAIjF,oBAAC,OAAD,CAAM,UAAU,SAAS,EAAE,gBAAgB,KAC1C,WAAW,IAAK,CAAE,KAAM,IACnB,cAAU,aAAc,MACnB,oBAAC,QAAD,CAAO,SAAQ,GAAC,KAAK,KAAK,IAAK,GACvC,oBAAC,QAAD,KACC,oBAAC,KAAD,KACC,oBAAC,KAAD,KAAK,MACJ,OAAO,QAAQ,IAAK,CAAE,EAAG,KAAO,oBAAC,KAAD,CAAI,IAAK,IAAI,MAGhD,oBAAC,QAAD,KACC,oBAAC,KAAD,KACC,oBAAC,KAAD,KAAK,EAAE,SACN,OAAO,QAAQ,IAAK,CAAE,EAAG,IAClB,oBAAC,KAAD,CAAI,IAAK,GAAG,KAAK,KAAM,OAAO,GAAG,IAAK,EAAG,GAAI,QAAS,MAG/D,oBAAC,KAAD,KACC,oBAAC,KAAD,KAAK,EAAE,OACN,OAAO,QAAQ,IAAK,CAAE,EAAG,IAClB,oBAAC,KAAD,CAAI,IAAK,GAAG,KAAK,KAAM,OAAO,MAAM,IAAK,EAAG,GAAI,QAAS,QAM5D,oBAAC,QAAD,CAAO,SAAQ,GAAC,KAAK,KAAK,IAAK,GACvC,oBAAC,QAAD,KACC,oBAAC,KAAD,KACC,oBAAC,KAAD,KAAK,MACJ,OAAO,QAAQ,IAAK,CAAE,EAAG,KAAO,oBAAC,KAAD,CAAI,IAAK,IAAI,MAGhD,oBAAC,QAAD,KACC,oBAAC,KAAD,KACC,oBAAC,KAAD,KAAK,EAAE,QACN,OAAO,QAAQ,IAAK,CAAE,EAAG,IAClB,oBAAC,KAAD,CAAI,IAAK,GAAG,KAAK,KAAM,OAAO,GAAG,IAAK,EAAG,GAAI,QAAS,MAG/D,oBAAC,KAAD,KACC,oBAAC,KAAD,KAAK,EAAE,OACN,OAAO,QAAQ,IAAK,CAAE,EAAG,IAClB,oBAAC,KAAD,CAAI,IAAK,GAAG,KAAK,KAAO,GAAE,OAAO,GAAG,IAAK,EAAG,IAAK,QAAS,UAUnE,SAAW,CAAC,CAAE,EAAG,EAAG,KAAM,aAAc,eAAkB,CAC/D,GAAI,CACH,KAAM,SAAU,YAAc,oBAAsB,aAC9C,CAAE,OAAQ,WAAY,SAAY,QAAS,EAAG,EAAG,KAAM,cAE7D,MAAO,CACN,OAFc,WAAU,OAAQ,SAGhC,kBAEQ,MAFR,CAGD,MAAO,KAiBT,wBAAyB,gBAAU,CAClC,YAAa,MAAQ,CACpB,MAAO,OA2BR,sCAAmB,IAAM,CACxB,KAAM,SAAY,OAAU,CAC3B,KAAM,QAAS,KAAK,MAAM,OACpB,CAAE,QAAW,aAAc,KAAK,MAAM,EAAG,KAAK,MAAM,EAAG,MAAM,KAAK,MAAM,cACxE,MAAQ,OAAO,aAAc,QAC7B,WAAa,GACnB,OAAU,GAAI,EAAG,EAAI,OAAO,QAAQ,OAAQ,IAAM,CACjD,KAAM,OAAO,SAAW,OAAO,QAAS,GAAM,SAAW,QACzD,WAAY,OAAS,MAAM,IAAK,IAAK,GAAG,IAEzC,KAAM,QAAS,OAAO,QAAS,QACzB,KAAO,aAAc,QACrB,eAAiB,KAAK,MAAM,YAAY,QAC9C,MAAM,eAAU,eAAgB,OAC/B,eAAe,KAAM,MAEf,CAAE,OAAQ,aAElB,KAAK,MAAM,UAAW,QAAS,WA3C/B,SAAW,EACX,KAAM,CAAE,EAAG,EAAG,KAAM,aAAc,aAAgB,MAClD,KAAK,MAAQ,iCACT,SAAS,CAAE,EAAG,EAAG,KAAM,aAAc,eACrC,aAIE,0BAA0B,UAAW,UAAY,CACvD,GACC,UAAU,OAAS,UAAU,MAC7B,UAAU,eAAiB,UAAU,cACrC,UAAU,IAAM,UAAU,GAC1B,UAAU,IAAM,UAAU,GAC1B,UAAU,cAAgB,UAAU,YACnC,CACD,KAAM,CAAE,EAAG,EAAG,KAAM,aAAc,aAAgB,UAClD,MAAO,kCACH,SAAS,CAAE,EAAG,EAAG,KAAM,aAAc,eACrC,WAGL,MAAO,MAwBR,QAAS,CACR,KAAM,CAAE,OAAQ,YAAe,KAAK,MAC9B,CAAE,GAAM,KAAK,MACnB,MAAM,QAIL,oBAAC,MAAD,CAAK,MAAO,CAAE,UAAW,OAAQ,MAAO,SACvC,oBAAC,OAAD,CAAM,UAAU,SAAU,EAAE,2BAA4B,CAAE,EAAG,KAAK,MAAM,EAAG,QAAS,WACnF,aAAc,WAAY,OAAQ,KAAK,MAAM,aAAc,GAC3D,KAAK,MAAM,UAAY,oBAAC,UAAD,CAAS,QAAS,EAAE,iCAC3C,oBAAC,iBAAD,CAAQ,QAAQ,YAAY,KAAK,KAAK,QAAS,KAAK,kBAAoB,EAAE,0BAC9D,MARP,oBAAC,gBAAD,CAAO,QAAQ,UAAU,EAAE,wBAiBrC,WAAW,aAAe,CACzB,YAAa,GACb,UAAW,MAGZ,WAAW,UAAY,CACtB,KAAM,uCACN,EAAG,+BAAoB,CACtB,4BACA,gCAAsB,qBACpB,WACH,EAAG,+BAAoB,CACtB,6BAAmB,+BAAoB,CAAE,4BAAkB,gCAAsB,sBACjF,4BACA,gCAAsB,qBACpB,WACH,aAAc,6BAAmB,6BAAmB,WACpD,YAAa,0BACb,UAAW,2BAMZ,SAAe,gBAAiB,UAAY,iBAAe,c,uWCzM3D,eAAgB,EAAG,EAAI,CACtB,GAAK,CAAC,oEAAa,GAClB,KAAM,IAAI,WAAW,oFAAsF,EAAI,KAEhH,GAAK,CAAC,oEAAa,GAClB,KAAM,IAAI,WAAW,2FAA6F,EAAI,KAEvH,KAAM,MAAO,KAAK,QAAS,GACrB,EAAI,EAAE,OACZ,GAAI,UAAW,EACf,OAAU,GAAI,EAAG,EAAI,EAAG,IAClB,KAAM,KAAQ,EAAG,IACrB,WAAY,GAGd,iBAAY,EACL,SAMR,4BAAe","file":"static/js/NaiveBayes.0c194313.chunk.js","sourcesContent":["/**\n* @license Apache-2.0\n*\n* Copyright (c) 2018 The Stdlib Authors.\n*\n* Licensed under the Apache License, Version 2.0 (the \"License\");\n* you may not use this file except in compliance with the License.\n* You may obtain a copy of the License at\n*\n*    http://www.apache.org/licenses/LICENSE-2.0\n*\n* Unless required by applicable law or agreed to in writing, software\n* distributed under the License is distributed on an \"AS IS\" BASIS,\n* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n* See the License for the specific language governing permissions and\n* limitations under the License.\n*/\n\n'use strict';\n\n/**\n* Test if a value is an array of arrays.\n*\n* @module @stdlib/assert/is-array-array\n*\n* @example\n* var isArrayArray = require( '@stdlib/assert/is-array-array' );\n*\n* var bool = isArrayArray( [ [], [] ] );\n* // returns true\n*\n* bool = isArrayArray( [ {}, {} ] );\n* // returns false\n*\n* bool = isArrayArray( [] );\n* // returns false\n*/\n\n// MODULES //\n\nvar isArrayArray = require( './main.js' );\n\n\n// EXPORTS //\n\nmodule.exports = isArrayArray;\n","/**\n* @license Apache-2.0\n*\n* Copyright (c) 2018 The Stdlib Authors.\n*\n* Licensed under the Apache License, Version 2.0 (the \"License\");\n* you may not use this file except in compliance with the License.\n* You may obtain a copy of the License at\n*\n*    http://www.apache.org/licenses/LICENSE-2.0\n*\n* Unless required by applicable law or agreed to in writing, software\n* distributed under the License is distributed on an \"AS IS\" BASIS,\n* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n* See the License for the specific language governing permissions and\n* limitations under the License.\n*/\n\n'use strict';\n\n// MODULES //\n\nvar arrayfun = require( './../../tools/array-function' );\nvar isArray = require( './../../is-array' );\n\n\n// MAIN //\n\n/**\n* Tests if a value is an array of arrays.\n*\n* @name isArrayArray\n* @type {Function}\n* @param {*} value - value to test\n* @returns {boolean} boolean indicating whether a value is an array of arrays\n*\n* @example\n* var bool = isArrayArray( [ [], [] ] );\n* // returns true\n*\n* bool = isArrayArray( [ {}, {} ] );\n* // returns false\n*\n* bool = isArrayArray( [] );\n* // returns false\n*/\nvar isArrayArray = arrayfun( isArray );\n\n\n// EXPORTS //\n\nmodule.exports = isArrayArray;\n","// MODULES //\n\nimport uniq from 'uniq';\nimport ndarray from '@stdlib/ndarray/array';\nimport isArrayArray from '@stdlib/assert/is-array-array';\nimport isMatrixLike from '@stdlib/assert/is-matrix-like';\nimport exp from '@stdlib/math/base/special/exp';\nimport ln from '@stdlib/math/base/special/ln';\nimport pow from '@stdlib/math/base/special/pow';\nimport PI from '@stdlib/constants/float64/pi';\nimport mean from '@isle-project/utils/statistic/mean';\nimport stdev from '@isle-project/utils/statistic/stdev';\nimport max from '@isle-project/utils/statistic/max';\nimport subtract from '@isle-project/utils/subtract';\n\n\n// MAIN //\n\n/**\n* Naive Bayes fitting object constructor for normal distribution.\n*\n* @constructor\n* @param {Matrix} x - design matrix\n* @param {Array} y - vector of class memberships\n* @returns {GaussianFit} GaussianFit instance\n*/\nfunction GaussianFit( x, y ) {\n\tthis.n = x.shape[ 0 ];\n\tthis.p = x.shape[ 1 ];\n\n\tthis.classes = uniq( y.slice() );\n\tthis.nclass = this.classes.length;\n\n\tthis.fitGaussian( x, y );\n}\n\nGaussianFit.prototype.score = require( './score.js' );\n\n\n/**\n* Fit the data under the assumption that p(x_i|c) follows a normal distribution.\n*\n* ## Notes\n*\n* -   Assigns prior and conditional probabilities of BayesFit instance.\n*\n* @param {Matrix} x - design matrix\n* @param {Array} y - vector of class memberships\n* @returns {void}\n*/\nGaussianFit.prototype.fitGaussian = function fitGaussian( x, y ) {\n\tthis.prior = {};\n\tconst shape = [ this.p, this.nclass ];\n\tthis.mu = ndarray( new Float64Array( shape[0]*shape[1] ), { 'shape': shape } );\n\tthis.sigma = ndarray( new Float64Array( shape[0]*shape[1] ), { 'shape': shape } );\n\tfor ( let i = 0; i < this.nclass; i++ ) {\n\t\tconst ids = [];\n\t\tconst c = this.classes[ i ];\n\t\tfor ( let j = 0; j < this.n; j++ ) {\n\t\t\tif ( y[ j ] === c ) {\n\t\t\t\tids.push( j );\n\t\t\t}\n\t\t}\n\t\tconst nc = ids.length;\n\t\tthis.prior[ c ] = ln( nc / this.n );\n\t\tfor ( let j = 0; j < this.p; j++ ) {\n\t\t\tconst vals = ids.map( i => x.get( i, j ) );\n\t\t\tconst mu = mean( vals );\n\t\t\tconst sigma = stdev( vals );\n\t\t\tthis.mu.set( j, i, mu );\n\t\t\tthis.sigma.set( j, i, sigma );\n\t\t}\n\t}\n};\n\n/**\n* Calculate p(X=x,C=i), i.e. the joint probability of observation x and class i.\n*\n* @param {Array} x - new observation\n* @param {number} i - class indicator\n* @returns {number} log probability\n*/\nGaussianFit.prototype.calcGaussianProb = function calcGaussianProb( x, i ) {\n\tconst c = this.classes[ i ];\n\tlet res = this.prior[ c ];\n\n\tfor ( let j = 0; j < this.p; j++ ) {\n\t\tconst sigma = this.sigma.get( j, i );\n\t\tconst s2 = sigma*sigma;\n\t\tconst mu = this.mu.get( j, i );\n\t\tconst val = ( -0.5 * ln( 2 * PI * s2 ) ) - ( pow( x[ j ] - mu, 2 ) / s2 );\n\t\tres += val;\n\t}\n\treturn res;\n};\n\n/**\n* Predict class membership for one new observation.\n*\n* @param {Array} x - new observation\n* @returns {(number|string)} predicted class membership\n*/\nGaussianFit.prototype.predictOne = function predictOne( x ) {\n\tconst nClasses = this.classes.length;\n\tconst logLik = new Array( nClasses );\n\tfor ( let i = 0; i < nClasses; i++ ) {\n\t\tlogLik[ i ] = this.calcGaussianProb( x, i );\n\t}\n\tlet max = logLik[ 0 ];\n\tlet argmax = this.classes[ 0 ];\n\tfor ( let i = 0; i < nClasses; i++ ) {\n\t\tconst val = logLik[ i ];\n\t\tif ( val > max ) {\n\t\t\tmax = val;\n\t\t\targmax = this.classes[ i ];\n\t\t}\n\t}\n\treturn argmax;\n};\n\n/**\n* Predict class membership for new observation(s).\n*\n* @param {(Matrix|Array)} x - new observation(s)\n* @returns {Array} array of predicted class memberships\n*/\nGaussianFit.prototype.predict = function predict( x ) {\n\tconst nClasses = this.classes.length;\n\tif ( isArrayArray( x ) ) {\n\t\tx = ndarray( x );\n\t}\n\t// Case A: Predictions for multiple observations:\n\tif ( isMatrixLike( x ) ) {\n\t\tconst [ nrow, ncol ] = x.shape;\n\t\tconst ret = new Array( nrow );\n\t\tfor ( let i = 0; i < nrow; i++ ) {\n\t\t\tconst logLik = new Array( nClasses );\n\t\t\tfor ( let j = 0; j < nClasses; j++ ) {\n\t\t\t\tconst arr = new Array( ncol );\n\t\t\t\tfor ( let k = 0; k < ncol; k++ ) {\n\t\t\t\t\tarr[ k ] = x.get( i, k );\n\t\t\t\t}\n\t\t\t\tlogLik[ j ] = this.calcGaussianProb( arr, j );\n\t\t\t}\n\t\t\tlet max = logLik[ 0 ];\n\t\t\tlet argmax = this.classes[ 0 ];\n\t\t\tfor ( let j = 0; j < nClasses; j++ ) {\n\t\t\t\tconst val = logLik[ j ];\n\t\t\t\tif ( val > max ) {\n\t\t\t\t\tmax = val;\n\t\t\t\t\targmax = this.classes[ j ];\n\t\t\t\t}\n\t\t\t}\n\t\t\tret[ i ] = argmax;\n\t\t}\n\t\treturn ret;\n\t}\n\t// Case B: Only one new observation:\n\treturn this.predictOne( x );\n};\n\n/**\n* Calculates class membership probabilities.\n*\n* @param {(Matrix|Array)} x - design matrix\n* @returns {Array} class probabilities\n*/\nGaussianFit.prototype.predictProbs = function predictProbs( x ) {\n\tif ( isArrayArray( x ) ) {\n\t\tx = ndarray( x );\n\t}\n\t// Case A: Predictions for multiple observations:\n\tif ( isMatrixLike( x ) ) {\n\t\tconst [ nrow, ncol ] = x.shape;\n\t\tconst ret = new Array( nrow );\n\t\tfor ( let i = 0; i < nrow; i++ ) {\n\t\t\tlet logLik = new Array( this.nclass );\n\t\t\tfor ( let j = 0; j < this.nclass; j++ ) {\n\t\t\t\tconst arr = new Array( ncol );\n\t\t\t\tfor ( let k = 0; k < ncol; k++ ) {\n\t\t\t\t\tarr[ k ] = x.get( i, k );\n\t\t\t\t}\n\t\t\t\tlogLik[ j ] = this.calcGaussianProb( arr, j );\n\t\t\t}\n\t\t\tconst a = max( logLik );\n\t\t\tlet summand = 0;\n\t\t\tfor ( let j = 0; j < logLik.length; j++ ) {\n\t\t\t\tsummand += exp( logLik[ j ] - a );\n\t\t\t}\n\t\t\tconst denom = a + ln( summand );\n\t\t\tlogLik = subtract( logLik, denom );\n\t\t\tret[ i ] = logLik.map( x => exp( x ) );\n\t\t}\n\t\treturn ret;\n\t}\n\t// Case B: Create prediction for a single observation:\n\tconst logLik = new Array( this.nclass );\n\tfor ( let j = 0; j < this.nclass; j++ ) {\n\t\tlogLik[ j ] = this.calcGaussianProb( x, j );\n\t}\n\tconst a = max( logLik );\n\tlet summand = 0;\n\tfor ( let j = 0; j < logLik.length; j++ ) {\n\t\tsummand += exp( logLik[ j ] - a );\n\t}\n\tconst denom = a + ln( summand );\n\tlogLik = subtract( logLik, denom );\n\treturn logLik.map( x => exp( x ) );\n};\n\n\n// EXPORTS //\n\nexport default GaussianFit;\n","// MODULES //\n\nimport uniq from 'uniq';\nimport ndarray from '@stdlib/ndarray/array';\nimport max from '@isle-project/utils/statistic/max';\nimport subtract from '@isle-project/utils/subtract';\nimport exp from '@stdlib/math/base/special/exp';\nimport isArrayArray from '@stdlib/assert/is-array-array';\nimport isMatrixLike from '@stdlib/assert/is-matrix-like';\nimport ln from '@stdlib/math/base/special/ln';\nimport sum from '@isle-project/utils/statistic/sum';\n\n\n// MAIN //\n\n/**\n* Naive Bayes fitting object constructor for multinomial distribution.\n*\n* @constructor\n* @param {Matrix} x - design matrix\n* @param {Array} y - vector of class memberships\n* @param {number} alpha - Laplace smoothing parameter\n* @returns {MultinomialFit} MultinomialFit instance\n*/\nfunction MultinomialFit( x, y, alpha ) {\n\tthis.n = x.shape[ 0 ];\n\tthis.p = x.shape[ 1 ];\n\n\tthis.classes = uniq( y.slice() );\n\tthis.nclass = this.classes.length;\n\tthis.alpha = alpha;\n\n\tthis.fitMultinomial( x, y );\n}\n\nMultinomialFit.prototype.score = require( './score.js' );\n\n\n/**\n* Fit the data under the assumption that p(x_i|c) follows a multinomial distribution.\n*\n* ## Notes\n*\n* -   Assigns prior and conditional probabilities of BayesFit instance.\n*\n* @param {Matrix} x - design matrix\n* @param {Array} y - vector of class memberships\n* @returns {Void}\n*/\nMultinomialFit.prototype.fitMultinomial = function fitMultinomial( x, y ) {\n\tconst prior = {};\n\tconst shape = [ this.p, this.nclass ];\n\tconst cprob = ndarray( new Float64Array( shape[0]*shape[1] ), { 'shape': shape } );\n\tfor ( let i = 0; i < this.nclass; i++ ) {\n\t\tconst ids = [];\n\t\tconst counts = new Int32Array( this.p );\n\t\tconst c = this.classes[ i ];\n\t\tfor ( let j = 0; j < this.n; j++ ) {\n\t\t\tif ( y[ j ] === c ) {\n\t\t\t\tids.push( j );\n\t\t\t}\n\t\t}\n\t\tconst nc = ids.length;\n\t\tprior[ c ] = ln( nc / this.n );\n\t\tlet totalCount = 0;\n\t\tfor ( let j = 0; j < this.p; j++ ) {\n\t\t\tconst vals = ids.map( i => x.get( i, j ) );\n\t\t\tcounts[ j ] = sum( vals );\n\t\t\ttotalCount += counts[ j ];\n\t\t}\n\t\tfor ( let j = 0; j < this.p; j++ ) {\n\t\t\tconst val = ln( counts[ j ] + this.alpha ) - ln( totalCount + this.p * this.alpha );\n\t\t\tcprob.set( j, i, val );\n\t\t}\n\t}\n\tthis.prior = prior;\n\tthis.cprob = cprob;\n};\n\n/**\n* Calculates multinomial probability.\n*\n* @param {Array} x - new observation\n* @param {number} i - class indicator\n* @param {number} j - variable indicator\n* @returns {number} probability\n*/\nMultinomialFit.prototype.calcMultinomProb = function calcMultinomProb( x, i, j ) {\n\tconst c = this.classes[ i ];\n\tlet res = this.prior[ c ];\n\tfor ( j = 0; j < this.p; j++ ) {\n\t\tconst val = x[ j ] ? x[ j ] * this.cprob.get( j, i ) : 0;\n\t\tres += val;\n\t}\n\treturn res;\n};\n\n/**\n* Predict class membership for one new observation.\n*\n* @param {Array} x - new observation\n* @returns {(number|string)} predicted class membership\n*/\nMultinomialFit.prototype.predictOne = function predictOne( x ) {\n\tconst nClasses = this.classes.length;\n\tconst logLik = new Array( nClasses );\n\tfor ( let i = 0; i < nClasses; i++ ) {\n\t\tconst c = this.classes[ i ];\n\t\tlogLik[ i ] = this.prior[ c ];\n\t\tfor ( let j = 0; j < this.p; j++ ) {\n\t\t\tconst val = x[ j ] ? x[ j ] * this.cprob.get( j, i ) : 0;\n\t\t\tlogLik[ i ] += val;\n\t\t}\n\t}\n\tlet max = logLik[ 0 ];\n\tlet argmax = this.classes[ 0 ];\n\tfor ( let i = 0; i < nClasses; i++ ) {\n\t\tconst val = logLik[ i ];\n\t\tif ( val > max ) {\n\t\t\tmax = val;\n\t\t\targmax = this.classes[ i ];\n\t\t}\n\t}\n\treturn argmax;\n};\n\n/**\n* Predict class membership for new observation(s).\n*\n* @param {(Matrix|Array)} x - new observation(s)\n* @returns {Array} array of predicted class memberships\n*/\nMultinomialFit.prototype.predict = function predict( x ) {\n\tconst nClasses = this.classes.length;\n\tif ( isArrayArray( x ) ) {\n\t\tx = ndarray( x );\n\t}\n\t// Case A: Predictions for multiple observations:\n\tif ( isMatrixLike( x ) ) {\n\t\tconst ret = [];\n\t\tconst nrow = x.shape[ 0 ];\n\t\tfor ( let i = 0; i < nrow; i++ ) {\n\t\t\tconst logLik = new Array( nClasses );\n\t\t\tfor ( let j = 0; j < nClasses; j++ ) {\n\t\t\t\tconst c = this.classes[ j ];\n\t\t\t\tlogLik[ j ] = this.prior[ c ];\n\t\t\t\tfor ( let k = 0; k < this.p; k++ ) {\n\t\t\t\t\tconst val = x.get( i, k ) ? x.get( i, k ) * this.cprob.get( k, j ) : 0;\n\t\t\t\t\tlogLik[ j ] += val;\n\t\t\t\t}\n\t\t\t}\n\t\t\tlet max = logLik[ 0 ];\n\t\t\tlet argmax = this.classes[ 0 ];\n\t\t\tfor ( let j = 0; j < nClasses; j++ ) {\n\t\t\t\t\tconst val = logLik[ j ];\n\t\t\t\t\tif ( val > max ) {\n\t\t\t\t\t\tmax = val;\n\t\t\t\t\t\targmax = this.classes[ j ];\n\t\t\t\t\t}\n\t\t\t}\n\t\t\tret[ i ] = argmax;\n\t\t}\n\t\treturn ret;\n\t}\n\t// Case B: Only one new observation:\n\treturn this.predictOne( x );\n};\n\n/**\n* Calculates class membership probabilities.\n*\n* @param {(Matrix|Array)} x - design matrix\n* @returns {Array} class probabilities\n*/\nMultinomialFit.prototype.predictProbs = function predictProbs( x ) {\n\tif ( isArrayArray( x ) ) {\n\t\tx = ndarray( x );\n\t}\n\t// Case A: Predictions for multiple observations:\n\tif ( isMatrixLike( x ) ) {\n\t\tconst nrow = x.shape[ 0 ];\n\t\tconst ret = new Array( nrow );\n\t\tfor ( let i = 0; i < nrow; i++ ) {\n\t\t\tlet logLik = new Array( this.nclass );\n\t\t\tfor ( let j = 0; j < this.nclass; j++ ) {\n\t\t\t\tconst c = this.classes[ j ];\n\t\t\t\tlogLik[ j ] = this.prior[ c ];\n\t\t\t\tfor ( let k = 0; k < this.p; k++ ) {\n\t\t\t\t\tconst val = x.get( i, k ) ? x.get( i, k ) * this.cprob.get( k, j ) : 0;\n\t\t\t\t\tlogLik[ j ] += val;\n\t\t\t\t}\n\t\t\t}\n\t\t\tconst a = max( logLik );\n\t\t\tlet summand = 0;\n\t\t\tfor ( let j = 0; j < logLik.length; j++ ) {\n\t\t\t\tsummand += exp( logLik[ j ] - a );\n\t\t\t}\n\t\t\tconst denom = a + ln( summand );\n\t\t\tlogLik = subtract( logLik, denom );\n\t\t\tret[ i ] = logLik.map( x => exp( x ) );\n\t\t}\n\t\treturn ret;\n\t}\n\t// Case B: Create prediction for a single observation:\n\tlet logLik = new Array( this.nclass );\n\tfor ( let j = 0; j < this.nclass; j++ ) {\n\t\tconst c = this.classes[ j ];\n\t\tlogLik[ j ] = this.prior[ c ];\n\t\tfor ( let k = 0; k < this.p; k++ ) {\n\t\t\tconst val = x[ k ] * this.cprob.get( k, j );\n\t\t\tlogLik[ j ] += val;\n\t\t}\n\t}\n\tconst a = max( logLik );\n\tlet summand = 0;\n\tfor ( let j = 0; j < logLik.length; j++ ) {\n\t\tsummand += exp( logLik[ j ] - a );\n\t}\n\tconst denom = a + ln( summand );\n\tlogLik = subtract( logLik, denom );\n\treturn logLik.map( x => exp( x ) );\n};\n\n\n// EXPORTS //\n\nexport default MultinomialFit;\n","// MODULES //\n\nimport ndarray from '@stdlib/ndarray/array';\nimport hasOwnProperty from '@stdlib/assert/has-own-property';\nimport isArrayArray from '@stdlib/assert/is-array-array';\nimport isArrayLike from '@stdlib/assert/is-array-like';\nimport isMatrixLike from '@stdlib/assert/is-matrix-like';\nimport { isPrimitive as isNumber } from '@stdlib/assert/is-number';\nimport GaussianFit from './gaussian.js';\nimport MultinomialFit from './multinomial.js';\n\n\n// MAIN //\n\n/**\n* Fits a multinomial naive Bayes model.\n*\n* @param {(Matrix|Array)} x - design matrix\n* @param {Array} y - vector of class memberships\n* @param {Object} [opts] - function options\n* @param {number} [opts.alpha] - Laplace smoothing parameter\n* @returns {MultinomialFit} MultinomialFit instance\n*/\nfunction multinomNB( x, y, opts ) {\n\tif ( isArrayArray( x ) ) {\n\t\tx = ndarray( x );\n\t} else if ( !isMatrixLike( x ) ) {\n\t\tconst msg = 'invalid input argument. The first argument must be a matrix or an array-of-arrays. Value: `' + x + '`';\n\t\tthrow new TypeError( msg );\n\t}\n\tif ( !isArrayLike( y ) ) {\n\t\tthrow new TypeError( 'invalid input argument. The second argument must be array-like. Value: `' + y + '`' );\n\t}\n\tif ( arguments > 2 ) {\n\t\tif ( hasOwnProperty( opts, 'alpha' ) ) {\n\t\t\tif ( !isNumber( opts.alpha ) ) {\n\t\t\t\tthrow new TypeError( 'invalid option. Laplace smoothing option must be a number primitive. Option: `' + opts.alpha + '`.' );\n\t\t\t}\n\t\t}\n\t}\n\tconst alpha = opts.alpha || 1;\n\tconst fit = new MultinomialFit( x, y, alpha );\n\treturn fit;\n}\n\n/**\n* Fits a Gaussian naive Bayes model.\n*\n* @param {(Matrix|Array)} x - design matrix\n* @param {Array} y - vector of class memberships\n* @returns {GaussianFit} model fit\n*/\nfunction gaussianNB( x, y ) {\n\tif ( isArrayArray( x ) ) {\n\t\tx = ndarray( x );\n\t} else if ( !isMatrixLike( x ) ) {\n\t\tconst msg = 'invalid input argument. The first argument must be a matrix or an array-of-arrays. Value: `' + x + '`';\n\t\tthrow new TypeError( msg );\n\t}\n\tif ( !isArrayLike( y ) ) {\n\t\tthrow new TypeError( 'invalid input argument. The second argument must be array-like. Value: `' + y + '`' );\n\t}\n\tconst fit = new GaussianFit( x, y );\n\treturn fit;\n}\n\n\n// EXPORTS //\n\nexport { multinomNB as multinomial, gaussianNB as gaussian };\n","// MODULES //\n\nimport contains from '@stdlib/assert/contains';\nimport ndarray from '@stdlib/ndarray/array';\nimport isArray from '@stdlib/assert/is-array';\nimport extractCategoriesFromValues from '@isle-project/utils/extract-categories-from-values';\nimport isNonMissingNumber from '@isle-project/utils/is-non-missing-number';\nimport isMissing from '@isle-project/utils/is-missing';\n\n\n// MAIN //\n\nexport function designMatrix( x, y, data, quantitative ) {\n\tlet matrix = [];\n\tconst predictors = [];\n\tconst hash = {};\n\tif ( !isArray( x ) ) {\n\t\tx = [ x ];\n\t}\n\tfor ( let j = 0; j < x.length; j++ ) {\n\t\tconst values = data[ x[ j ] ];\n\t\tif ( contains( quantitative, x[ j ] ) ) {\n\t\t\tpredictors.push( x[ j ] );\n\t\t} else {\n\t\t\tconst categories = extractCategoriesFromValues( values, x[ j ] );\n\t\t\tfor ( let k = 0; k < categories.length; k++ ) {\n\t\t\t\tpredictors.push( `${x[ j ]}_${categories[ k ]}` );\n\t\t\t}\n\t\t\thash[ x[ j ] ] = categories;\n\t\t}\n\t}\n\tconst nobs = data[ x[ 0 ] ].length;\n\tfor ( let i = 0; i < nobs; i++ ) {\n\t\tconst row = [];\n\t\tfor ( let j = 0; j < x.length; j++ ) {\n\t\t\tconst values = data[ x[ j ] ];\n\t\t\tif ( contains( quantitative, x[ j ] ) ) {\n\t\t\t\trow.push( values[ i ] );\n\t\t\t} else {\n\t\t\t\tconst categories = hash[ x[ j ] ];\n\t\t\t\tconst val = values[ i ];\n\t\t\t\tfor ( let k = 0; k < categories.length; k++ ) {\n\t\t\t\t\trow.push( ( val === categories[ k ] ) ? 1 : 0 );\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tmatrix.push( row );\n\t}\n\tmatrix = ndarray( matrix );\n\tconst yvalues = data[ y ];\n\treturn { matrix, predictors, yvalues };\n}\n\nexport function designMatrixMissing( x, y, data, quantitative ) {\n\tlet matrix = [];\n\tconst predictors = [];\n\tconst hash = {};\n\tif ( !isArray( x ) ) {\n\t\tx = [ x ];\n\t}\n\tfor ( let j = 0; j < x.length; j++ ) {\n\t\tconst values = data[ x[ j ] ];\n\t\tif ( contains( quantitative, x[ j ] ) ) {\n\t\t\tpredictors.push( x[ j ] );\n\t\t} else {\n\t\t\tconst categories = extractCategoriesFromValues( values, x[ j ] );\n\t\t\tfor ( let k = 0; k < categories.length; k++ ) {\n\t\t\t\tpredictors.push( `${x[ j ]}_${categories[ k ]}` );\n\t\t\t}\n\t\t\thash[ x[ j ] ] = categories;\n\t\t}\n\t}\n\tconst nobs = data[ x[ 0 ] ].length;\n\tconst yvalues = [];\n\tfor ( let i = 0; i < nobs; i++ ) {\n\t\tconst row = [];\n\t\tlet missing = false;\n\t\tfor ( let j = 0; j < x.length; j++ ) {\n\t\t\tconst values = data[ x[ j ] ];\n\t\t\tif ( contains( quantitative, x[ j ] ) ) {\n\t\t\t\tif ( isNonMissingNumber( values[ i ] ) ) {\n\t\t\t\t\trow.push( values[ i ] );\n\t\t\t\t} else {\n\t\t\t\t\tmissing = true;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tconst categories = hash[ x[ j ] ];\n\t\t\t\tconst val = values[ i ];\n\t\t\t\tif ( isMissing( val ) ) {\n\t\t\t\t\tmissing = true;\n\t\t\t\t} else {\n\t\t\t\t\tfor ( let k = 0; k < categories.length; k++ ) {\n\t\t\t\t\t\trow.push( ( val === categories[ k ] ) ? 1 : 0 );\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif ( isMissing( data[ y ][ i ] ) ) {\n\t\t\tmissing = true;\n\t\t}\n\t\tif ( !missing ) {\n\t\t\tmatrix.push( row );\n\t\t\tyvalues.push( data[ y ][ i ] );\n\t\t}\n\t}\n\tmatrix = ndarray( matrix );\n\treturn { matrix, predictors, yvalues };\n}\n","// MODULES //\n\nimport React, { Component } from 'react';\nimport PropTypes from 'prop-types';\nimport { withTranslation } from 'react-i18next';\nimport Alert from 'react-bootstrap/Alert';\nimport Button from 'react-bootstrap/Button';\nimport contains from '@stdlib/assert/contains';\nimport Table from '@isle-project/components/table';\nimport exp from '@stdlib/math/base/special/exp';\nimport Tooltip from '@isle-project/components/tooltip';\nimport { gaussian } from './naive_bayes.js';\nimport { designMatrix, designMatrixMissing } from './design_matrix.js';\nimport { withPropCheck } from '@isle-project/utils/prop-check';\nimport { Factor } from '@isle-project/utils/factor-variable';\n\n\n// VARIABLES //\n\nlet COUNTER = 0;\n\n\n// FUNCTIONS //\n\nconst summaryTable = ( predictors, result, quantitative, t ) => {\n\treturn (\n\t\t<div>\n\t\t\t<span className=\"title\">{t('apriori-probs')}:</span>\n\t\t\t<Table bordered size=\"sm\">\n\t\t\t\t<thead>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t{result.classes.map( ( x, i ) => <th key={i}>{x}</th>)}\n\t\t\t\t\t</tr>\n\t\t\t\t</thead>\n\t\t\t\t<tbody>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t{result.classes.map( ( x, i ) => <th key={i}>{exp(result.prior[ x ]).toFixed( 3 )}</th>)}\n\t\t\t\t\t</tr>\n\t\t\t\t</tbody>\n\t\t\t</Table>\n\t\t\t<span className=\"title\">{t('conditionals')}:</span>\n\t\t\t{predictors.map( ( pred, i ) => {\n\t\t\t\tif ( contains( quantitative, pred ) ) {\n\t\t\t\t\treturn ( <Table bordered size=\"sm\" key={i} >\n\t\t\t\t\t\t<thead>\n\t\t\t\t\t\t\t<tr>\n\t\t\t\t\t\t\t\t<th>{pred}</th>\n\t\t\t\t\t\t\t\t{result.classes.map( ( x, i ) => <th key={i}>{x}</th>)}\n\t\t\t\t\t\t\t</tr>\n\t\t\t\t\t\t</thead>\n\t\t\t\t\t\t<tbody>\n\t\t\t\t\t\t\t<tr>\n\t\t\t\t\t\t\t\t<th>{t('mean')}</th>\n\t\t\t\t\t\t\t\t{result.classes.map( ( _, j ) => {\n\t\t\t\t\t\t\t\t\treturn <td key={`${i}-${j}`}>{result.mu.get( i, j ).toFixed( 6 )}</td>;\n\t\t\t\t\t\t\t\t})}\n\t\t\t\t\t\t\t</tr>\n\t\t\t\t\t\t\t<tr>\n\t\t\t\t\t\t\t\t<th>{t('sd')}</th>\n\t\t\t\t\t\t\t\t{result.classes.map( ( _, j ) => {\n\t\t\t\t\t\t\t\t\treturn <td key={`${i}-${j}`}>{result.sigma.get( i, j ).toFixed( 6 )}</td>;\n\t\t\t\t\t\t\t\t})}\n\t\t\t\t\t\t\t</tr>\n\t\t\t\t\t\t</tbody>\n\t\t\t\t\t</Table> );\n\t\t\t\t}\n\t\t\t\treturn ( <Table bordered size=\"sm\" key={i} >\n\t\t\t\t\t<thead>\n\t\t\t\t\t\t<tr>\n\t\t\t\t\t\t\t<th>{pred}</th>\n\t\t\t\t\t\t\t{result.classes.map( ( x, i ) => <th key={i}>{x}</th>)}\n\t\t\t\t\t\t</tr>\n\t\t\t\t\t</thead>\n\t\t\t\t\t<tbody>\n\t\t\t\t\t\t<tr>\n\t\t\t\t\t\t\t<th>{t('yes')}</th>\n\t\t\t\t\t\t\t{result.classes.map( ( _, j ) => {\n\t\t\t\t\t\t\t\treturn <td key={`${i}-${j}`}>{result.mu.get( i, j ).toFixed( 3 )}</td>;\n\t\t\t\t\t\t\t})}\n\t\t\t\t\t\t</tr>\n\t\t\t\t\t\t<tr>\n\t\t\t\t\t\t\t<th>{t('no')}</th>\n\t\t\t\t\t\t\t{result.classes.map( ( _, j ) => {\n\t\t\t\t\t\t\t\treturn <td key={`${i}-${j}`}>{(1-result.mu.get( i, j )).toFixed( 3 )}</td>;\n\t\t\t\t\t\t\t})}\n\t\t\t\t\t\t</tr>\n\t\t\t\t\t</tbody>\n\t\t\t\t</Table> );\n\t\t\t})}\n\t\t</div>\n\t);\n};\n\nconst fitModel = ({ x, y, data, quantitative, omitMissing }) => {\n\ttry {\n\t\tconst designM = omitMissing ? designMatrixMissing : designMatrix;\n\t\tconst { matrix, predictors, yvalues } = designM( x, y, data, quantitative );\n\t\tconst result = gaussian( matrix, yvalues );\n\t\treturn {\n\t\t\tresult,\n\t\t\tpredictors\n\t\t};\n\t} catch ( error ) {\n\t\treturn {};\n\t}\n};\n\n\n// MAIN //\n\n/**\n* Naive Bayes assuming that the predictors given the class membership follow a normal distribution.\n*\n* @property {Object} data - object of value arrays\n* @property {(string|Factor)} y - outcome variable\n* @property {(string|Factor|Array<(string|Factor)>)} x - one or more predictor variables\n* @property {Array<string>} quantitative - array of variables in `data` that are `quantitative`\n* @property {boolean} omitMissing - controls whether to omit missing values\n* @property {Function} onPredict - callback invoked with predictions and residuals after model fitting\n*/\nclass NaiveBayes extends Component {\n\tconstructor( props ) {\n\t\tsuper( props );\n\n\t\tCOUNTER += 1;\n\t\tconst { x, y, data, quantitative, omitMissing } = props;\n\t\tthis.state = {\n\t\t\t...fitModel({ x, y, data, quantitative, omitMissing }),\n\t\t\t...props\n\t\t};\n\t}\n\n\tstatic getDerivedStateFromProps( nextProps, prevState ) {\n\t\tif (\n\t\t\tnextProps.data !== prevState.data ||\n\t\t\tnextProps.quantitative !== prevState.quantitative ||\n\t\t\tnextProps.x !== prevState.x ||\n\t\t\tnextProps.y !== prevState.y ||\n\t\t\tnextProps.omitMissing !== prevState.omitMissing\n\t\t) {\n\t\t\tconst { x, y, data, quantitative, omitMissing } = nextProps;\n\t\t\treturn {\n\t\t\t\t...fitModel({ x, y, data, quantitative, omitMissing }),\n\t\t\t\t...nextProps\n\t\t\t};\n\t\t}\n\t\treturn null;\n\t}\n\n\thandlePrediction = () => {\n\t\tconst predict = ( data ) => {\n\t\t\tconst result = this.state.result;\n\t\t\tconst { matrix } = designMatrix( this.props.x, this.props.y, data, this.props.quantitative );\n\t\t\tconst probs = result.predictProbs( matrix );\n\t\t\tconst classProbs = {};\n\t\t\tfor ( let i = 0; i < result.classes.length; i++ ) {\n\t\t\t\tconst name = 'probs_' + result.classes[ i ] + '_bayes' + COUNTER;\n\t\t\t\tclassProbs[ name ] = probs.map( x => x[ i ] );\n\t\t\t}\n\t\t\tconst fitted = result.predict( matrix );\n\t\t\tconst name = 'pred_bayes'+ COUNTER;\n\t\t\tconst newCategorical = this.props.categorical.slice();\n\t\t\tif ( !contains( newCategorical, name ) ) {\n\t\t\t\tnewCategorical.push( name );\n\t\t\t}\n\t\t\treturn { fitted, classProbs };\n\t\t};\n\t\tthis.props.onPredict( predict, COUNTER );\n\t};\n\n\trender() {\n\t\tconst { result, predictors } = this.state;\n\t\tconst { t } = this.props;\n\t\tif ( !result ) {\n\t\t\treturn <Alert variant=\"danger\">{t('missing-attributes')}</Alert>;\n\t\t}\n\t\treturn (\n\t\t\t<div style={{ overflowX: 'auto', width: '100%' }}>\n\t\t\t\t<span className=\"title\" >{t('naive-bayes-for-response', { y: this.props.y, counter: COUNTER })}</span>\n\t\t\t\t{summaryTable( predictors, result, this.props.quantitative, t )}\n\t\t\t\t{this.props.onPredict ? <Tooltip tooltip={t('use-model-to-predict-tooltip')} >\n\t\t\t\t\t<Button variant=\"secondary\" size=\"sm\" onClick={this.handlePrediction} >{t('use-model-to-predict')}</Button>\n\t\t\t\t</Tooltip> : null}\n\t\t\t</div>\n\t\t);\n\t}\n}\n\n\n// PROPERTIES //\n\nNaiveBayes.defaultProps = {\n\tomitMissing: false,\n\tonPredict: null\n};\n\nNaiveBayes.propTypes = {\n\tdata: PropTypes.object.isRequired,\n\ty: PropTypes.oneOfType([\n\t\tPropTypes.string,\n\t\tPropTypes.instanceOf( Factor )\n\t]).isRequired,\n\tx: PropTypes.oneOfType([\n\t\tPropTypes.arrayOf( PropTypes.oneOfType([ PropTypes.string, PropTypes.instanceOf( Factor ) ]) ),\n\t\tPropTypes.string,\n\t\tPropTypes.instanceOf( Factor )\n\t]).isRequired,\n\tquantitative: PropTypes.arrayOf( PropTypes.string ).isRequired,\n\tomitMissing: PropTypes.bool,\n\tonPredict: PropTypes.func\n};\n\n\n// EXPORTS //\n\nexport default withTranslation( 'models' )( withPropCheck( NaiveBayes ) );\n","// MODULES //\n\nimport isArrayLike from '@stdlib/assert/is-array-like';\n\n\n// MAIN //\n\n/**\n* Calculates the mean accuracy of the given test data and labels.\n*\n* @param {(Matrix|Array)} x - design matrix\n* @param {Array} y - vector of class memberships\n* @returns {number} mean accuracy\n*/\nfunction score( x, y ) {\n\tif ( !isArrayLike( x ) ) {\n\t\tthrow new TypeError( 'invalid argument. First argument must be a matrix or array of test data. Value: `' + x + '`' );\n\t}\n\tif ( !isArrayLike( y ) ) {\n\t\tthrow new TypeError( 'invalid argument. Second argument must be an array of labels for the test data. Value: `' + y + '`' );\n\t}\n\tconst yhat = this.predict( x ); // eslint-disable-line @babel/no-invalid-this\n\tconst n = y.length;\n\tlet accuracy = 0;\n\tfor ( let i = 0; i < n; i++ ) {\n\t\tif ( yhat[ i ] === y[ i ] ) {\n\t\t\taccuracy += 1;\n\t\t}\n\t}\n\taccuracy /= n;\n\treturn accuracy;\n}\n\n\n// EXPORTS //\n\nexport default score;\n"],"sourceRoot":""}