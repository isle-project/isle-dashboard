{"version":3,"sources":["../node_modules/@stdlib/assert/is-array-array/lib/index.js","../node_modules/@stdlib/assert/is-array-array/lib/main.js","../node_modules/@isle-project/components/models/naive-bayes/gaussian.js","../node_modules/@isle-project/components/models/naive-bayes/multinomial.js","../node_modules/@isle-project/components/models/naive-bayes/naive_bayes.js","../node_modules/@isle-project/components/models/naive-bayes/design_matrix.js","../node_modules/@isle-project/components/models/naive-bayes/main.js","../node_modules/@isle-project/components/models/naive-bayes/score.js"],"names":[],"mappings":"oKAwCA,GAAI,eAAe,oBAAS,KAAY,EAKxC,OAAO,QAAU,a,sECvBjB,GAAI,UAAW,oBAAS,KAA+B,EACnD,QAAU,oBAAS,KAAmB,EAuBtC,cAAe,SAAU,OAAQ,EAKrC,OAAO,QAAU,a,yqDCzBjB,qBAAsB,EAAG,EAAI,CAC5B,KAAK,EAAI,EAAE,MAAO,GAClB,KAAK,EAAI,EAAE,MAAO,GAElB,KAAK,QAAU,eAAM,EAAE,MAAM,CAAE,EAC/B,KAAK,OAAS,KAAK,QAAQ,OAE3B,KAAK,YAAa,EAAG,CAAE,CACxB,CAEA,YAAY,UAAU,MAAQ,oBAAS,KAAa,EAcpD,YAAY,UAAU,YAAc,SAAsB,EAAG,EAAI,CAChE,KAAK,MAAQ,CAAC,EACd,KAAM,OAAQ,CAAE,KAAK,EAAG,KAAK,MAAO,EACpC,KAAK,GAAK,oBAAS,GAAI,cAAc,MAAM,GAAG,MAAM,EAAG,EAAG,CAAE,KAAe,CAAE,EAC7E,KAAK,MAAQ,oBAAS,GAAI,cAAc,MAAM,GAAG,MAAM,EAAG,EAAG,CAAE,KAAe,CAAE,EAChF,OAAU,GAAI,EAAG,EAAI,KAAK,OAAQ,IAAM,CACvC,KAAM,KAAM,CAAC,EACP,EAAI,KAAK,QAAS,GACxB,OAAU,GAAI,EAAG,EAAI,KAAK,EAAG,IACvB,EAAG,KAAQ,GACf,IAAI,KAAM,CAAE,EAGd,KAAM,IAAK,IAAI,OACf,KAAK,MAAO,GAAM,iBAAI,GAAK,KAAK,CAAE,EAClC,OAAU,GAAI,EAAG,EAAI,KAAK,EAAG,IAAM,CAClC,KAAM,MAAO,IAAI,IAAK,IAAK,EAAE,IAAK,GAAG,CAAE,CAAE,EACnC,GAAK,WAAM,IAAK,EAChB,MAAQ,YAAO,IAAK,EAC1B,KAAK,GAAG,IAAK,EAAG,EAAG,EAAG,EACtB,KAAK,MAAM,IAAK,EAAG,EAAG,KAAM,CAC7B,CACD,CACD,EASA,YAAY,UAAU,iBAAmB,SAA2B,EAAG,EAAI,CAC1E,KAAM,GAAI,KAAK,QAAS,GACxB,GAAI,KAAM,KAAK,MAAO,GAEtB,OAAU,GAAI,EAAG,EAAI,KAAK,EAAG,IAAM,CAClC,KAAM,OAAQ,KAAK,MAAM,IAAK,EAAG,CAAE,EAC7B,GAAK,MAAM,MACX,GAAK,KAAK,GAAG,IAAK,EAAG,CAAE,EAE7B,KADc,IAAO,iBAAI,EAAI,iBAAK,EAAG,EAAQ,kBAAK,EAAG,GAAM,GAAI,CAAE,EAAI,EAEtE,CACA,MAAO,IACR,EAQA,YAAY,UAAU,WAAa,SAAqB,EAAI,CAC3D,KAAM,UAAW,KAAK,QAAQ,OACxB,OAAS,GAAI,OAAO,QAAS,EACnC,OAAU,GAAI,EAAG,EAAI,SAAU,IAC9B,OAAQ,GAAM,KAAK,iBAAkB,EAAG,CAAE,EAE3C,GAAI,MAAM,OAAQ,GACd,OAAS,KAAK,QAAS,GAC3B,OAAU,GAAI,EAAG,EAAI,SAAU,IAAM,CACpC,KAAM,KAAM,OAAQ,GACf,IAAM,MACV,MAAM,IACN,OAAS,KAAK,QAAS,GAEzB,CACA,MAAO,OACR,EAQA,YAAY,UAAU,QAAU,SAAkB,EAAI,CACrD,KAAM,UAAW,KAAK,QAAQ,OAK9B,GAJK,6BAAc,CAAE,GACpB,GAAI,oBAAS,CAAE,GAGX,6BAAc,CAAE,EAAI,CACxB,KAAM,CAAE,KAAM,MAAS,EAAE,MACnB,IAAM,GAAI,OAAO,IAAK,EAC5B,OAAU,GAAI,EAAG,EAAI,KAAM,IAAM,CAChC,KAAM,QAAS,GAAI,OAAO,QAAS,EACnC,OAAU,GAAI,EAAG,EAAI,SAAU,IAAM,CACpC,KAAM,KAAM,GAAI,OAAO,IAAK,EAC5B,OAAU,GAAI,EAAG,EAAI,KAAM,IAC1B,IAAK,GAAM,EAAE,IAAK,EAAG,CAAE,EAExB,OAAQ,GAAM,KAAK,iBAAkB,IAAK,CAAE,CAC7C,CACA,GAAI,MAAM,OAAQ,GACd,OAAS,KAAK,QAAS,GAC3B,OAAU,GAAI,EAAG,EAAI,SAAU,IAAM,CACpC,KAAM,KAAM,OAAQ,GACf,IAAM,MACV,MAAM,IACN,OAAS,KAAK,QAAS,GAEzB,CACA,IAAK,GAAM,MACZ,CACA,MAAO,IACR,CAEA,MAAO,MAAK,WAAY,CAAE,CAC3B,EAQA,YAAY,UAAU,aAAe,SAAuB,EAAI,CAK/D,GAJK,6BAAc,CAAE,GACpB,GAAI,oBAAS,CAAE,GAGX,6BAAc,CAAE,EAAI,CACxB,KAAM,CAAE,KAAM,MAAS,EAAE,MACnB,IAAM,GAAI,OAAO,IAAK,EAC5B,OAAU,GAAI,EAAG,EAAI,KAAM,IAAM,CAChC,GAAI,SAAS,GAAI,OAAO,KAAK,MAAO,EACpC,OAAU,GAAI,EAAG,EAAI,KAAK,OAAQ,IAAM,CACvC,KAAM,KAAM,GAAI,OAAO,IAAK,EAC5B,OAAU,GAAI,EAAG,EAAI,KAAM,IAC1B,IAAK,GAAM,EAAE,IAAK,EAAG,CAAE,EAExB,QAAQ,GAAM,KAAK,iBAAkB,IAAK,CAAE,CAC7C,CACA,KAAM,IAAI,UAAK,OAAO,EACtB,GAAI,UAAU,EACd,OAAU,GAAI,EAAG,EAAI,QAAO,OAAQ,IACnC,UAAW,kBAAK,QAAQ,GAAM,EAAE,EAEjC,KAAM,QAAQ,GAAI,iBAAI,QAAQ,EAC9B,QAAS,eAAU,QAAQ,MAAM,EACjC,IAAK,GAAM,QAAO,IAAK,IAAK,kBAAK,EAAE,CAAE,CACtC,CACA,MAAO,IACR,CAEA,KAAM,QAAS,GAAI,OAAO,KAAK,MAAO,EACtC,OAAU,GAAI,EAAG,EAAI,KAAK,OAAQ,IACjC,OAAQ,GAAM,KAAK,iBAAkB,EAAG,CAAE,EAE3C,KAAM,GAAI,UAAK,MAAO,EACtB,GAAI,SAAU,EACd,OAAU,GAAI,EAAG,EAAI,OAAO,OAAQ,IACnC,SAAW,kBAAK,OAAQ,GAAM,CAAE,EAEjC,KAAM,OAAQ,EAAI,iBAAI,OAAQ,EAC9B,cAAS,eAAU,OAAQ,KAAM,EAC1B,OAAO,IAAK,IAAK,kBAAK,EAAE,CAAE,CAClC,EAKA,aAAe,Y,+BC7Lf,oCAAyB,EAAG,EAAG,MAAQ,CACtC,KAAK,EAAI,EAAE,MAAO,GAClB,KAAK,EAAI,EAAE,MAAO,GAElB,KAAK,QAAU,eAAM,EAAE,MAAM,CAAE,EAC/B,KAAK,OAAS,KAAK,QAAQ,OAC3B,KAAK,MAAQ,MAEb,KAAK,eAAgB,EAAG,CAAE,CAC3B,CAEA,2BAAe,UAAU,MAAQ,oBAAS,KAAa,EAcvD,2BAAe,UAAU,eAAiB,SAAyB,EAAG,EAAI,CACzE,KAAM,OAAQ,CAAC,EACT,MAAQ,CAAE,KAAK,EAAG,KAAK,MAAO,EAC9B,MAAQ,oBAAS,GAAI,cAAc,MAAM,GAAG,MAAM,EAAG,EAAG,CAAE,KAAe,CAAE,EACjF,OAAU,GAAI,EAAG,EAAI,KAAK,OAAQ,IAAM,CACvC,KAAM,KAAM,CAAC,EACP,OAAS,GAAI,YAAY,KAAK,CAAE,EAChC,EAAI,KAAK,QAAS,GACxB,OAAU,GAAI,EAAG,EAAI,KAAK,EAAG,IACvB,EAAG,KAAQ,GACf,IAAI,KAAM,CAAE,EAGd,KAAM,IAAK,IAAI,OACf,MAAO,GAAM,iBAAI,GAAK,KAAK,CAAE,EAC7B,GAAI,YAAa,EACjB,OAAU,GAAI,EAAG,EAAI,KAAK,EAAG,IAAM,CAClC,KAAM,MAAO,IAAI,IAAK,IAAK,EAAE,IAAK,GAAG,CAAE,CAAE,EACzC,OAAQ,GAAM,UAAK,IAAK,EACxB,YAAc,OAAQ,EACvB,CACA,OAAU,GAAI,EAAG,EAAI,KAAK,EAAG,IAAM,CAClC,KAAM,KAAM,iBAAI,OAAQ,GAAM,KAAK,KAAM,EAAI,iBAAI,WAAa,KAAK,EAAI,KAAK,KAAM,EAClF,MAAM,IAAK,EAAG,EAAG,GAAI,CACtB,CACD,CACA,KAAK,MAAQ,MACb,KAAK,MAAQ,KACd,EAUA,2BAAe,UAAU,iBAAmB,SAA2B,EAAG,EAAG,EAAI,CAChF,KAAM,GAAI,KAAK,QAAS,GACxB,GAAI,KAAM,KAAK,MAAO,GACtB,IAAM,EAAI,EAAG,EAAI,KAAK,EAAG,IAExB,KADY,EAAG,GAAM,EAAG,GAAM,KAAK,MAAM,IAAK,EAAG,CAAE,EAAI,EAGxD,MAAO,IACR,EAQA,2BAAe,UAAU,WAAa,SAAqB,EAAI,CAC9D,KAAM,UAAW,KAAK,QAAQ,OACxB,OAAS,GAAI,OAAO,QAAS,EACnC,OAAU,GAAI,EAAG,EAAI,SAAU,IAAM,CACpC,KAAM,GAAI,KAAK,QAAS,GACxB,OAAQ,GAAM,KAAK,MAAO,GAC1B,OAAU,GAAI,EAAG,EAAI,KAAK,EAAG,IAAM,CAClC,KAAM,KAAM,EAAG,GAAM,EAAG,GAAM,KAAK,MAAM,IAAK,EAAG,CAAE,EAAI,EACvD,OAAQ,IAAO,GAChB,CACD,CACA,GAAI,MAAM,OAAQ,GACd,OAAS,KAAK,QAAS,GAC3B,OAAU,GAAI,EAAG,EAAI,SAAU,IAAM,CACpC,KAAM,KAAM,OAAQ,GACf,IAAM,MACV,MAAM,IACN,OAAS,KAAK,QAAS,GAEzB,CACA,MAAO,OACR,EAQA,2BAAe,UAAU,QAAU,SAAkB,EAAI,CACxD,KAAM,UAAW,KAAK,QAAQ,OAK9B,GAJK,6BAAc,CAAE,GACpB,GAAI,oBAAS,CAAE,GAGX,6BAAc,CAAE,EAAI,CACxB,KAAM,KAAM,CAAC,EACP,KAAO,EAAE,MAAO,GACtB,OAAU,GAAI,EAAG,EAAI,KAAM,IAAM,CAChC,KAAM,QAAS,GAAI,OAAO,QAAS,EACnC,OAAU,GAAI,EAAG,EAAI,SAAU,IAAM,CACpC,KAAM,GAAI,KAAK,QAAS,GACxB,OAAQ,GAAM,KAAK,MAAO,GAC1B,OAAU,GAAI,EAAG,EAAI,KAAK,EAAG,IAAM,CAClC,KAAM,KAAM,EAAE,IAAK,EAAG,CAAE,EAAI,EAAE,IAAK,EAAG,CAAE,EAAI,KAAK,MAAM,IAAK,EAAG,CAAE,EAAI,EACrE,OAAQ,IAAO,GAChB,CACD,CACA,GAAI,MAAM,OAAQ,GACd,OAAS,KAAK,QAAS,GAC3B,OAAU,GAAI,EAAG,EAAI,SAAU,IAAM,CACnC,KAAM,KAAM,OAAQ,GACf,IAAM,MACV,MAAM,IACN,OAAS,KAAK,QAAS,GAE1B,CACA,IAAK,GAAM,MACZ,CACA,MAAO,IACR,CAEA,MAAO,MAAK,WAAY,CAAE,CAC3B,EAQA,2BAAe,UAAU,aAAe,SAAuB,EAAI,CAKlE,GAJK,6BAAc,CAAE,GACpB,GAAI,oBAAS,CAAE,GAGX,6BAAc,CAAE,EAAI,CACxB,KAAM,MAAO,EAAE,MAAO,GAChB,IAAM,GAAI,OAAO,IAAK,EAC5B,OAAU,GAAI,EAAG,EAAI,KAAM,IAAM,CAChC,GAAI,SAAS,GAAI,OAAO,KAAK,MAAO,EACpC,OAAU,GAAI,EAAG,EAAI,KAAK,OAAQ,IAAM,CACvC,KAAM,GAAI,KAAK,QAAS,GACxB,QAAQ,GAAM,KAAK,MAAO,GAC1B,OAAU,GAAI,EAAG,EAAI,KAAK,EAAG,IAAM,CAClC,KAAM,KAAM,EAAE,IAAK,EAAG,CAAE,EAAI,EAAE,IAAK,EAAG,CAAE,EAAI,KAAK,MAAM,IAAK,EAAG,CAAE,EAAI,EACrE,QAAQ,IAAO,GAChB,CACD,CACA,KAAM,IAAI,UAAK,OAAO,EACtB,GAAI,UAAU,EACd,OAAU,GAAI,EAAG,EAAI,QAAO,OAAQ,IACnC,UAAW,kBAAK,QAAQ,GAAM,EAAE,EAEjC,KAAM,QAAQ,GAAI,iBAAI,QAAQ,EAC9B,QAAS,eAAU,QAAQ,MAAM,EACjC,IAAK,GAAM,QAAO,IAAK,IAAK,kBAAK,EAAE,CAAE,CACtC,CACA,MAAO,IACR,CAEA,GAAI,QAAS,GAAI,OAAO,KAAK,MAAO,EACpC,OAAU,GAAI,EAAG,EAAI,KAAK,OAAQ,IAAM,CACvC,KAAM,GAAI,KAAK,QAAS,GACxB,OAAQ,GAAM,KAAK,MAAO,GAC1B,OAAU,GAAI,EAAG,EAAI,KAAK,EAAG,IAAM,CAClC,KAAM,KAAM,EAAG,GAAM,KAAK,MAAM,IAAK,EAAG,CAAE,EAC1C,OAAQ,IAAO,GAChB,CACD,CACA,KAAM,GAAI,UAAK,MAAO,EACtB,GAAI,SAAU,EACd,OAAU,GAAI,EAAG,EAAI,OAAO,OAAQ,IACnC,SAAW,kBAAK,OAAQ,GAAM,CAAE,EAEjC,KAAM,OAAQ,EAAI,iBAAI,OAAQ,EAC9B,cAAS,eAAU,OAAQ,KAAM,EAC1B,OAAO,IAAK,IAAK,kBAAK,EAAE,CAAE,CAClC,EAKA,gBAAe,KC3Mf,oBAAqB,EAAG,EAAG,KAAO,CACjC,GAAK,aAAc,CAAE,EACpB,EAAI,QAAS,CAAE,UACJ,CAAC,aAAc,CAAE,EAAI,CAChC,KAAM,KAAM,8FAAgG,EAAI,IAChH,KAAM,IAAI,WAAW,GAAI,CAC1B,CACA,GAAK,CAAC,YAAa,CAAE,EACpB,KAAM,IAAI,WAAW,2EAA6E,EAAI,GAAI,EAE3G,GAAK,UAAY,GACX,eAAgB,KAAM,OAAQ,GAC7B,CAAC,SAAU,KAAK,KAAM,EAC1B,KAAM,IAAI,WAAW,iFAAmF,KAAK,MAAQ,IAAK,EAI7H,KAAM,OAAQ,KAAK,OAAS,EAE5B,MADY,IAAI,gBAAgB,EAAG,EAAG,KAAM,CAE7C,CASA,oBAAqB,EAAG,EAAI,CAC3B,GAAK,6BAAc,CAAE,EACpB,EAAI,oBAAS,CAAE,UACJ,CAAC,6BAAc,CAAE,EAAI,CAChC,KAAM,KAAM,8FAAgG,EAAI,IAChH,KAAM,IAAI,WAAW,GAAI,CAC1B,CACA,GAAK,CAAC,4BAAa,CAAE,EACpB,KAAM,IAAI,WAAW,2EAA6E,EAAI,GAAI,EAG3G,MADY,IAAI,UAAa,EAAG,CAAE,CAEnC,C,sPCpDO,sBAAuB,EAAG,EAAG,KAAM,aAAe,CACxD,GAAI,QAAS,CAAC,EACd,KAAM,YAAa,CAAC,EACd,KAAO,CAAC,EACR,uBAAS,CAAE,GAChB,GAAI,CAAE,CAAE,GAET,OAAU,GAAI,EAAG,EAAI,EAAE,OAAQ,IAAM,CACpC,KAAM,QAAS,KAAM,EAAG,IACxB,GAAK,cAAU,aAAc,EAAG,EAAI,EACnC,WAAW,KAAM,EAAG,EAAI,MAClB,CACN,KAAM,YAAa,qCAA6B,OAAQ,EAAG,EAAI,EAC/D,OAAU,GAAI,EAAG,EAAI,WAAW,OAAQ,IACvC,WAAW,KAAM,GAAG,EAAG,MAAO,WAAY,IAAM,EAEjD,KAAM,EAAG,IAAQ,UAClB,CACD,CACA,KAAM,MAAO,KAAM,EAAG,IAAM,OAC5B,OAAU,GAAI,EAAG,EAAI,KAAM,IAAM,CAChC,KAAM,KAAM,CAAC,EACb,OAAU,GAAI,EAAG,EAAI,EAAE,OAAQ,IAAM,CACpC,KAAM,QAAS,KAAM,EAAG,IACxB,GAAK,cAAU,aAAc,EAAG,EAAI,EACnC,IAAI,KAAM,OAAQ,EAAI,MAChB,CACN,KAAM,YAAa,KAAM,EAAG,IACtB,IAAM,OAAQ,GACpB,OAAU,GAAI,EAAG,EAAI,WAAW,OAAQ,IACvC,IAAI,KAAQ,MAAQ,WAAY,GAAQ,EAAI,CAAE,CAEhD,CACD,CACA,OAAO,KAAM,GAAI,CAClB,CACA,OAAS,oBAAS,MAAO,EACzB,KAAM,SAAU,KAAM,GACtB,MAAO,CAAE,OAAQ,WAAY,OAAQ,CACtC,CAEO,6BAA8B,EAAG,EAAG,KAAM,aAAe,CAC/D,GAAI,QAAS,CAAC,EACd,KAAM,YAAa,CAAC,EACd,KAAO,CAAC,EACR,uBAAS,CAAE,GAChB,GAAI,CAAE,CAAE,GAET,OAAU,GAAI,EAAG,EAAI,EAAE,OAAQ,IAAM,CACpC,KAAM,QAAS,KAAM,EAAG,IACxB,GAAK,cAAU,aAAc,EAAG,EAAI,EACnC,WAAW,KAAM,EAAG,EAAI,MAClB,CACN,KAAM,YAAa,qCAA6B,OAAQ,EAAG,EAAI,EAC/D,OAAU,GAAI,EAAG,EAAI,WAAW,OAAQ,IACvC,WAAW,KAAM,GAAG,EAAG,MAAO,WAAY,IAAM,EAEjD,KAAM,EAAG,IAAQ,UAClB,CACD,CACA,KAAM,MAAO,KAAM,EAAG,IAAM,OACtB,QAAU,CAAC,EACjB,OAAU,GAAI,EAAG,EAAI,KAAM,IAAM,CAChC,KAAM,KAAM,CAAC,EACb,GAAI,SAAU,GACd,OAAU,GAAI,EAAG,EAAI,EAAE,OAAQ,IAAM,CACpC,KAAM,QAAS,KAAM,EAAG,IACxB,GAAK,cAAU,aAAc,EAAG,EAAI,EAC9B,4BAAoB,OAAQ,EAAI,EACpC,IAAI,KAAM,OAAQ,EAAI,EAEtB,QAAU,OAEL,CACN,KAAM,YAAa,KAAM,EAAG,IACtB,IAAM,OAAQ,GACpB,GAAK,iBAAW,GAAI,EACnB,QAAU,OAEV,QAAU,GAAI,EAAG,EAAI,WAAW,OAAQ,IACvC,IAAI,KAAQ,MAAQ,WAAY,GAAQ,EAAI,CAAE,CAGjD,CACD,CACK,iBAAW,KAAM,GAAK,EAAI,GAC9B,SAAU,IAEL,SACL,QAAO,KAAM,GAAI,EACjB,QAAQ,KAAM,KAAM,GAAK,EAAI,EAE/B,CACA,cAAS,oBAAS,MAAO,EAClB,CAAE,OAAQ,WAAY,OAAQ,CACtC,C,utBCxFA,GAAI,SAAU,EAKd,KAAM,cAAe,CAAE,WAAY,OAAQ,aAAc,IAEvD,oBAAC,WACA,oBAAC,QAAK,UAAU,SAAS,EAAE,eAAe,EAAE,GAAC,EAC7C,oBAAC,QAAK,CAAC,SAAQ,GAAC,KAAK,MACpB,oBAAC,aACA,oBAAC,UACC,OAAO,QAAQ,IAAK,CAAE,EAAG,IAAO,oBAAC,MAAG,IAAK,GAAI,CAAE,CAAK,CACtD,CACD,EACA,oBAAC,aACA,oBAAC,UACC,OAAO,QAAQ,IAAK,CAAE,EAAG,IAAO,oBAAC,MAAG,IAAK,GAAI,kBAAI,OAAO,MAAO,EAAG,EAAE,QAAS,CAAE,CAAE,CAAK,CACxF,CACD,CACD,EACA,oBAAC,QAAK,UAAU,SAAS,EAAE,cAAc,EAAE,GAAC,EAC3C,WAAW,IAAK,CAAE,KAAM,IACnB,cAAU,aAAc,IAAK,EACxB,oBAAC,QAAK,CAAC,SAAQ,GAAC,KAAK,KAAK,IAAK,GACvC,oBAAC,aACA,oBAAC,UACA,oBAAC,UAAI,IAAK,EACT,OAAO,QAAQ,IAAK,CAAE,EAAG,KAAO,oBAAC,MAAG,IAAK,IAAI,CAAE,CAAK,CACtD,CACD,EACA,oBAAC,aACA,oBAAC,UACA,oBAAC,UAAI,EAAE,MAAM,CAAE,EACd,OAAO,QAAQ,IAAK,CAAE,EAAG,IAClB,oBAAC,MAAG,IAAK,GAAG,KAAK,KAAM,OAAO,GAAG,IAAK,EAAG,CAAE,EAAE,QAAS,CAAE,CAAE,CACjE,CACF,EACA,oBAAC,UACA,oBAAC,UAAI,EAAE,IAAI,CAAE,EACZ,OAAO,QAAQ,IAAK,CAAE,EAAG,IAClB,oBAAC,MAAG,IAAK,GAAG,KAAK,KAAM,OAAO,MAAM,IAAK,EAAG,CAAE,EAAE,QAAS,CAAE,CAAE,CACpE,CACF,CACD,CACD,EAEQ,oBAAC,QAAK,CAAC,SAAQ,GAAC,KAAK,KAAK,IAAK,GACvC,oBAAC,aACA,oBAAC,UACA,oBAAC,UAAI,IAAK,EACT,OAAO,QAAQ,IAAK,CAAE,EAAG,KAAO,oBAAC,MAAG,IAAK,IAAI,CAAE,CAAK,CACtD,CACD,EACA,oBAAC,aACA,oBAAC,UACA,oBAAC,UAAI,EAAE,KAAK,CAAE,EACb,OAAO,QAAQ,IAAK,CAAE,EAAG,IAClB,oBAAC,MAAG,IAAK,GAAG,KAAK,KAAM,OAAO,GAAG,IAAK,EAAG,CAAE,EAAE,QAAS,CAAE,CAAE,CACjE,CACF,EACA,oBAAC,UACA,oBAAC,UAAI,EAAE,IAAI,CAAE,EACZ,OAAO,QAAQ,IAAK,CAAE,EAAG,IAClB,oBAAC,MAAG,IAAK,GAAG,KAAK,KAAO,GAAE,OAAO,GAAG,IAAK,EAAG,CAAE,GAAG,QAAS,CAAE,CAAE,CACrE,CACF,CACD,CACD,CACA,CACF,EAII,SAAW,CAAC,CAAE,EAAG,EAAG,KAAM,aAAc,eAAkB,CAC/D,GAAI,CACH,KAAM,SAAU,YAAc,oBAAsB,aAC9C,CAAE,OAAQ,WAAY,SAAY,QAAS,EAAG,EAAG,KAAM,YAAa,EAE1E,MAAO,CACN,OAFc,WAAU,OAAQ,OAAQ,EAGxC,UACD,CACD,OAAU,MAAR,CACD,MAAO,CAAC,CACT,CACD,EAeA,MAAM,kBAAmB,gBAAU,CAClC,YAAa,MAAQ,CACpB,MAAO,KAAM,EA2Bd,sCAAmB,IAAM,CACxB,KAAM,SAAY,OAAU,CAC3B,KAAM,QAAS,KAAK,MAAM,OACpB,CAAE,QAAW,aAAc,KAAK,MAAM,EAAG,KAAK,MAAM,EAAG,MAAM,KAAK,MAAM,YAAa,EACrF,MAAQ,OAAO,aAAc,MAAO,EACpC,WAAa,CAAC,EACpB,OAAU,GAAI,EAAG,EAAI,OAAO,QAAQ,OAAQ,IAAM,CACjD,KAAM,OAAO,SAAW,OAAO,QAAS,GAAM,SAAW,QACzD,WAAY,OAAS,MAAM,IAAK,IAAK,GAAG,EAAI,CAC7C,CACA,KAAM,QAAS,OAAO,QAAS,MAAO,EAChC,KAAO,aAAc,QACrB,eAAiB,KAAK,MAAM,YAAY,MAAM,EACpD,MAAM,eAAU,eAAgB,IAAK,GACpC,eAAe,KAAM,IAAK,EAEpB,CAAE,OAAQ,UAAW,CAC7B,EACA,KAAK,MAAM,UAAW,QAAS,OAAQ,CACxC,CAAC,EA5CA,SAAW,EACX,KAAM,CAAE,EAAG,EAAG,KAAM,aAAc,aAAgB,MAClD,KAAK,MAAQ,iCACT,SAAS,CAAE,EAAG,EAAG,KAAM,aAAc,WAAY,CAAC,CAAC,EACnD,KAAK,CAEV,CAEA,MAAO,0BAA0B,UAAW,UAAY,CACvD,GACC,UAAU,OAAS,UAAU,MAC7B,UAAU,eAAiB,UAAU,cACrC,UAAU,IAAM,UAAU,GAC1B,UAAU,IAAM,UAAU,GAC1B,UAAU,cAAgB,UAAU,YACnC,CACD,KAAM,CAAE,EAAG,EAAG,KAAM,aAAc,aAAgB,UAClD,MAAO,kCACH,SAAS,CAAE,EAAG,EAAG,KAAM,aAAc,WAAY,CAAC,CAAC,EACnD,SAAS,CAEd,CACA,MAAO,KACR,CAuBA,QAAS,CACR,KAAM,CAAE,OAAQ,YAAe,KAAK,MAC9B,CAAE,GAAM,KAAK,MACnB,MAAM,QAIL,oBAAC,OAAI,MAAO,CAAE,UAAW,OAAQ,MAAO,MAAO,GAC9C,oBAAC,QAAK,UAAU,SAAU,EAAE,2BAA4B,CAAE,EAAG,KAAK,MAAM,EAAG,QAAS,OAAQ,CAAC,CAAE,EAC9F,aAAc,WAAY,OAAQ,KAAK,MAAM,aAAc,CAAE,EAC7D,KAAK,MAAM,UAAY,oBAAC,UAAO,CAAC,QAAS,EAAE,8BAA8B,GACzE,oBAAC,iBAAM,CAAC,QAAQ,YAAY,KAAK,KAAK,QAAS,KAAK,kBAAoB,EAAE,sBAAsB,CAAE,CACnG,EAAa,IACd,EATO,oBAAC,gBAAK,CAAC,QAAQ,UAAU,EAAE,oBAAoB,CAAE,CAW1D,CACD,CAKA,WAAW,aAAe,CACzB,YAAa,GACb,UAAW,IACZ,EAEA,WAAW,UAAY,CACtB,KAAM,uCACN,EAAG,+BAAoB,CACtB,4BACA,gCAAsB,iBAAO,CAC9B,CAAC,EAAE,WACH,EAAG,+BAAoB,CACtB,6BAAmB,+BAAoB,CAAE,4BAAkB,gCAAsB,iBAAO,CAAE,CAAC,CAAE,EAC7F,4BACA,gCAAsB,iBAAO,CAC9B,CAAC,EAAE,WACH,aAAc,6BAAmB,2BAAiB,EAAE,WACpD,YAAa,0BACb,UAAW,yBACZ,EAKA,SAAe,gBAAiB,QAAS,EAAG,iBAAe,UAAW,CAAE,C,yWCzMxE,eAAgB,EAAG,EAAI,CACtB,GAAK,CAAC,oEAAa,CAAE,EACpB,KAAM,IAAI,WAAW,oFAAsF,EAAI,GAAI,EAEpH,GAAK,CAAC,oEAAa,CAAE,EACpB,KAAM,IAAI,WAAW,2FAA6F,EAAI,GAAI,EAE3H,KAAM,MAAO,KAAK,QAAS,CAAE,EACvB,EAAI,EAAE,OACZ,GAAI,UAAW,EACf,OAAU,GAAI,EAAG,EAAI,EAAG,IAClB,KAAM,KAAQ,EAAG,IACrB,WAAY,GAGd,iBAAY,EACL,QACR,CAKA,4BAAe,K","file":"static/js/NaiveBayes.7d6bb29e.chunk.js","sourcesContent":["/**\n* @license Apache-2.0\n*\n* Copyright (c) 2018 The Stdlib Authors.\n*\n* Licensed under the Apache License, Version 2.0 (the \"License\");\n* you may not use this file except in compliance with the License.\n* You may obtain a copy of the License at\n*\n*    http://www.apache.org/licenses/LICENSE-2.0\n*\n* Unless required by applicable law or agreed to in writing, software\n* distributed under the License is distributed on an \"AS IS\" BASIS,\n* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n* See the License for the specific language governing permissions and\n* limitations under the License.\n*/\n\n'use strict';\n\n/**\n* Test if a value is an array of arrays.\n*\n* @module @stdlib/assert/is-array-array\n*\n* @example\n* var isArrayArray = require( '@stdlib/assert/is-array-array' );\n*\n* var bool = isArrayArray( [ [], [] ] );\n* // returns true\n*\n* bool = isArrayArray( [ {}, {} ] );\n* // returns false\n*\n* bool = isArrayArray( [] );\n* // returns false\n*/\n\n// MODULES //\n\nvar isArrayArray = require( './main.js' );\n\n\n// EXPORTS //\n\nmodule.exports = isArrayArray;\n","/**\n* @license Apache-2.0\n*\n* Copyright (c) 2018 The Stdlib Authors.\n*\n* Licensed under the Apache License, Version 2.0 (the \"License\");\n* you may not use this file except in compliance with the License.\n* You may obtain a copy of the License at\n*\n*    http://www.apache.org/licenses/LICENSE-2.0\n*\n* Unless required by applicable law or agreed to in writing, software\n* distributed under the License is distributed on an \"AS IS\" BASIS,\n* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n* See the License for the specific language governing permissions and\n* limitations under the License.\n*/\n\n'use strict';\n\n// MODULES //\n\nvar arrayfun = require( './../../tools/array-function' );\nvar isArray = require( './../../is-array' );\n\n\n// MAIN //\n\n/**\n* Tests if a value is an array of arrays.\n*\n* @name isArrayArray\n* @type {Function}\n* @param {*} value - value to test\n* @returns {boolean} boolean indicating whether a value is an array of arrays\n*\n* @example\n* var bool = isArrayArray( [ [], [] ] );\n* // returns true\n*\n* bool = isArrayArray( [ {}, {} ] );\n* // returns false\n*\n* bool = isArrayArray( [] );\n* // returns false\n*/\nvar isArrayArray = arrayfun( isArray );\n\n\n// EXPORTS //\n\nmodule.exports = isArrayArray;\n","// MODULES //\n\nimport uniq from 'uniq';\nimport ndarray from '@stdlib/ndarray/array';\nimport isArrayArray from '@stdlib/assert/is-array-array';\nimport isMatrixLike from '@stdlib/assert/is-matrix-like';\nimport exp from '@stdlib/math/base/special/exp';\nimport ln from '@stdlib/math/base/special/ln';\nimport pow from '@stdlib/math/base/special/pow';\nimport PI from '@stdlib/constants/float64/pi';\nimport mean from '@isle-project/utils/statistic/mean';\nimport stdev from '@isle-project/utils/statistic/stdev';\nimport max from '@isle-project/utils/statistic/max';\nimport subtract from '@isle-project/utils/subtract';\n\n\n// MAIN //\n\n/**\n* Naive Bayes fitting object constructor for normal distribution.\n*\n* @constructor\n* @param {Matrix} x - design matrix\n* @param {Array} y - vector of class memberships\n* @returns {GaussianFit} GaussianFit instance\n*/\nfunction GaussianFit( x, y ) {\n\tthis.n = x.shape[ 0 ];\n\tthis.p = x.shape[ 1 ];\n\n\tthis.classes = uniq( y.slice() );\n\tthis.nclass = this.classes.length;\n\n\tthis.fitGaussian( x, y );\n}\n\nGaussianFit.prototype.score = require( './score.js' );\n\n\n/**\n* Fit the data under the assumption that p(x_i|c) follows a normal distribution.\n*\n* ## Notes\n*\n* -   Assigns prior and conditional probabilities of BayesFit instance.\n*\n* @param {Matrix} x - design matrix\n* @param {Array} y - vector of class memberships\n* @returns {void}\n*/\nGaussianFit.prototype.fitGaussian = function fitGaussian( x, y ) {\n\tthis.prior = {};\n\tconst shape = [ this.p, this.nclass ];\n\tthis.mu = ndarray( new Float64Array( shape[0]*shape[1] ), { 'shape': shape } );\n\tthis.sigma = ndarray( new Float64Array( shape[0]*shape[1] ), { 'shape': shape } );\n\tfor ( let i = 0; i < this.nclass; i++ ) {\n\t\tconst ids = [];\n\t\tconst c = this.classes[ i ];\n\t\tfor ( let j = 0; j < this.n; j++ ) {\n\t\t\tif ( y[ j ] === c ) {\n\t\t\t\tids.push( j );\n\t\t\t}\n\t\t}\n\t\tconst nc = ids.length;\n\t\tthis.prior[ c ] = ln( nc / this.n );\n\t\tfor ( let j = 0; j < this.p; j++ ) {\n\t\t\tconst vals = ids.map( i => x.get( i, j ) );\n\t\t\tconst mu = mean( vals );\n\t\t\tconst sigma = stdev( vals );\n\t\t\tthis.mu.set( j, i, mu );\n\t\t\tthis.sigma.set( j, i, sigma );\n\t\t}\n\t}\n};\n\n/**\n* Calculate p(X=x,C=i), i.e. the joint probability of observation x and class i.\n*\n* @param {Array} x - new observation\n* @param {number} i - class indicator\n* @returns {number} log probability\n*/\nGaussianFit.prototype.calcGaussianProb = function calcGaussianProb( x, i ) {\n\tconst c = this.classes[ i ];\n\tlet res = this.prior[ c ];\n\n\tfor ( let j = 0; j < this.p; j++ ) {\n\t\tconst sigma = this.sigma.get( j, i );\n\t\tconst s2 = sigma*sigma;\n\t\tconst mu = this.mu.get( j, i );\n\t\tconst val = ( -0.5 * ln( 2 * PI * s2 ) ) - ( pow( x[ j ] - mu, 2 ) / s2 );\n\t\tres += val;\n\t}\n\treturn res;\n};\n\n/**\n* Predict class membership for one new observation.\n*\n* @param {Array} x - new observation\n* @returns {(number|string)} predicted class membership\n*/\nGaussianFit.prototype.predictOne = function predictOne( x ) {\n\tconst nClasses = this.classes.length;\n\tconst logLik = new Array( nClasses );\n\tfor ( let i = 0; i < nClasses; i++ ) {\n\t\tlogLik[ i ] = this.calcGaussianProb( x, i );\n\t}\n\tlet max = logLik[ 0 ];\n\tlet argmax = this.classes[ 0 ];\n\tfor ( let i = 0; i < nClasses; i++ ) {\n\t\tconst val = logLik[ i ];\n\t\tif ( val > max ) {\n\t\t\tmax = val;\n\t\t\targmax = this.classes[ i ];\n\t\t}\n\t}\n\treturn argmax;\n};\n\n/**\n* Predict class membership for new observation(s).\n*\n* @param {(Matrix|Array)} x - new observation(s)\n* @returns {Array} array of predicted class memberships\n*/\nGaussianFit.prototype.predict = function predict( x ) {\n\tconst nClasses = this.classes.length;\n\tif ( isArrayArray( x ) ) {\n\t\tx = ndarray( x );\n\t}\n\t// Case A: Predictions for multiple observations:\n\tif ( isMatrixLike( x ) ) {\n\t\tconst [ nrow, ncol ] = x.shape;\n\t\tconst ret = new Array( nrow );\n\t\tfor ( let i = 0; i < nrow; i++ ) {\n\t\t\tconst logLik = new Array( nClasses );\n\t\t\tfor ( let j = 0; j < nClasses; j++ ) {\n\t\t\t\tconst arr = new Array( ncol );\n\t\t\t\tfor ( let k = 0; k < ncol; k++ ) {\n\t\t\t\t\tarr[ k ] = x.get( i, k );\n\t\t\t\t}\n\t\t\t\tlogLik[ j ] = this.calcGaussianProb( arr, j );\n\t\t\t}\n\t\t\tlet max = logLik[ 0 ];\n\t\t\tlet argmax = this.classes[ 0 ];\n\t\t\tfor ( let j = 0; j < nClasses; j++ ) {\n\t\t\t\tconst val = logLik[ j ];\n\t\t\t\tif ( val > max ) {\n\t\t\t\t\tmax = val;\n\t\t\t\t\targmax = this.classes[ j ];\n\t\t\t\t}\n\t\t\t}\n\t\t\tret[ i ] = argmax;\n\t\t}\n\t\treturn ret;\n\t}\n\t// Case B: Only one new observation:\n\treturn this.predictOne( x );\n};\n\n/**\n* Calculates class membership probabilities.\n*\n* @param {(Matrix|Array)} x - design matrix\n* @returns {Array} class probabilities\n*/\nGaussianFit.prototype.predictProbs = function predictProbs( x ) {\n\tif ( isArrayArray( x ) ) {\n\t\tx = ndarray( x );\n\t}\n\t// Case A: Predictions for multiple observations:\n\tif ( isMatrixLike( x ) ) {\n\t\tconst [ nrow, ncol ] = x.shape;\n\t\tconst ret = new Array( nrow );\n\t\tfor ( let i = 0; i < nrow; i++ ) {\n\t\t\tlet logLik = new Array( this.nclass );\n\t\t\tfor ( let j = 0; j < this.nclass; j++ ) {\n\t\t\t\tconst arr = new Array( ncol );\n\t\t\t\tfor ( let k = 0; k < ncol; k++ ) {\n\t\t\t\t\tarr[ k ] = x.get( i, k );\n\t\t\t\t}\n\t\t\t\tlogLik[ j ] = this.calcGaussianProb( arr, j );\n\t\t\t}\n\t\t\tconst a = max( logLik );\n\t\t\tlet summand = 0;\n\t\t\tfor ( let j = 0; j < logLik.length; j++ ) {\n\t\t\t\tsummand += exp( logLik[ j ] - a );\n\t\t\t}\n\t\t\tconst denom = a + ln( summand );\n\t\t\tlogLik = subtract( logLik, denom );\n\t\t\tret[ i ] = logLik.map( x => exp( x ) );\n\t\t}\n\t\treturn ret;\n\t}\n\t// Case B: Create prediction for a single observation:\n\tconst logLik = new Array( this.nclass );\n\tfor ( let j = 0; j < this.nclass; j++ ) {\n\t\tlogLik[ j ] = this.calcGaussianProb( x, j );\n\t}\n\tconst a = max( logLik );\n\tlet summand = 0;\n\tfor ( let j = 0; j < logLik.length; j++ ) {\n\t\tsummand += exp( logLik[ j ] - a );\n\t}\n\tconst denom = a + ln( summand );\n\tlogLik = subtract( logLik, denom );\n\treturn logLik.map( x => exp( x ) );\n};\n\n\n// EXPORTS //\n\nexport default GaussianFit;\n","// MODULES //\n\nimport uniq from 'uniq';\nimport ndarray from '@stdlib/ndarray/array';\nimport max from '@isle-project/utils/statistic/max';\nimport subtract from '@isle-project/utils/subtract';\nimport exp from '@stdlib/math/base/special/exp';\nimport isArrayArray from '@stdlib/assert/is-array-array';\nimport isMatrixLike from '@stdlib/assert/is-matrix-like';\nimport ln from '@stdlib/math/base/special/ln';\nimport sum from '@isle-project/utils/statistic/sum';\n\n\n// MAIN //\n\n/**\n* Naive Bayes fitting object constructor for multinomial distribution.\n*\n* @constructor\n* @param {Matrix} x - design matrix\n* @param {Array} y - vector of class memberships\n* @param {number} alpha - Laplace smoothing parameter\n* @returns {MultinomialFit} MultinomialFit instance\n*/\nfunction MultinomialFit( x, y, alpha ) {\n\tthis.n = x.shape[ 0 ];\n\tthis.p = x.shape[ 1 ];\n\n\tthis.classes = uniq( y.slice() );\n\tthis.nclass = this.classes.length;\n\tthis.alpha = alpha;\n\n\tthis.fitMultinomial( x, y );\n}\n\nMultinomialFit.prototype.score = require( './score.js' );\n\n\n/**\n* Fit the data under the assumption that p(x_i|c) follows a multinomial distribution.\n*\n* ## Notes\n*\n* -   Assigns prior and conditional probabilities of BayesFit instance.\n*\n* @param {Matrix} x - design matrix\n* @param {Array} y - vector of class memberships\n* @returns {Void}\n*/\nMultinomialFit.prototype.fitMultinomial = function fitMultinomial( x, y ) {\n\tconst prior = {};\n\tconst shape = [ this.p, this.nclass ];\n\tconst cprob = ndarray( new Float64Array( shape[0]*shape[1] ), { 'shape': shape } );\n\tfor ( let i = 0; i < this.nclass; i++ ) {\n\t\tconst ids = [];\n\t\tconst counts = new Int32Array( this.p );\n\t\tconst c = this.classes[ i ];\n\t\tfor ( let j = 0; j < this.n; j++ ) {\n\t\t\tif ( y[ j ] === c ) {\n\t\t\t\tids.push( j );\n\t\t\t}\n\t\t}\n\t\tconst nc = ids.length;\n\t\tprior[ c ] = ln( nc / this.n );\n\t\tlet totalCount = 0;\n\t\tfor ( let j = 0; j < this.p; j++ ) {\n\t\t\tconst vals = ids.map( i => x.get( i, j ) );\n\t\t\tcounts[ j ] = sum( vals );\n\t\t\ttotalCount += counts[ j ];\n\t\t}\n\t\tfor ( let j = 0; j < this.p; j++ ) {\n\t\t\tconst val = ln( counts[ j ] + this.alpha ) - ln( totalCount + this.p * this.alpha );\n\t\t\tcprob.set( j, i, val );\n\t\t}\n\t}\n\tthis.prior = prior;\n\tthis.cprob = cprob;\n};\n\n/**\n* Calculates multinomial probability.\n*\n* @param {Array} x - new observation\n* @param {number} i - class indicator\n* @param {number} j - variable indicator\n* @returns {number} probability\n*/\nMultinomialFit.prototype.calcMultinomProb = function calcMultinomProb( x, i, j ) {\n\tconst c = this.classes[ i ];\n\tlet res = this.prior[ c ];\n\tfor ( j = 0; j < this.p; j++ ) {\n\t\tconst val = x[ j ] ? x[ j ] * this.cprob.get( j, i ) : 0;\n\t\tres += val;\n\t}\n\treturn res;\n};\n\n/**\n* Predict class membership for one new observation.\n*\n* @param {Array} x - new observation\n* @returns {(number|string)} predicted class membership\n*/\nMultinomialFit.prototype.predictOne = function predictOne( x ) {\n\tconst nClasses = this.classes.length;\n\tconst logLik = new Array( nClasses );\n\tfor ( let i = 0; i < nClasses; i++ ) {\n\t\tconst c = this.classes[ i ];\n\t\tlogLik[ i ] = this.prior[ c ];\n\t\tfor ( let j = 0; j < this.p; j++ ) {\n\t\t\tconst val = x[ j ] ? x[ j ] * this.cprob.get( j, i ) : 0;\n\t\t\tlogLik[ i ] += val;\n\t\t}\n\t}\n\tlet max = logLik[ 0 ];\n\tlet argmax = this.classes[ 0 ];\n\tfor ( let i = 0; i < nClasses; i++ ) {\n\t\tconst val = logLik[ i ];\n\t\tif ( val > max ) {\n\t\t\tmax = val;\n\t\t\targmax = this.classes[ i ];\n\t\t}\n\t}\n\treturn argmax;\n};\n\n/**\n* Predict class membership for new observation(s).\n*\n* @param {(Matrix|Array)} x - new observation(s)\n* @returns {Array} array of predicted class memberships\n*/\nMultinomialFit.prototype.predict = function predict( x ) {\n\tconst nClasses = this.classes.length;\n\tif ( isArrayArray( x ) ) {\n\t\tx = ndarray( x );\n\t}\n\t// Case A: Predictions for multiple observations:\n\tif ( isMatrixLike( x ) ) {\n\t\tconst ret = [];\n\t\tconst nrow = x.shape[ 0 ];\n\t\tfor ( let i = 0; i < nrow; i++ ) {\n\t\t\tconst logLik = new Array( nClasses );\n\t\t\tfor ( let j = 0; j < nClasses; j++ ) {\n\t\t\t\tconst c = this.classes[ j ];\n\t\t\t\tlogLik[ j ] = this.prior[ c ];\n\t\t\t\tfor ( let k = 0; k < this.p; k++ ) {\n\t\t\t\t\tconst val = x.get( i, k ) ? x.get( i, k ) * this.cprob.get( k, j ) : 0;\n\t\t\t\t\tlogLik[ j ] += val;\n\t\t\t\t}\n\t\t\t}\n\t\t\tlet max = logLik[ 0 ];\n\t\t\tlet argmax = this.classes[ 0 ];\n\t\t\tfor ( let j = 0; j < nClasses; j++ ) {\n\t\t\t\t\tconst val = logLik[ j ];\n\t\t\t\t\tif ( val > max ) {\n\t\t\t\t\t\tmax = val;\n\t\t\t\t\t\targmax = this.classes[ j ];\n\t\t\t\t\t}\n\t\t\t}\n\t\t\tret[ i ] = argmax;\n\t\t}\n\t\treturn ret;\n\t}\n\t// Case B: Only one new observation:\n\treturn this.predictOne( x );\n};\n\n/**\n* Calculates class membership probabilities.\n*\n* @param {(Matrix|Array)} x - design matrix\n* @returns {Array} class probabilities\n*/\nMultinomialFit.prototype.predictProbs = function predictProbs( x ) {\n\tif ( isArrayArray( x ) ) {\n\t\tx = ndarray( x );\n\t}\n\t// Case A: Predictions for multiple observations:\n\tif ( isMatrixLike( x ) ) {\n\t\tconst nrow = x.shape[ 0 ];\n\t\tconst ret = new Array( nrow );\n\t\tfor ( let i = 0; i < nrow; i++ ) {\n\t\t\tlet logLik = new Array( this.nclass );\n\t\t\tfor ( let j = 0; j < this.nclass; j++ ) {\n\t\t\t\tconst c = this.classes[ j ];\n\t\t\t\tlogLik[ j ] = this.prior[ c ];\n\t\t\t\tfor ( let k = 0; k < this.p; k++ ) {\n\t\t\t\t\tconst val = x.get( i, k ) ? x.get( i, k ) * this.cprob.get( k, j ) : 0;\n\t\t\t\t\tlogLik[ j ] += val;\n\t\t\t\t}\n\t\t\t}\n\t\t\tconst a = max( logLik );\n\t\t\tlet summand = 0;\n\t\t\tfor ( let j = 0; j < logLik.length; j++ ) {\n\t\t\t\tsummand += exp( logLik[ j ] - a );\n\t\t\t}\n\t\t\tconst denom = a + ln( summand );\n\t\t\tlogLik = subtract( logLik, denom );\n\t\t\tret[ i ] = logLik.map( x => exp( x ) );\n\t\t}\n\t\treturn ret;\n\t}\n\t// Case B: Create prediction for a single observation:\n\tlet logLik = new Array( this.nclass );\n\tfor ( let j = 0; j < this.nclass; j++ ) {\n\t\tconst c = this.classes[ j ];\n\t\tlogLik[ j ] = this.prior[ c ];\n\t\tfor ( let k = 0; k < this.p; k++ ) {\n\t\t\tconst val = x[ k ] * this.cprob.get( k, j );\n\t\t\tlogLik[ j ] += val;\n\t\t}\n\t}\n\tconst a = max( logLik );\n\tlet summand = 0;\n\tfor ( let j = 0; j < logLik.length; j++ ) {\n\t\tsummand += exp( logLik[ j ] - a );\n\t}\n\tconst denom = a + ln( summand );\n\tlogLik = subtract( logLik, denom );\n\treturn logLik.map( x => exp( x ) );\n};\n\n\n// EXPORTS //\n\nexport default MultinomialFit;\n","// MODULES //\n\nimport ndarray from '@stdlib/ndarray/array';\nimport hasOwnProperty from '@stdlib/assert/has-own-property';\nimport isArrayArray from '@stdlib/assert/is-array-array';\nimport isArrayLike from '@stdlib/assert/is-array-like';\nimport isMatrixLike from '@stdlib/assert/is-matrix-like';\nimport { isPrimitive as isNumber } from '@stdlib/assert/is-number';\nimport GaussianFit from './gaussian.js';\nimport MultinomialFit from './multinomial.js';\n\n\n// MAIN //\n\n/**\n* Fits a multinomial naive Bayes model.\n*\n* @param {(Matrix|Array)} x - design matrix\n* @param {Array} y - vector of class memberships\n* @param {Object} [opts] - function options\n* @param {number} [opts.alpha] - Laplace smoothing parameter\n* @returns {MultinomialFit} MultinomialFit instance\n*/\nfunction multinomNB( x, y, opts ) {\n\tif ( isArrayArray( x ) ) {\n\t\tx = ndarray( x );\n\t} else if ( !isMatrixLike( x ) ) {\n\t\tconst msg = 'invalid input argument. The first argument must be a matrix or an array-of-arrays. Value: `' + x + '`';\n\t\tthrow new TypeError( msg );\n\t}\n\tif ( !isArrayLike( y ) ) {\n\t\tthrow new TypeError( 'invalid input argument. The second argument must be array-like. Value: `' + y + '`' );\n\t}\n\tif ( arguments > 2 ) {\n\t\tif ( hasOwnProperty( opts, 'alpha' ) ) {\n\t\t\tif ( !isNumber( opts.alpha ) ) {\n\t\t\t\tthrow new TypeError( 'invalid option. Laplace smoothing option must be a number primitive. Option: `' + opts.alpha + '`.' );\n\t\t\t}\n\t\t}\n\t}\n\tconst alpha = opts.alpha || 1;\n\tconst fit = new MultinomialFit( x, y, alpha );\n\treturn fit;\n}\n\n/**\n* Fits a Gaussian naive Bayes model.\n*\n* @param {(Matrix|Array)} x - design matrix\n* @param {Array} y - vector of class memberships\n* @returns {GaussianFit} model fit\n*/\nfunction gaussianNB( x, y ) {\n\tif ( isArrayArray( x ) ) {\n\t\tx = ndarray( x );\n\t} else if ( !isMatrixLike( x ) ) {\n\t\tconst msg = 'invalid input argument. The first argument must be a matrix or an array-of-arrays. Value: `' + x + '`';\n\t\tthrow new TypeError( msg );\n\t}\n\tif ( !isArrayLike( y ) ) {\n\t\tthrow new TypeError( 'invalid input argument. The second argument must be array-like. Value: `' + y + '`' );\n\t}\n\tconst fit = new GaussianFit( x, y );\n\treturn fit;\n}\n\n\n// EXPORTS //\n\nexport { multinomNB as multinomial, gaussianNB as gaussian };\n","// MODULES //\n\nimport contains from '@stdlib/assert/contains';\nimport ndarray from '@stdlib/ndarray/array';\nimport isArray from '@stdlib/assert/is-array';\nimport extractCategoriesFromValues from '@isle-project/utils/extract-categories-from-values';\nimport isNonMissingNumber from '@isle-project/utils/is-non-missing-number';\nimport isMissing from '@isle-project/utils/is-missing';\n\n\n// MAIN //\n\nexport function designMatrix( x, y, data, quantitative ) {\n\tlet matrix = [];\n\tconst predictors = [];\n\tconst hash = {};\n\tif ( !isArray( x ) ) {\n\t\tx = [ x ];\n\t}\n\tfor ( let j = 0; j < x.length; j++ ) {\n\t\tconst values = data[ x[ j ] ];\n\t\tif ( contains( quantitative, x[ j ] ) ) {\n\t\t\tpredictors.push( x[ j ] );\n\t\t} else {\n\t\t\tconst categories = extractCategoriesFromValues( values, x[ j ] );\n\t\t\tfor ( let k = 0; k < categories.length; k++ ) {\n\t\t\t\tpredictors.push( `${x[ j ]}_${categories[ k ]}` );\n\t\t\t}\n\t\t\thash[ x[ j ] ] = categories;\n\t\t}\n\t}\n\tconst nobs = data[ x[ 0 ] ].length;\n\tfor ( let i = 0; i < nobs; i++ ) {\n\t\tconst row = [];\n\t\tfor ( let j = 0; j < x.length; j++ ) {\n\t\t\tconst values = data[ x[ j ] ];\n\t\t\tif ( contains( quantitative, x[ j ] ) ) {\n\t\t\t\trow.push( values[ i ] );\n\t\t\t} else {\n\t\t\t\tconst categories = hash[ x[ j ] ];\n\t\t\t\tconst val = values[ i ];\n\t\t\t\tfor ( let k = 0; k < categories.length; k++ ) {\n\t\t\t\t\trow.push( ( val === categories[ k ] ) ? 1 : 0 );\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tmatrix.push( row );\n\t}\n\tmatrix = ndarray( matrix );\n\tconst yvalues = data[ y ];\n\treturn { matrix, predictors, yvalues };\n}\n\nexport function designMatrixMissing( x, y, data, quantitative ) {\n\tlet matrix = [];\n\tconst predictors = [];\n\tconst hash = {};\n\tif ( !isArray( x ) ) {\n\t\tx = [ x ];\n\t}\n\tfor ( let j = 0; j < x.length; j++ ) {\n\t\tconst values = data[ x[ j ] ];\n\t\tif ( contains( quantitative, x[ j ] ) ) {\n\t\t\tpredictors.push( x[ j ] );\n\t\t} else {\n\t\t\tconst categories = extractCategoriesFromValues( values, x[ j ] );\n\t\t\tfor ( let k = 0; k < categories.length; k++ ) {\n\t\t\t\tpredictors.push( `${x[ j ]}_${categories[ k ]}` );\n\t\t\t}\n\t\t\thash[ x[ j ] ] = categories;\n\t\t}\n\t}\n\tconst nobs = data[ x[ 0 ] ].length;\n\tconst yvalues = [];\n\tfor ( let i = 0; i < nobs; i++ ) {\n\t\tconst row = [];\n\t\tlet missing = false;\n\t\tfor ( let j = 0; j < x.length; j++ ) {\n\t\t\tconst values = data[ x[ j ] ];\n\t\t\tif ( contains( quantitative, x[ j ] ) ) {\n\t\t\t\tif ( isNonMissingNumber( values[ i ] ) ) {\n\t\t\t\t\trow.push( values[ i ] );\n\t\t\t\t} else {\n\t\t\t\t\tmissing = true;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tconst categories = hash[ x[ j ] ];\n\t\t\t\tconst val = values[ i ];\n\t\t\t\tif ( isMissing( val ) ) {\n\t\t\t\t\tmissing = true;\n\t\t\t\t} else {\n\t\t\t\t\tfor ( let k = 0; k < categories.length; k++ ) {\n\t\t\t\t\t\trow.push( ( val === categories[ k ] ) ? 1 : 0 );\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif ( isMissing( data[ y ][ i ] ) ) {\n\t\t\tmissing = true;\n\t\t}\n\t\tif ( !missing ) {\n\t\t\tmatrix.push( row );\n\t\t\tyvalues.push( data[ y ][ i ] );\n\t\t}\n\t}\n\tmatrix = ndarray( matrix );\n\treturn { matrix, predictors, yvalues };\n}\n","// MODULES //\n\nimport React, { Component } from 'react';\nimport PropTypes from 'prop-types';\nimport { withTranslation } from 'react-i18next';\nimport Alert from 'react-bootstrap/Alert';\nimport Button from 'react-bootstrap/Button';\nimport contains from '@stdlib/assert/contains';\nimport Table from '@isle-project/components/table';\nimport exp from '@stdlib/math/base/special/exp';\nimport Tooltip from '@isle-project/components/tooltip';\nimport { gaussian } from './naive_bayes.js';\nimport { designMatrix, designMatrixMissing } from './design_matrix.js';\nimport { withPropCheck } from '@isle-project/utils/prop-check';\nimport { Factor } from '@isle-project/utils/factor-variable';\n\n\n// VARIABLES //\n\nlet COUNTER = 0;\n\n\n// FUNCTIONS //\n\nconst summaryTable = ( predictors, result, quantitative, t ) => {\n\treturn (\n\t\t<div>\n\t\t\t<span className=\"title\">{t('apriori-probs')}:</span>\n\t\t\t<Table bordered size=\"sm\">\n\t\t\t\t<thead>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t{result.classes.map( ( x, i ) => <th key={i}>{x}</th>)}\n\t\t\t\t\t</tr>\n\t\t\t\t</thead>\n\t\t\t\t<tbody>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t{result.classes.map( ( x, i ) => <th key={i}>{exp(result.prior[ x ]).toFixed( 3 )}</th>)}\n\t\t\t\t\t</tr>\n\t\t\t\t</tbody>\n\t\t\t</Table>\n\t\t\t<span className=\"title\">{t('conditionals')}:</span>\n\t\t\t{predictors.map( ( pred, i ) => {\n\t\t\t\tif ( contains( quantitative, pred ) ) {\n\t\t\t\t\treturn ( <Table bordered size=\"sm\" key={i} >\n\t\t\t\t\t\t<thead>\n\t\t\t\t\t\t\t<tr>\n\t\t\t\t\t\t\t\t<th>{pred}</th>\n\t\t\t\t\t\t\t\t{result.classes.map( ( x, i ) => <th key={i}>{x}</th>)}\n\t\t\t\t\t\t\t</tr>\n\t\t\t\t\t\t</thead>\n\t\t\t\t\t\t<tbody>\n\t\t\t\t\t\t\t<tr>\n\t\t\t\t\t\t\t\t<th>{t('mean')}</th>\n\t\t\t\t\t\t\t\t{result.classes.map( ( _, j ) => {\n\t\t\t\t\t\t\t\t\treturn <td key={`${i}-${j}`}>{result.mu.get( i, j ).toFixed( 6 )}</td>;\n\t\t\t\t\t\t\t\t})}\n\t\t\t\t\t\t\t</tr>\n\t\t\t\t\t\t\t<tr>\n\t\t\t\t\t\t\t\t<th>{t('sd')}</th>\n\t\t\t\t\t\t\t\t{result.classes.map( ( _, j ) => {\n\t\t\t\t\t\t\t\t\treturn <td key={`${i}-${j}`}>{result.sigma.get( i, j ).toFixed( 6 )}</td>;\n\t\t\t\t\t\t\t\t})}\n\t\t\t\t\t\t\t</tr>\n\t\t\t\t\t\t</tbody>\n\t\t\t\t\t</Table> );\n\t\t\t\t}\n\t\t\t\treturn ( <Table bordered size=\"sm\" key={i} >\n\t\t\t\t\t<thead>\n\t\t\t\t\t\t<tr>\n\t\t\t\t\t\t\t<th>{pred}</th>\n\t\t\t\t\t\t\t{result.classes.map( ( x, i ) => <th key={i}>{x}</th>)}\n\t\t\t\t\t\t</tr>\n\t\t\t\t\t</thead>\n\t\t\t\t\t<tbody>\n\t\t\t\t\t\t<tr>\n\t\t\t\t\t\t\t<th>{t('yes')}</th>\n\t\t\t\t\t\t\t{result.classes.map( ( _, j ) => {\n\t\t\t\t\t\t\t\treturn <td key={`${i}-${j}`}>{result.mu.get( i, j ).toFixed( 3 )}</td>;\n\t\t\t\t\t\t\t})}\n\t\t\t\t\t\t</tr>\n\t\t\t\t\t\t<tr>\n\t\t\t\t\t\t\t<th>{t('no')}</th>\n\t\t\t\t\t\t\t{result.classes.map( ( _, j ) => {\n\t\t\t\t\t\t\t\treturn <td key={`${i}-${j}`}>{(1-result.mu.get( i, j )).toFixed( 3 )}</td>;\n\t\t\t\t\t\t\t})}\n\t\t\t\t\t\t</tr>\n\t\t\t\t\t</tbody>\n\t\t\t\t</Table> );\n\t\t\t})}\n\t\t</div>\n\t);\n};\n\nconst fitModel = ({ x, y, data, quantitative, omitMissing }) => {\n\ttry {\n\t\tconst designM = omitMissing ? designMatrixMissing : designMatrix;\n\t\tconst { matrix, predictors, yvalues } = designM( x, y, data, quantitative );\n\t\tconst result = gaussian( matrix, yvalues );\n\t\treturn {\n\t\t\tresult,\n\t\t\tpredictors\n\t\t};\n\t} catch ( error ) {\n\t\treturn {};\n\t}\n};\n\n\n// MAIN //\n\n/**\n* Naive Bayes assuming that the predictors given the class membership follow a normal distribution.\n*\n* @property {Object} data - object of value arrays\n* @property {(string|Factor)} y - outcome variable\n* @property {(string|Factor|Array<(string|Factor)>)} x - one or more predictor variables\n* @property {Array<string>} quantitative - array of variables in `data` that are `quantitative`\n* @property {boolean} omitMissing - controls whether to omit missing values\n* @property {Function} onPredict - callback invoked with predictions and residuals after model fitting\n*/\nclass NaiveBayes extends Component {\n\tconstructor( props ) {\n\t\tsuper( props );\n\n\t\tCOUNTER += 1;\n\t\tconst { x, y, data, quantitative, omitMissing } = props;\n\t\tthis.state = {\n\t\t\t...fitModel({ x, y, data, quantitative, omitMissing }),\n\t\t\t...props\n\t\t};\n\t}\n\n\tstatic getDerivedStateFromProps( nextProps, prevState ) {\n\t\tif (\n\t\t\tnextProps.data !== prevState.data ||\n\t\t\tnextProps.quantitative !== prevState.quantitative ||\n\t\t\tnextProps.x !== prevState.x ||\n\t\t\tnextProps.y !== prevState.y ||\n\t\t\tnextProps.omitMissing !== prevState.omitMissing\n\t\t) {\n\t\t\tconst { x, y, data, quantitative, omitMissing } = nextProps;\n\t\t\treturn {\n\t\t\t\t...fitModel({ x, y, data, quantitative, omitMissing }),\n\t\t\t\t...nextProps\n\t\t\t};\n\t\t}\n\t\treturn null;\n\t}\n\n\thandlePrediction = () => {\n\t\tconst predict = ( data ) => {\n\t\t\tconst result = this.state.result;\n\t\t\tconst { matrix } = designMatrix( this.props.x, this.props.y, data, this.props.quantitative );\n\t\t\tconst probs = result.predictProbs( matrix );\n\t\t\tconst classProbs = {};\n\t\t\tfor ( let i = 0; i < result.classes.length; i++ ) {\n\t\t\t\tconst name = 'probs_' + result.classes[ i ] + '_bayes' + COUNTER;\n\t\t\t\tclassProbs[ name ] = probs.map( x => x[ i ] );\n\t\t\t}\n\t\t\tconst fitted = result.predict( matrix );\n\t\t\tconst name = 'pred_bayes'+ COUNTER;\n\t\t\tconst newCategorical = this.props.categorical.slice();\n\t\t\tif ( !contains( newCategorical, name ) ) {\n\t\t\t\tnewCategorical.push( name );\n\t\t\t}\n\t\t\treturn { fitted, classProbs };\n\t\t};\n\t\tthis.props.onPredict( predict, COUNTER );\n\t};\n\n\trender() {\n\t\tconst { result, predictors } = this.state;\n\t\tconst { t } = this.props;\n\t\tif ( !result ) {\n\t\t\treturn <Alert variant=\"danger\">{t('missing-attributes')}</Alert>;\n\t\t}\n\t\treturn (\n\t\t\t<div style={{ overflowX: 'auto', width: '100%' }}>\n\t\t\t\t<span className=\"title\" >{t('naive-bayes-for-response', { y: this.props.y, counter: COUNTER })}</span>\n\t\t\t\t{summaryTable( predictors, result, this.props.quantitative, t )}\n\t\t\t\t{this.props.onPredict ? <Tooltip tooltip={t('use-model-to-predict-tooltip')} >\n\t\t\t\t\t<Button variant=\"secondary\" size=\"sm\" onClick={this.handlePrediction} >{t('use-model-to-predict')}</Button>\n\t\t\t\t</Tooltip> : null}\n\t\t\t</div>\n\t\t);\n\t}\n}\n\n\n// PROPERTIES //\n\nNaiveBayes.defaultProps = {\n\tomitMissing: false,\n\tonPredict: null\n};\n\nNaiveBayes.propTypes = {\n\tdata: PropTypes.object.isRequired,\n\ty: PropTypes.oneOfType([\n\t\tPropTypes.string,\n\t\tPropTypes.instanceOf( Factor )\n\t]).isRequired,\n\tx: PropTypes.oneOfType([\n\t\tPropTypes.arrayOf( PropTypes.oneOfType([ PropTypes.string, PropTypes.instanceOf( Factor ) ]) ),\n\t\tPropTypes.string,\n\t\tPropTypes.instanceOf( Factor )\n\t]).isRequired,\n\tquantitative: PropTypes.arrayOf( PropTypes.string ).isRequired,\n\tomitMissing: PropTypes.bool,\n\tonPredict: PropTypes.func\n};\n\n\n// EXPORTS //\n\nexport default withTranslation( 'models' )( withPropCheck( NaiveBayes ) );\n","// MODULES //\n\nimport isArrayLike from '@stdlib/assert/is-array-like';\n\n\n// MAIN //\n\n/**\n* Calculates the mean accuracy of the given test data and labels.\n*\n* @param {(Matrix|Array)} x - design matrix\n* @param {Array} y - vector of class memberships\n* @returns {number} mean accuracy\n*/\nfunction score( x, y ) {\n\tif ( !isArrayLike( x ) ) {\n\t\tthrow new TypeError( 'invalid argument. First argument must be a matrix or array of test data. Value: `' + x + '`' );\n\t}\n\tif ( !isArrayLike( y ) ) {\n\t\tthrow new TypeError( 'invalid argument. Second argument must be an array of labels for the test data. Value: `' + y + '`' );\n\t}\n\tconst yhat = this.predict( x ); // eslint-disable-line @babel/no-invalid-this\n\tconst n = y.length;\n\tlet accuracy = 0;\n\tfor ( let i = 0; i < n; i++ ) {\n\t\tif ( yhat[ i ] === y[ i ] ) {\n\t\t\taccuracy += 1;\n\t\t}\n\t}\n\taccuracy /= n;\n\treturn accuracy;\n}\n\n\n// EXPORTS //\n\nexport default score;\n"],"sourceRoot":""}